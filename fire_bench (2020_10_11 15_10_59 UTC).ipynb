{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fire-bench.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE8Kh2Sy68qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTXkbjkcFF1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchfusion_utils.fp16 import convertToFP16\n",
        "from torchfusion_utils.initializers import *\n",
        "from torchfusion_utils.metrics import Accuracy\n",
        "from torchfusion_utils.models import load_model,save_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej88vpKhFJt4",
        "colab_type": "code",
        "outputId": "c4923215-2f4c-4350-984f-867b3e24c092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "pip install torchfusion-utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchfusion-utils\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/12/1eb84f9f81ad64a7a6be97a79899f4ad1a82c39422cfdda4d838ed459305/torchfusion_utils-0.1.5-py3-none-any.whl\n",
            "Installing collected packages: torchfusion-utils\n",
            "Successfully installed torchfusion-utils-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa16X1sJ85YR",
        "colab_type": "code",
        "outputId": "a6453932-e433-47a4-bb41-2b5006b1b8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxwr8Ukl9QIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/FIRE-SMOKE-DATASET.zip\" -d \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnUu8E-y780W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/drive/My Drive/FIRE-SMOKE-DATASET/Train'\n",
        "test_dir = '/content/drive/My Drive/FIRE-SMOKE-DATASET/Test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afs7STTj-LPQ",
        "colab_type": "code",
        "outputId": "43670b34-0ef8-42c1-c1f4-d34b04966ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "def load_split_train_test(datadir,testdir):\n",
        "    train_transforms = transforms.Compose([transforms.Resize((224,224),0),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       ])\n",
        "    transforms_test = transforms.Compose([transforms.Resize((224,224),0),\n",
        "                                       transforms.ToTensor()])\n",
        "    train_data = datasets.ImageFolder(datadir,       \n",
        "                    transform=train_transforms)\n",
        "    test_data = datasets.ImageFolder(testdir,       \n",
        "                    transform=transforms_test)\n",
        "    num_train = len(train_data)\n",
        "    print(num_train)\n",
        "    indices = list(range(num_train))\n",
        "    trainloader = torch.utils.data.DataLoader(train_data,\n",
        "                   shuffle = True, batch_size=64)\n",
        "    testloader = torch.utils.data.DataLoader(test_data, batch_size=64,shuffle = True)  #shuffle = True\n",
        "    \n",
        "    return trainloader, testloader\n",
        "trainloader, testloader = load_split_train_test(data_dir, test_dir)\n",
        "\n",
        "print(trainloader.dataset.classes)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2700\n",
            "['Fire', 'Neutral', 'Smoke']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE15b5hx_5ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ResNet = models.resnet50(num_classes=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aeCh1cBAbd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1kZtVj7vo4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRFvVPukAegA",
        "colab_type": "code",
        "outputId": "0f9b0f17-030f-4d73-e10e-a7a8cb26eed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdGwUifhAf0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Model = ResNet \n",
        "\n",
        "Model = Model.to(device)\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(Model.parameters(), lr=lr)\n",
        "\n",
        "Model,optimizer = convertToFP16(Model, optimizer)\n",
        "\n",
        "milestones = [20, 50,100,150]\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ4e475BZHlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "class_names = ['Fire','Neutral','Smoke']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb-5xlqrBEHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "train_losses,test_losses = [],[]\n",
        "p = []\n",
        "t= []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAR8i7sWBynF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_traing_and_validation_loop(Model, n_epochs, save_path):\n",
        "    \n",
        "    n_epochs = n_epochs\n",
        "\n",
        "    saving_criteria_of_model = 0\n",
        "\n",
        "    training_loss_array = []\n",
        "\n",
        "    validation_loss_array = []\n",
        "    \n",
        "    train_acc = Accuracy()\n",
        "    \n",
        "    validation_acc = Accuracy(topK=1)\n",
        "    \n",
        "\n",
        "    for i in range(n_epochs):\n",
        "        print(i,\"th epoch\")\n",
        "\n",
        "        p = []\n",
        "        t = []\n",
        "\n",
        "        total_test_data = 0\n",
        "\n",
        "        total_train_data = 0\n",
        "\n",
        "        correct_test_data = 0\n",
        "\n",
        "        training_loss = 0\n",
        "\n",
        "        validation_loss = 0\n",
        "        \n",
        "        train_acc.reset()\n",
        "\n",
        "        for data, target in trainloader:\n",
        "\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            predictions = Model(data)\n",
        "            p.append(predictions)\n",
        "            t.append(target)\n",
        "\n",
        "            loss = criteria(predictions, target)\n",
        "            \n",
        "            optimizer.backward(loss)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss += loss.item()*data.size(0)\n",
        "\n",
        "            train_acc.update(predictions, target)\n",
        "            \n",
        "        scheduler.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            validation_acc.reset()\n",
        "            \n",
        "            for data, target in testloader:\n",
        "                #print(\"target\",target)\n",
        "\n",
        "                data, target = data.to(device,dtype=torch.float), target.to(device,dtype=torch.float)\n",
        "\n",
        "\n",
        "                \n",
        "                data = data.float()\n",
        "                target = target.long()\n",
        "                data, target = Variable(data), Variable(target)\n",
        "\n",
        "\n",
        "\n",
        "                predictions = Model(data)\n",
        "                \n",
        "                loss = criteria(predictions, target)\n",
        "                \n",
        "                validation_acc.update(predictions, target)\n",
        "                \n",
        "                total_test_data += target.size(0)\n",
        "\n",
        "                validation_loss += loss.item()*data.size(0)\n",
        "                \n",
        "                \n",
        "        training_loss = training_loss / 2700\n",
        "        \n",
        "        validation_loss = validation_loss / total_test_data\n",
        "\n",
        "        training_loss_array.append(training_loss)\n",
        "        \n",
        "        validation_loss_array.append(validation_loss)\n",
        "        \n",
        "        #tf.cpu() \n",
        "        \n",
        "        predictions = torch.argmax(predictions, 1)  #this needs gpu\n",
        "\n",
        "        predictions = predictions.cpu()\n",
        "        predictions = predictions.numpy()\n",
        "        \n",
        "        ground_truth = target.cpu().numpy()\n",
        "        pred = predictions\n",
        "        l = len(pred)\n",
        "        ground_truth = target.cpu().numpy()\n",
        "        ground_truth = np.array(ground_truth)    \n",
        "        pred = np.array(predictions)\n",
        "\n",
        "        print(\"gt\", ground_truth)\n",
        "        print(\"pred\",pred)\n",
        "        \n",
        "      \n",
        "        \n",
        "      \n",
        "\n",
        "        print(f'{i+1} / {n_epochs} Training loss: {training_loss}, Tran_Accuracy: {train_acc.getValue()}, Validation_loss: {validation_loss}, Validation_Accuracy: {validation_acc.getValue()}')\n",
        "        if i in [0,5,8,9,12,14,15,19,21,39,49,99,149,199]:\n",
        "          print(classification_report(ground_truth,pred,target_names=class_names))\n",
        "          #print()\n",
        "          #print(confusion_matrix(ground_truth,pred, class_names))\n",
        "\n",
        "        if saving_criteria_of_model < validation_acc.getValue():\n",
        "\n",
        "            torch.save(Model, save_path)\n",
        "            \n",
        "            saving_criteria_of_model = validation_acc.getValue()\n",
        "            \n",
        "            print('--------------------------Saving Model---------------------------')\n",
        "    \n",
        "    plt.figure(figsize=(20, 4))\n",
        "        \n",
        "    x_axis = (range(n_epochs))\n",
        "        \n",
        "    plt.plot(x_axis, training_loss_array, 'r', validation_loss_array, 'b')\n",
        "        \n",
        "    plt.title('A graph of training loss vs validation loss')\n",
        "        \n",
        "    plt.legend(['train loss', 'validation loss'])\n",
        "        \n",
        "    plt.xlabel('Number of Epochs')\n",
        "        \n",
        "    plt.ylabel('Loss')\n",
        "        \n",
        "    return Model,p,t\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USHsxI6WdSCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f17e588a-687e-4cd5-f543-0c51ab3594cb"
      },
      "source": [
        "n_epochs = 30\n",
        "model,p,t = model_traing_and_validation_loop(Model, n_epochs, 'fire-flame.pt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 th epoch\n",
            "gt [2 1 2 1 1 2 2 2 1 2 1 2 1 2 2 0 0 1 0 2 2 1 2 2 1 0 2 0 2 1 0 1 1 1 0 2 1\n",
            " 0 0 0 0 1 0 1]\n",
            "pred [2 1 1 1 0 2 2 1 1 0 1 0 1 2 0 2 0 1 0 0 1 1 1 2 1 0 2 0 2 1 0 1 1 0 0 2 0\n",
            " 1 0 0 0 1 0 2]\n",
            "1 / 30 Training loss: 1.0834291811342593, Tran_Accuracy: 0.46666666865348816, Validation_loss: 0.6921875, Validation_Accuracy: 0.7099999785423279\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.59      0.83      0.69        12\n",
            "     Neutral       0.71      0.75      0.73        16\n",
            "       Smoke       0.80      0.50      0.62        16\n",
            "\n",
            "    accuracy                           0.68        44\n",
            "   macro avg       0.70      0.69      0.68        44\n",
            "weighted avg       0.71      0.68      0.68        44\n",
            "\n",
            "--------------------------Saving Model---------------------------\n",
            "1 th epoch\n",
            "gt [2 2 0 1 1 2 1 2 2 2 2 1 2 2 1 1 0 0 0 2 0 2 0 1 1 2 0 2 0 1 0 0 2 1 1 1 2\n",
            " 2 1 0 2 0 1 1]\n",
            "pred [2 2 0 1 0 2 1 2 1 1 2 1 1 2 1 1 0 0 0 1 0 2 0 1 1 2 0 2 0 1 0 1 1 1 1 1 2\n",
            " 1 1 0 1 0 1 1]\n",
            "2 / 30 Training loss: 0.580668041087963, Tran_Accuracy: 0.7837036848068237, Validation_loss: 0.662890625, Validation_Accuracy: 0.7233333587646484\n",
            "--------------------------Saving Model---------------------------\n",
            "2 th epoch\n",
            "gt [2 1 0 2 1 2 2 2 1 1 2 1 2 0 1 1 2 2 0 0 0 2 0 2 0 1 2 1 2 1 1 2 2 2 2 0 0\n",
            " 0 2 2 2 2 1 2]\n",
            "pred [2 1 0 0 1 1 1 1 1 1 1 1 2 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 2 1 0 1 0 0 0\n",
            " 0 1 2 0 0 1 0]\n",
            "3 / 30 Training loss: 0.4837572337962963, Tran_Accuracy: 0.8070370554924011, Validation_loss: 1.0854166666666667, Validation_Accuracy: 0.5833333134651184\n",
            "3 th epoch\n",
            "gt [2 0 1 2 0 0 0 1 0 1 0 2 2 1 0 2 1 1 0 0 0 2 0 0 1 1 1 1 1 1 1 0 0 2 1 0 2\n",
            " 0 2 2 1 0 0 2]\n",
            "pred [2 0 1 2 0 0 0 1 0 1 2 2 2 1 0 2 1 1 2 0 0 2 0 0 1 1 2 0 1 1 1 0 0 2 1 0 2\n",
            " 0 1 2 1 0 0 2]\n",
            "4 / 30 Training loss: 0.4736060474537037, Tran_Accuracy: 0.8155555725097656, Validation_loss: 0.4681477864583333, Validation_Accuracy: 0.8299999833106995\n",
            "--------------------------Saving Model---------------------------\n",
            "4 th epoch\n",
            "gt [0 2 1 0 0 1 1 2 0 2 2 0 2 0 0 2 2 2 1 0 1 1 2 1 2 0 0 1 2 2 1 0 2 2 1 0 1\n",
            " 0 0 2 1 0 2 1]\n",
            "pred [0 1 0 0 0 1 1 2 2 1 2 0 2 2 0 2 2 2 1 0 1 1 1 0 2 0 0 1 2 2 0 0 2 2 1 0 2\n",
            " 0 0 2 1 0 1 1]\n",
            "5 / 30 Training loss: 0.3883033130787037, Tran_Accuracy: 0.8514814972877502, Validation_loss: 0.68, Validation_Accuracy: 0.7799999713897705\n",
            "5 th epoch\n",
            "gt [2 1 0 0 1 2 1 0 0 1 1 1 2 0 0 2 1 1 2 1 1 1 1 2 0 1 2 2 1 2 1 0 0 2 2 0 1\n",
            " 1 1 2 1 1 1 2]\n",
            "pred [2 1 0 2 1 2 1 0 0 1 1 1 2 0 0 2 1 1 2 1 1 2 1 1 0 1 2 2 1 2 0 0 0 2 2 0 1\n",
            " 1 1 2 1 1 0 2]\n",
            "6 / 30 Training loss: 0.3587523509837963, Tran_Accuracy: 0.8581481575965881, Validation_loss: 0.7712565104166667, Validation_Accuracy: 0.7799999713897705\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.82      0.90      0.86        10\n",
            "     Neutral       0.95      0.86      0.90        21\n",
            "       Smoke       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.89        44\n",
            "   macro avg       0.87      0.89      0.88        44\n",
            "weighted avg       0.89      0.89      0.89        44\n",
            "\n",
            "6 th epoch\n",
            "gt [2 2 1 0 1 0 2 1 1 2 2 2 1 2 1 1 0 2 2 2 0 2 2 1 0 2 1 2 1 0 0 2 0 2 1 0 1\n",
            " 0 0 0 2 0 2 1]\n",
            "pred [1 2 0 0 1 0 2 1 0 2 2 2 1 2 1 1 0 2 2 0 0 2 2 1 0 1 1 2 0 0 0 2 0 2 2 0 1\n",
            " 0 0 0 2 0 2 2]\n",
            "7 / 30 Training loss: 0.3419609917534722, Tran_Accuracy: 0.8666666746139526, Validation_loss: 0.6576432291666666, Validation_Accuracy: 0.79666668176651\n",
            "7 th epoch\n",
            "gt [1 1 2 1 2 2 2 0 0 2 0 2 1 2 1 0 1 1 1 2 2 0 0 2 1 1 1 1 0 2 2 0 2 1 1 0 0\n",
            " 2 0 0 1 2 1 1]\n",
            "pred [1 1 2 1 2 2 2 0 0 0 0 2 1 2 1 0 0 2 1 2 2 0 0 1 1 1 1 1 0 2 2 0 2 1 1 0 0\n",
            " 2 0 0 1 1 2 1]\n",
            "8 / 30 Training loss: 0.30634675202546297, Tran_Accuracy: 0.8855555653572083, Validation_loss: 0.5341080729166666, Validation_Accuracy: 0.8233333230018616\n",
            "8 th epoch\n",
            "gt [0 2 0 0 2 1 2 0 0 0 0 0 0 0 1 1 1 1 2 1 0 1 2 1 0 1 2 0 1 0 1 0 1 2 2 1 2\n",
            " 0 2 2 2 1 1 1]\n",
            "pred [0 2 1 0 2 1 2 0 0 0 0 0 0 0 1 1 1 2 1 1 0 1 2 1 0 1 2 0 0 0 2 0 1 2 1 1 2\n",
            " 0 2 2 2 1 1 1]\n",
            "9 / 30 Training loss: 0.2735105613425926, Tran_Accuracy: 0.8985185027122498, Validation_loss: 0.624697265625, Validation_Accuracy: 0.7933333516120911\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.94      0.94      0.94        16\n",
            "     Neutral       0.81      0.81      0.81        16\n",
            "       Smoke       0.83      0.83      0.83        12\n",
            "\n",
            "    accuracy                           0.86        44\n",
            "   macro avg       0.86      0.86      0.86        44\n",
            "weighted avg       0.86      0.86      0.86        44\n",
            "\n",
            "9 th epoch\n",
            "gt [2 0 0 2 2 1 2 1 2 1 2 2 1 1 1 0 1 0 0 0 1 0 1 2 0 1 2 2 0 1 0 2 2 0 2 0 1\n",
            " 0 0 2 0 0 2 0]\n",
            "pred [2 2 0 2 1 1 2 2 2 1 2 2 2 2 1 2 1 2 0 0 1 0 1 2 0 1 0 1 0 1 0 1 2 0 2 0 1\n",
            " 0 0 2 0 0 2 0]\n",
            "10 / 30 Training loss: 0.3021961805555556, Tran_Accuracy: 0.8833333253860474, Validation_loss: 0.5698307291666667, Validation_Accuracy: 0.800000011920929\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.82      0.87        17\n",
            "     Neutral       0.75      0.75      0.75        12\n",
            "       Smoke       0.65      0.73      0.69        15\n",
            "\n",
            "    accuracy                           0.77        44\n",
            "   macro avg       0.78      0.77      0.77        44\n",
            "weighted avg       0.79      0.77      0.78        44\n",
            "\n",
            "10 th epoch\n",
            "gt [1 1 0 2 1 0 1 2 0 2 1 1 1 0 0 2 1 2 0 0 0 1 0 2 2 1 0 2 0 2 2 0 0 2 1 2 1\n",
            " 0 0 1 1 0 0 2]\n",
            "pred [1 1 0 1 1 1 1 1 0 2 1 1 1 0 0 2 1 2 0 0 0 1 0 2 2 2 2 2 0 1 1 0 0 1 1 0 1\n",
            " 0 0 1 0 0 0 2]\n",
            "11 / 30 Training loss: 0.31844731083622685, Tran_Accuracy: 0.8881481289863586, Validation_loss: 0.6760677083333333, Validation_Accuracy: 0.7900000214576721\n",
            "11 th epoch\n",
            "gt [2 1 1 2 1 0 0 0 1 1 0 0 1 2 2 2 1 0 2 2 2 2 1 2 2 0 0 0 0 2 0 0 1 0 2 0 0\n",
            " 0 1 2 0 1 0 0]\n",
            "pred [1 1 1 2 1 0 0 0 0 1 0 2 1 2 2 2 2 2 2 2 2 2 1 2 2 0 0 0 0 1 0 0 1 0 2 0 0\n",
            " 0 2 2 0 1 0 0]\n",
            "12 / 30 Training loss: 0.23154170283564815, Tran_Accuracy: 0.9177777767181396, Validation_loss: 0.6662825520833333, Validation_Accuracy: 0.8199999928474426\n",
            "12 th epoch\n",
            "gt [1 2 0 1 2 0 1 2 2 1 2 1 0 2 0 1 1 2 0 1 1 1 0 2 2 2 2 1 0 0 0 1 1 0 0 0 1\n",
            " 2 0 2 1 0 1 0]\n",
            "pred [2 2 0 1 1 0 2 2 2 1 2 1 0 2 0 1 1 2 2 2 1 1 0 1 2 2 2 1 0 0 0 1 0 0 0 0 1\n",
            " 2 0 2 1 0 1 0]\n",
            "13 / 30 Training loss: 0.2427070674189815, Tran_Accuracy: 0.9103703498840332, Validation_loss: 0.5417317708333333, Validation_Accuracy: 0.8133333325386047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.93      0.93        15\n",
            "     Neutral       0.86      0.75      0.80        16\n",
            "       Smoke       0.73      0.85      0.79        13\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.84      0.84      0.84        44\n",
            "weighted avg       0.85      0.84      0.84        44\n",
            "\n",
            "13 th epoch\n",
            "gt [1 2 0 1 0 2 2 1 1 1 0 2 0 0 2 0 0 2 1 2 2 0 2 0 0 0 2 0 2 0 2 1 0 2 0 1 2\n",
            " 1 1 0 2 2 2 1]\n",
            "pred [1 2 0 1 0 1 2 1 2 2 0 2 0 0 2 0 0 2 1 2 1 0 2 0 0 2 2 0 2 0 1 0 0 2 0 2 2\n",
            " 0 1 0 2 1 2 1]\n",
            "14 / 30 Training loss: 0.18178096064814814, Tran_Accuracy: 0.9351851940155029, Validation_loss: 0.7783658854166666, Validation_Accuracy: 0.7666666507720947\n",
            "14 th epoch\n",
            "gt [0 1 0 1 1 0 0 0 1 2 0 1 0 0 0 2 0 2 1 1 1 0 0 0 2 1 0 0 2 0 0 0 0 2 2 0 0\n",
            " 1 0 2 1 2 2 1]\n",
            "pred [0 1 0 1 2 0 0 0 1 1 2 1 0 0 0 2 0 2 2 0 1 1 0 0 2 1 0 0 1 0 0 0 0 2 2 0 0\n",
            " 2 0 2 1 2 2 1]\n",
            "15 / 30 Training loss: 0.25037037037037035, Tran_Accuracy: 0.9066666960716248, Validation_loss: 0.7578125, Validation_Accuracy: 0.753333330154419\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.95      0.91      0.93        22\n",
            "     Neutral       0.73      0.67      0.70        12\n",
            "       Smoke       0.67      0.80      0.73        10\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.78      0.79      0.78        44\n",
            "weighted avg       0.83      0.82      0.82        44\n",
            "\n",
            "15 th epoch\n",
            "gt [1 2 0 0 0 2 2 1 0 2 2 2 2 0 2 1 1 2 2 2 0 2 1 0 2 1 2 1 2 0 0 1 1 2 0 0 0\n",
            " 2 2 2 0 0 1 2]\n",
            "pred [1 1 0 0 0 1 1 2 2 2 2 1 1 0 2 2 1 1 2 2 0 2 2 0 2 1 1 1 2 0 0 1 1 2 0 0 0\n",
            " 2 2 2 0 0 1 1]\n",
            "16 / 30 Training loss: 0.20878951461226852, Tran_Accuracy: 0.9244444370269775, Validation_loss: 0.64017578125, Validation_Accuracy: 0.8100000023841858\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.93      0.96        14\n",
            "     Neutral       0.47      0.70      0.56        10\n",
            "       Smoke       0.75      0.60      0.67        20\n",
            "\n",
            "    accuracy                           0.73        44\n",
            "   macro avg       0.74      0.74      0.73        44\n",
            "weighted avg       0.77      0.73      0.74        44\n",
            "\n",
            "16 th epoch\n",
            "gt [1 0 2 0 0 0 0 2 0 0 0 2 2 2 0 0 1 2 1 0 2 0 1 0 2 1 2 0 0 1 1 0 1 1 1 2 1\n",
            " 1 1 2 1 2 2 2]\n",
            "pred [1 0 2 0 1 2 0 1 0 0 0 2 2 2 0 2 1 2 2 0 2 0 1 2 2 1 2 0 0 1 2 0 1 1 2 1 1\n",
            " 2 1 2 2 1 2 2]\n",
            "17 / 30 Training loss: 0.13253327546296295, Tran_Accuracy: 0.95333331823349, Validation_loss: 0.9180208333333333, Validation_Accuracy: 0.753333330154419\n",
            "17 th epoch\n",
            "gt [1 1 1 0 0 2 2 0 2 2 2 0 2 0 1 0 2 0 2 2 2 1 0 1 2 1 0 1 2 1 1 2 2 2 1 1 1\n",
            " 1 1 1 2 2 0 1]\n",
            "pred [2 0 0 0 0 2 2 0 2 2 2 0 2 0 2 0 2 0 2 2 2 1 0 1 2 0 0 1 2 1 0 2 2 2 1 1 1\n",
            " 1 1 1 2 2 0 1]\n",
            "18 / 30 Training loss: 0.25879774305555553, Tran_Accuracy: 0.9111111164093018, Validation_loss: 0.6782356770833333, Validation_Accuracy: 0.800000011920929\n",
            "18 th epoch\n",
            "gt [1 0 0 1 0 2 2 0 2 0 1 1 1 0 1 1 0 0 2 2 2 2 0 2 0 2 1 0 1 2 1 1 0 2 0 1 0\n",
            " 1 2 0 2 0 2 1]\n",
            "pred [1 0 0 1 0 2 2 0 1 0 1 0 1 0 2 1 0 0 2 2 2 2 0 2 0 1 1 1 1 2 2 1 1 2 0 1 0\n",
            " 1 1 0 2 0 2 2]\n",
            "19 / 30 Training loss: 0.19450104890046296, Tran_Accuracy: 0.9322222471237183, Validation_loss: 0.8346875, Validation_Accuracy: 0.7699999809265137\n",
            "19 th epoch\n",
            "gt [0 1 0 1 1 2 1 0 2 0 1 0 0 2 1 2 0 1 2 0 1 0 2 0 2 2 1 2 2 0 2 1 2 2 1 1 1\n",
            " 2 0 1 2 0 2 1]\n",
            "pred [0 0 0 1 1 2 1 0 0 0 1 2 0 1 2 2 0 1 1 0 2 0 2 0 2 1 1 2 2 0 2 1 1 2 2 0 2\n",
            " 2 0 1 2 0 2 2]\n",
            "20 / 30 Training loss: 0.10654170283564815, Tran_Accuracy: 0.9651851654052734, Validation_loss: 1.0138932291666667, Validation_Accuracy: 0.800000011920929\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.80      0.92      0.86        13\n",
            "     Neutral       0.67      0.53      0.59        15\n",
            "       Smoke       0.65      0.69      0.67        16\n",
            "\n",
            "    accuracy                           0.70        44\n",
            "   macro avg       0.70      0.71      0.71        44\n",
            "weighted avg       0.70      0.70      0.70        44\n",
            "\n",
            "20 th epoch\n",
            "gt [2 1 0 0 1 0 1 1 2 0 2 1 1 0 0 2 2 0 2 1 1 1 1 1 2 0 2 1 0 1 0 0 2 0 1 1 2\n",
            " 1 2 0 2 0 0 0]\n",
            "pred [2 1 0 0 1 0 2 1 2 0 2 0 1 0 0 2 2 0 2 2 1 1 2 1 2 1 2 1 0 1 2 0 2 0 2 2 2\n",
            " 1 1 0 2 0 0 0]\n",
            "21 / 30 Training loss: 0.05880303276909722, Tran_Accuracy: 0.978518545627594, Validation_loss: 1.0026822916666667, Validation_Accuracy: 0.7866666913032532\n",
            "21 th epoch\n",
            "gt [1 0 1 2 2 2 1 2 1 2 1 1 1 0 2 0 1 1 1 0 1 0 1 1 2 1 2 1 1 0 2 1 2 0 1 0 0\n",
            " 1 2 0 0 2 0 2]\n",
            "pred [1 0 1 2 0 2 2 1 1 2 0 1 2 0 2 0 1 1 0 0 0 0 1 1 2 1 2 2 1 0 2 1 2 0 1 2 0\n",
            " 1 2 2 0 2 0 2]\n",
            "22 / 30 Training loss: 0.027887415002893517, Tran_Accuracy: 0.9911110997200012, Validation_loss: 0.9334635416666667, Validation_Accuracy: 0.8199999928474426\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.71      0.83      0.77        12\n",
            "     Neutral       0.93      0.68      0.79        19\n",
            "       Smoke       0.69      0.85      0.76        13\n",
            "\n",
            "    accuracy                           0.77        44\n",
            "   macro avg       0.78      0.79      0.77        44\n",
            "weighted avg       0.80      0.77      0.77        44\n",
            "\n",
            "22 th epoch\n",
            "gt [1 0 1 2 0 1 2 2 2 1 1 0 1 2 2 0 0 0 2 0 1 0 2 0 1 0 0 0 2 0 2 0 2 1 2 0 0\n",
            " 2 2 0 1 2 2 0]\n",
            "pred [2 0 1 2 0 1 1 2 1 2 2 0 1 2 2 0 0 0 2 0 1 0 2 0 1 0 0 0 1 0 2 0 1 1 2 0 0\n",
            " 2 2 0 1 0 2 0]\n",
            "23 / 30 Training loss: 0.021571530942563658, Tran_Accuracy: 0.995555579662323, Validation_loss: 1.0520572916666666, Validation_Accuracy: 0.7900000214576721\n",
            "23 th epoch\n",
            "gt [0 0 0 2 2 0 0 1 2 2 1 2 0 1 1 2 0 0 1 2 0 1 1 0 0 2 1 0 0 1 1 0 2 2 0 2 1\n",
            " 0 0 2 0 0 0 2]\n",
            "pred [0 0 0 1 2 0 0 1 2 2 1 2 1 2 1 2 0 0 1 2 0 1 1 0 0 1 1 0 2 1 1 0 2 2 0 2 2\n",
            " 0 1 2 0 0 0 2]\n",
            "24 / 30 Training loss: 0.016503250687210647, Tran_Accuracy: 0.9959259033203125, Validation_loss: 0.9883203125, Validation_Accuracy: 0.8166666626930237\n",
            "24 th epoch\n",
            "gt [1 2 0 0 1 1 0 1 2 1 1 1 0 0 2 1 2 0 1 2 2 0 2 1 0 2 2 0 2 0 1 0 0 0 1 0 0\n",
            " 1 0 1 1 1 1 2]\n",
            "pred [1 2 0 0 0 1 0 1 2 2 1 1 0 0 2 1 2 0 2 2 2 0 2 1 0 0 2 0 2 0 1 0 0 0 1 0 0\n",
            " 1 0 1 1 1 1 2]\n",
            "25 / 30 Training loss: 0.012510505958839699, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.067607421875, Validation_Accuracy: 0.8133333325386047\n",
            "25 th epoch\n",
            "gt [1 2 0 2 2 1 1 1 0 1 2 0 1 0 0 2 1 1 0 0 1 2 0 1 0 1 2 1 1 1 0 1 0 2 0 2 0\n",
            " 0 2 1 2 1 2 0]\n",
            "pred [0 2 0 2 2 1 1 2 0 1 2 0 1 0 2 2 2 1 0 0 1 2 0 1 0 1 2 1 1 1 0 1 0 2 0 2 0\n",
            " 0 2 1 2 1 2 0]\n",
            "26 / 30 Training loss: 0.010412594830548322, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.1516845703125, Validation_Accuracy: 0.8100000023841858\n",
            "26 th epoch\n",
            "gt [0 1 2 1 0 0 2 2 1 1 2 2 0 0 2 0 2 1 1 1 2 1 1 1 1 2 1 0 1 1 2 0 2 2 0 2 2\n",
            " 2 1 1 2 0 1 2]\n",
            "pred [0 1 2 1 0 2 0 2 1 2 2 2 0 0 2 0 2 1 1 0 2 1 2 1 1 2 2 0 2 1 2 0 1 2 0 2 2\n",
            " 1 0 1 1 0 1 2]\n",
            "27 / 30 Training loss: 0.022860118724681713, Tran_Accuracy: 0.9951851963996887, Validation_loss: 1.1445182291666667, Validation_Accuracy: 0.7933333516120911\n",
            "27 th epoch\n",
            "gt [1 0 2 0 1 0 1 0 1 0 2 1 2 2 1 1 0 1 2 2 1 0 0 1 2 1 0 1 0 1 0 1 0 2 2 0 2\n",
            " 1 2 1 1 2 1 1]\n",
            "pred [1 0 2 0 1 0 0 0 2 2 2 1 2 2 1 1 2 1 2 2 0 0 0 2 2 1 0 1 0 1 0 0 0 2 2 0 2\n",
            " 1 1 0 2 2 1 1]\n",
            "28 / 30 Training loss: 0.02521827980324074, Tran_Accuracy: 0.992222249507904, Validation_loss: 1.0771875, Validation_Accuracy: 0.8233333230018616\n",
            "28 th epoch\n",
            "gt [0 1 2 0 2 1 2 0 0 0 2 0 2 1 2 1 0 2 0 1 1 0 0 0 0 1 2 0 2 1 1 2 0 2 2 2 2\n",
            " 0 0 2 0 0 2 2]\n",
            "pred [0 1 2 0 1 1 2 0 2 0 2 1 1 1 2 1 0 2 0 1 1 0 0 0 1 1 2 0 2 2 2 2 0 1 2 2 2\n",
            " 0 0 2 0 0 0 2]\n",
            "29 / 30 Training loss: 0.016282891167534723, Tran_Accuracy: 0.9959259033203125, Validation_loss: 1.0412890625, Validation_Accuracy: 0.8033333420753479\n",
            "29 th epoch\n",
            "gt [1 1 2 2 0 2 2 1 1 0 1 0 1 2 1 2 2 0 1 1 2 2 0 1 2 0 0 1 2 0 0 0 2 2 2 0 0\n",
            " 0 2 1 1 2 0 0]\n",
            "pred [1 2 2 2 0 2 2 1 1 0 1 0 0 2 1 2 2 0 1 1 2 2 1 1 2 0 0 1 2 2 0 0 2 2 2 1 0\n",
            " 0 2 0 2 2 0 0]\n",
            "30 / 30 Training loss: 0.01142142966941551, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.11078125, Validation_Accuracy: 0.8100000023841858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAEWCAYAAADvpLcuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeZyN9fvH8dfHlr2QFJKSLZEylSLaQwkZIS1a0L7vWnxbtKFSUZGkshVK1rRSWixlqez7LpGdGT6/P64zP0MzY5hzzn3Omffz8ZiHmbPc93UWM+e+7uu6Ps57j4iIiIiIiIiISEbyBB2AiIiIiIiIiIjELiWPREREREREREQkU0oeiYiIiIiIiIhIppQ8EhERERERERGRTCl5JCIiIiIiIiIimVLySEREREREREREMqXkkYiIiOzHOeedcyeHaVu3OefWOue2OudKhWObGezjD+fc+eG+7SHG0N4590O4txuLnHMVQ++RfKGfxzrnbsjObQ9jX4875/rmJN5MtptrXi8REZFwOKw/5CIiIpJzzrnvgNOAY733uwIOJ+ycc/mBHkBd7/2MDK6vCCwG8nvvUw93P977GpG4rWSP975xOLYTSup95L0vn27bXcOxbREREckZVR6JiIgEIJQ4OQ/wwJVh3G4snRgqAxQE/jjcDcTY4xERERHJlZQ8EhERCcb1wM9AfyDDlp80zrkTnXMTnXNbnHNfOefecs59FLourS3oZufcMuCb0OWfOOfWOOf+Dd23Rrrt9XfOve2cmxDa5vfOuRMO2O3Fzrn5zrlNof25TGI7wjn3mnNuVejrtdBlVYC5oZttcs59k8HdJ6a7fqtz7pxQO9GPzrlXnXMbgC7OuUrOuW+ccxucc3875z52zh2VLoYlzrmLQ993cc4Ndc4NCD22P5xzSYd52zOcc7+FrvvEOTfEOfdcVq9Vuvue65ybEnr+pzjnzk13XXvn3KLQdhc759qFLj859Fr8G3qcQzLZ9ljn3J0HXDbDOXeVM68659Y55zY752Y5507NYButnXNTD7jsPufcyND3l4ce+2bn3HLnXJcsHut3zrlbQt/ndc51C8W/CLj8gNve6Jz7K/TYFznnOoUuLwKMBcqG3gtbnXNlQ6/RR+nuf2XoddoU2m/1dNctcc496JybGXoOhzjnCmYW9wFxRez1EhERSQRKHomIiATjeuDj0NdlzrkyWdx2IPArUAroAlyXwW0aAtWBy0I/jwUqA8cA00P7Sa8d8CxwNPB7BtdfAZwJ1AKuTrfdA3UG6gK1sRa8s4AnvPfzgLSE1VHe+wszuG+DdNcX9d7/FPr5bGARVrn0POCAF4Cyocd4PPY8ZOZKYDBwFDASePNQb+ucKwCMwJJ7JYFBQIsstvP/nHMlgdFAT+w16wGMds6VCiVJegKNvffFgHOx5x/s9fgSKAGUB97IZBeDgLbp9ncKcEJon5diz2sV4EjstduQwTa+AKo65yqnu+wa7L0GsA17jx6FJYBuc841z8bD74C9d04HkoDkA65fF7q+OHAj8Kpz7gzv/TagMbAq9F4o6r1flf6OoYTkIOBeoDQwBvgi9FqluRpoBJyIvXfbHyzgKLxeIiIicU/JIxERkShzztXHDvaHeu+nAQuxA/eMblsBS+I85b3f7b3/AUtyHKiL936b934HgPe+n/d+S2iWUhfgNOfckeluP9p7PzF0fWfgHOfc8emuf9F7v8l7vwz4FksOZaQd8Iz3fp33fj3wPzJObh2KVd77N7z3qd77Hd77Bd77Cd77XaF99MCSZZn5wXs/xnu/B/gQS2od6m3rYrMhe3rvU7z3w7EEXnZcDsz33n8YegyDgDlA09D1e4FTnXOFvPervfdpbX0p2PuirPd+Z+i1zsgIoLbbVy3WDhgeei1TgGJANcB57//y3q8+cAPe++3A54SSUKEkUjVC7y3v/Xfe+1ne+73e+5lY0iar5zzN1cBr3vvl3vt/sKRf+v2O9t4v9OZ7LPlyXja2C9Aae99O8N6nAN2AQlhCJ01P7/2q0L6/IPP3bXqRfr1ERETinpJHIiIi0XcD8KX3/u/QzwPJvHWtLPBP6GA/zfIMbvf/l4Vah150zi10zm0GloSuOjqj23vvtwL/hPaVZk2677cDRbOIb2m6n5cesJ3Dsd/jc86Vcc4Nds6tDD2ej9j/sRzowNgLusxnJ2V227LASu+9zyyuLBz4nBD6uVyowqY1cCuw2jk32jlXLXSbh7Eqq19DrVk3ZbRx7/0WrFKmTeiitoQqx7z332DVU28B65xz7zrnimcS50D2VTBdA3yW9j5zzp3tnPvWObfeOfdvKN6snvP0jz3987Tf8+Cca+yc+9k5949zbhPQJJvbTdv2/2/Pe783tK9y6W6T3fdtpttNF3dYXi8REZFEoOSRiIhIFDnnCmHVGQ2dzSRaA9yHVQZlVCGzGijpnCuc7rLjM7hd+iTHNUAz4GKsdali2u4z2oZzrijWmrVfm1A2rcKqL9JUOITt+Gxe3jV0WU3vfXHgWvZ/LJGwGijnnMvwOTuIA58TsOdlJYD3frz3/hLgOKzCpU/o8jXe+w7e+7JAJ6CXc+7kTPYxCGjrnDsHG0r+bdoV3vue3vs6wClY+9pDmWxjAlDaOVcbSyINTHfdQKwK6Xjv/ZHA22TvOV/N/s9ThbRvnHNHAMOwiqEy3vujsNaztO1m9n5Is9/zGnptjif0vOZANF4vERGRuKbkkYiISHQ1B/ZgB/a1Q1/VgUnYjJn9eO+XAlOxwdEFQsmCpgfe7gDFgF3YrJvCWPLlQE2cc/VD82KeBX723me3sia9QcATzrnSzrmjgaewyqDsWI+1BJ10kNsVA7YC/zrnypF5MiScfsJepzudc/mcc82weU7ZMQao4py7JnTf1tjrPSpURdUsNEtnF/a49gI451o559KWqd+IJVP2ZrGPE4BngCGhKhycc2eGqobyY3OLdma2jVDr1yfAK1jycEK6q4thFW87nXNnkUlbZQaGAnc758o750oAj6a7rgBwBPa6pzrnGmMzmtKsBUod0F554LYvd85dFHp8D2DP4eRsxpaZaLxeIiIicU3JIxERkei6AXjfe78sVLmwxnu/Bms1apdJe1U74BwsGfQcMAQ7kM3MAKztZiXwJ7aq24EGAk9j7Wp1sGqew/EcltyaCczChnNna0WyUIvU88CPodWz6mZy0/8BZwD/Yu1aww8z1mzz3u8GrgJuBjZhz88osn7e0+67ARsK/QD2mj0MXBFqU8wD3I9Vu/yDzRG6LXTXM4FfnHNbsaqfe7z3izLZxy7sebiY/SuGimOVMRux98AGLDmUmYGhbXzivU9Nd/ntwDPOuS1YQnDowR53SB9gPDADey/8/2sVare7O7StjVhCamS66+dgychFoffDfu2P3vu52OvwBvA3lkRtGnqtDls0Xi8REZF45/Zv5RcREZFYF1oSfI73/unDvH9/YIX3/omwBpbgnHO/AG97798POhYRERGRaFLlkYiISIwLtSJVcs7lcc41wuYZfRZ0XInOOdfQOXdsqJXpBmzp93FBxyUiIiISbZmtPCIiIiKx41is/acUsAK4zXv/W7Ah5QpVsRarIsAiIDmjZe9FREREEp3a1kREREREREREJFMRa1tzzvVzzq1zzs3O5Pp2zrmZzrlZzrnJmSxPLCIiIiIiIiIiAYpY5ZFzrgG2nOkA7/2pGVx/LvCX935jaKnWLt77sw+23aOPPtpXrFgx7PGKiIiIiIiIiORW06ZN+9t7Xzqj6yI288h7P9E5VzGL6yen+/FnoHx2tluxYkWmTp2as+BEREREREREROT/OeeWZnZdrKy2djMwNrMrnXMdnXNTnXNT169fH8WwRERERERERERyt8CTR865C7Dk0SOZ3cZ7/673Psl7n1S6dIYVVCIiIiIiIiIiEgERa1vLDudcLaAv0Nh7vyHIWERERERERERE5L8CqzxyzlUAhgPXee/nBRWHiIiIiIiIiIhkLmKVR865QcD5wNHOuRXA00B+AO/928BTQCmgl3MOINV7nxSpeERERERERERE5NBFcrW1tge5/hbglkjtX0REREREREREci7wgdkiIiIiIiIiIhK7Ah2YLSIiIiIiIhIr5s2DYcPAeyhUKHtfhQvv+z6fjrAlQemtLSIiIiIiIrlWaiqMHg1vvQUTJuRsW/nyZT/RlJ2kVPHicPbZ9rNIkJQ8EhERERERkVxn7Vp47z14+21YvhzKl4dnn4Wbb4aSJWH7dtix49C+srrP9u2wYUPGl+/dm3mcRYtC06Zw9dVw2WVKJEkwlDwSERERERGRXMF7mDwZevWCTz6BlBS46CJ4/XVL0KRvOzviCChRIjoxpaRknHBaswY+/xyGD4dBg5RIkuA4733QMRySpKQkP3Xq1KDDEBERERERkTixbRt8/LEljWbMsHaw9u3httugWrWgozu4lBT47jtLeA0fbhVMSiRJuDnnpnnvkzK8TskjERERERERSURz50Lv3tC/P/z7L9SqBXfcAddcY8mXeKREkkSKkkciIiIiIiKSK6SmwhdfWJXRV19B/vyQnGxJo3PPBeeCjjB8lEiScFLySERERERERBLa2rXQpw+88w6sWGEDsG+9FW65BcqUCTq6yFMiKfoWLoShQ+HeexPjuVXySERERERERBKO9/Djj1Zl9OmnlkC5+GKrMrriiv0HYOcmSiRFzooVljAaPBimTLHLvvrKBq/HOyWPREREREREJGFs3bpvAPbMmXDkkfsGYFetGnR0sUWJpJxbtw6GDbMV7yZNssvq1IE2bew5rFAh2PjCRckjERERERERiXtz5ljC6IMPYPNmOO20fQOwixQJOrrYl5ZIGjoURoxQIikrmzbZczR4MHz9NezZA6ecAm3bQuvWULly0BGGn5JHIiIiIiIiEpdSU2HkSHjrLfjmGyhQAFq1gttvh3POSawB2NGkRNJ/bd1qw9YHD4Zx42D3bjjpJEsYtWkDp54adISRpeRRrPEe7rsPypWDhx4KOpqYsXcvnHeerYDwyitBRyMiIiIiIkFas2bfAOyVK6016NZb4eab4Zhjgo4useTmRNLOnTB2rCWMvvgCduywQ/XWrS1hlJSUexKUSh7Fossvh99/h6VLc+8UtwN8/jk0bw4lS9ofivz5g45IRERERESiyXv44QerMho2zKqOLr3UWtMuvxzy5g06wsSXWSLp8svh7LOhVi2oWTO+E3gpKdaKNmgQfPaZtUCWLm0VbW3aQL16kCdP0FFGn5JHsSgtUzJihP2by3lvv4hmzLDSwAkTbJUEERERERFJfFu3wkcf2TyjWbPgqKPgxhut0qhKlaCjy73SJ5JGjbKT/GnKlLEkUloyqVYtmwlUsGBg4WZpzx4bdj14sK3Mt2GDDVpv2dISRhdcoLoOJY9iUWoqVKxo/8vGjg06msB99RVccgm89hp07gzXXgtvvx10VCIiIiIiEknTpkHfvrZy2pYtcPrpVmXUti0ULhx0dHKgtWstuTdrlq1yN2sW/PGHtX6BVetUqfLfpNIJJwRTyeM9/PKLJYyGDoXVq22werNmljC69FI44ojoxxWrlDyKVU8/Dc8+C4sWWSIpF7vgApg3z56K66+37PaqVSpLFRERERFJNJs2wcCBljT67TebpZOcDLfdBnXr5p75Molizx5YsGBfMiktsbRo0b7bFC1qiaT0SaWaNaFEifDH4711tAweDEOGwJIlliBq0sQSRldcocRkZpQ8ilXLl1vS6LHH4Lnngo4mMJMnW09pjx42R/yTT2wo23ffQcOGQUcnIiIiIhIe3sNff9khQG47eE2bZdS3r33e37EDateGDh3gmmusTU0Sy5YtVpWUvkpp5kzYuHHfbcqXt2RS+iqlqlUPb/7tnDmWMBo8GObOtRa0Sy6xhFGzZtaiJllT8iiWNW0KU6fCsmW5dkJ006bw0082O7xIEet3PuYYW0XhjTeCjk5EREREJOf++APuvtuWmi9UyFavatHCqiBKlgw6ushZvx4++MCSRnPnQrFi0K4d3HIL1KkTdHQSbd5bh0n6ZNKsWZZUTUmx2+TPD9Wr/7f1rWzZ/1alLVli1UWDB9t6VM7B+edbwuiqq+Doo6P9COObkkexbNQoy54MG2bv7lxmxgw74/Dss/DEE/sub9nSEkorVuTOKfciIiIikhg2bbJpFW+9BcWLw8MP22fczz6z5efz5rVq+xYtbB2d8uWDjjjn9u61maZ9+tg6QSkpcO65VmXUqpWdMBZJb/duG2NyYFJp+fJ9tylRYl8y6dhj7VD655/tunPOsYRRcrIlmeTwKHkUy/bssbrVU06B8eODjibq2rSBMWOs6ih9v+vAgXZG4ocfrKVNRERERCSe7NkD779vEyo2bIBOneyEaVolhPfWgDBihH3NmWOXJyVZIqlFC6u+iCcrVthjfu89+3xfqpTNM73lFjvcETlUGzfC7Nn7z1OaNcta4mrXtuPJ1q1z/QjhsFHyKNb973/QpQssXAgnnRR0NFEzbx5Uq2ZnX158cf/rNm+G0qVtpYUePYKJT0RERETkcPz0E9x1l60kVr8+9Oxpq4hlZc4cq0YaMQJ+/dUuq1p1X0XSmWfGZkV+SgqMHm1taWPHWtXRxRdbwqh5c61kJeHnvVX0RWLYdm6n5FGsW7HC1i58+GF44YWgo4mam2+2CqMlS6BMmf9ef+WV1re6dKlWXBARERGR2Ld6NTz6KAwYYK0zr7xiS84f6mfZFSus3euzz2wRmdRU217z5pZMatgw+HGpCxZYhVH//rBmDRx3HNx0k33lovPhIglFyaN40KyZNWwuXw4FCgQdTcQtWwaVKsGtt2Y+FHvAALjhBvjlFzjrrOjGJyIiIiKSXbt3W3XRM8/Arl1w//3QubMtT55TGzfabJcRI2DcOFul7KijbNB2ixY2eDtaM4R27rQ4+vSBb7+1SqjLL7cqoyZNbHUrEYlfgSSPnHP9gCuAdd77UzO43gGvA02A7UB77/30g203YZNHY8bYb95PPrEpXwnu7ruhd2/r1KtQIePbbNxoq67ddx+8/HJ04xMRERGJNxs3WvJi+3YbzHzkkfZv+q8DLytcWBXeOTVuHNxzj41kuOIKG7lQuXJk9rV9O0yYYAmcL76Af/6BggUtgdS8ua3DU6pU+Pc7e7a1pX34oe3zxBOti6B9eyhXLvz7E5FgBJU8agBsBQZkkjxqAtyFJY/OBl733p99sO0mbPJozx6r76xSxf4iJLB166xLr21b6Ncv69s2bmxLei5cqA82IiIiIplZtsw+N82bZ8mDzZutQuVg8ub9b4IpoyTTwRJRuTEJtXChVRiNHGnJotdes+qbaElNhYkT981JWrHCXs8GDawiqVmzzE/SZsfWrbYEet++1iCRP79tt0MHuPDC2Jy/JCI5E1jbmnOuIjAqk+TRO8B33vtBoZ/nAud771dntc2ETR4BPPccPPkkzJ8PJ58cdDQR8/jjNiD7r79sCGBW3nvPymCnTz/4kEERERGR3GjmTEscbdtmiYTzz7fLd++2FYk2b9739e+/+/+cncuyk4TKk+e/CaUSJeCii2xp9kSqTtm2Dbp2hW7dbNrEk09a5VGQg6G9t+HcaSu3/fWXXV6nzv4rtx0swZe2AlyfPjBokCWQqle3z+PXX79vpTgRSUyxmjwaBbzovf8h9PPXwCPe+ywzQwmdPFq1yk4PPPAAvPRS0NFExKZNVnXUqJGdyTiYv/+GY4+FRx6B55+PfHwiIiIi8eSbbywxUKyYrXRVs2b495GSYkmoQ008rV5tSQzn4LzzbEnt5GRbUTceeW+fXx98EFauhGuvtY/sZcsGHdl/zZ27ryLpl1/sssqV9yWSzjpr/8qhjRvh448taTRzJhQqZMuf33ILnHtu7qsqE8mt4j555JzrCHQEqFChQp2lS5dGLObAtWgBP/5odacJODj7+efhiSfgt9+gdu3s3eeSS2zFtblz9YdLREREJM3AgTZzpmpVSxyVLx90RP81b54lXAYNskRS3rxWjdS6tX3sjZeltmfMgLvugkmTrBr+jTegXr2go8qelSuttW7ECBtynZpqK6M1a2YtbmPGwKef2jDsM86wtrS2ba2KTERyl1hNHqltLSPjxlnd8eDB9lc1gWzbZlVHZ58No0dn/35vvw233WZnQSJxNk1EREQknnhvS8A/8oi1qI0YYatvxTLvbejykCH2MXfhQpuh06iRVSQ1bWrVU7FmwwZ46in7PFqihLWr3XyzJcHi0caN9jk8beW2tOHq7dpZldEZZwQdoYgEKavkUZBjzkYC1ztTF/j3YImjXOHSS6FiRXj33aAjCbs+fewPcOfOh3a/Fi2s4mjYsMjEJSIiIhIv9uyx+TqPPGLnGceNi/3EEdhnuZo1bcTn/PkwZYo9jt9/t8TFMcfYbKRPP83ejKVI27PHVgauUsUSR3fcYXF37Bi/iSOwBNi119rn6r//toaH1auhVy8ljkQka5FcbW0QcD5wNLAWeBrID+C9f9s554A3gUbAduDGg807glxQeQR2SqNzZ6vzjdQ6n1G2axdUqmRzwL/77tDvf/759gdu9uxwRyYiIiISH3bssAP/4cNtRObLL8f/ild798JPP1k10iefwNq1ULSotVS1aWPnVaM9yWHSJGtRmzHDPoP27KnqdxHJHQKpPPLet/XeH+e9z++9L++9f897/7b3/u3Q9d57f4f3vpL3vmZ2Eke5xk03Qb58CVV9NGCA9Vs//vjh3T85Gf74Y9/KESIiIiK5yT//2BzIESNsSfhu3eI/cQT2GOrVsxlCK1fC11/bvJ2xY62VrUwZaxObMMFm9UTSypVwzTU2B+iff2DoUBtIrsSRiEiEZx5FQq6oPAJo2RImTrTB2UGu+xkGqalQrZqVyf766+ENvV650oZAPvusDdwWERERyS2WLLGRmIsXw4cfWntXoktJga++soqkESNstbfSpe2EYps2UL9++JJnu3ZBjx62sEtqKjz8sLUFFikSnu2LiMSLWJ15JFnp1Mn6tIYPDzqSHPvkExuK+Pjjh79aWrlytkyo5h6JiIhIbvL773DOObBmDXz5Ze5IHIEN027cGD74ANats4/EF14I/ftDw4ZQoQLcd58tQ3+458K9h1GjoEYN+5x6ySVW5f7MM0ociYgcSMmjWHXxxXDSSfDOO0FHkiN799oIp1NOsd71nEhOtg9QCxaEJzYRERGRWDZhApx3niVSfvjB2qlyo4IFbQGVwYMtkTRoEJx5pg15rlvXPjI/+qh9TsxuImnePLj8cmuNy58fxo+3CqcTT4zsYxERiVdKHsWqPHmgQwf4/nuYOzfoaA7bqFE25Pqxx3JeWtyypf2r6iMRERFJdAMGQJMmlhj56SerjhEbpt2mjSV61q2zSqRq1WwG1OmnQ/Xq0KVL5nMyt2yxlrRTT7WVxnr0gJkzbTC3iIhkTjOPYtnatTbo5+67oXv3oKM5ZN7b2aD16+3sTr58Od/mWWfZdqdMyfm2RERERGKN9/DCC7bw7kUX2UmzI48MOqrYlzbtYfBgW9nXe6hVyxJNrVtDxYrw8cc2z2jNGrjxRnuey5QJOnIRkdihmUfxqkwZq9Ht3x927gw6mkP2zTc2IPuRR8KTOAJrXZs61QZHioiIiCSSPXvgjjsscdSuHYwZo8RRdh19NHTsaJ8/V66E11+3KqXHH4dKleD44+H6621W0i+/QL9+ShyJiBwKJY9iXceOtlZoHPZqde0Kxx0HN9wQvm2mta4lwBxxERERkf+3fbt9zund2068DRgABQoEHVV8Ou44K9z/8Uc74fjyy1C7tiWMfvrJKtlFROTQqG0t1u3dC1WqQNmyMHFi0NFk288/28og3brBAw+Ed9tnnGGDEydPDu92RUREJGveH/7KqZK5v/+2wc2//AI9e8KddwYdkYiI5EZqW4tnefJY9dGkSfDnn0FHk21du0LJktCpU/i3nZxsZ41WrAj/tkVERCRj8+bZKMZXXgk6ksSyaBGce66tFPbpp0ociYhIbFLyKB60b29riL77btCRZMvMmfDFF3DPPdZrHm5qXRMREYmuXbts8PCqVTZwOA676WPStGlWqf333/DVV3DVVUFHJCIikjElj+LBMcfYp4kBA2DHjqCjOagXXrCk0V13RWb7Vava8qr64CoiIhIdjz8Ov/0GQ4dasuO662wBCzl848ZBw4ZQqJC14terF3REIiIimVPyKF506gQbN1o9cwybP98+WN5+O5QoEbn9JCdbJ9+aNZHbh4iIiMDYsdCjh7VTtWoFI0bYea0rr1QL+eF6/3244gqoXNla8atVCzoiERGRrCl5FC/OP98+YbzzTtCRZOmll6zD7r77Iruf5GQb2jliRGT3IyIikputWWOrptasuW/WUZkyMGoUbN1qCaRt24KNMZ54D88+CzfdBBdeCN9/byuDiYiIxDolj+KFczY4+8cf4Y8/go4mQ8uXW2fdLbfAscdGdl+nnGLtazFeiCUiIhK39u6F66+3JNHgwbbSaZpTT7XLZsyAa6+120rWUlOtkPypp+x5HTUKihcPOioREZHsUfIonrRvDwUKxGz1UffudkbtoYcivy/nrPro++9h/frI709ERCS36d4dJkyA11+3kzYHatLE2tk++8xmIknmtm2DFi2gTx97rvr3t490IiIi8ULJo3hy9NG21NiAAbB9e9DR7GfdOlsMrl07OOGE6OwzORn27IHPP4/O/kRERHKLKVMsyZGcbBXFmbn7bqumeeklS4jIf61bZy1qY8ZA797w/PN2EkxERCSeKHkUbzp1gn//hU8+CTqS/bz+OuzcCY8+Gr19nnYaVKqk1jUREZFw2rwZ2raFsmXtxFBWiQ7n4I034KKLrLt+4sToxRkPFiyAc8+FWbNg+HC49dagIxIRETk8Sh7FmwYNbEmOGGpd27QJ3nzTiqKiuVqIc7bPr7+2hehEREQkZ7y3FVMXL4aBA7O3cmr+/HZO66ST4KqrYOHCyMcZD3791RJHmzbZZ5VmzYKOSERE5PApeRRv0gZn//STncaKAb162VnKIOYdJCfbAMqRI6O/b6gtluUAACAASURBVBERkUTz4Yfw8cfQpQvUq5f9+5UoYQOgvbcl6DdtiliIcWH0aLjgAihaFCZPhnPOCToiERGRnFHyKB5dfz0ccURMVB9t3w6vvgqNG8Ppp0d//0lJUKGCWtdERERyat48qzpq2PDwTgidfLK1Zi1cCFdfbSd3cqO+fa3KqHp1O9dXpUrQEYmIiOSckkfxqFQpK7n58ENbviNAffrA338Ht8pK2qprX35po6BERETk0O3ebXOOjjgCPvoI8uY9vO00bGjntiZMsGHa3oc3zljmPTz9NHToAJdcAt99B2XKBB2ViIhIeCh5FK86dbJesSFDAgth92545RUbw1S/fmBhkJxssYwaFVwMIiIi8ezxx2H6dOjXD8qXz9m2brwRHnrIVhZ7883wxBfrUlJsVbpnnrHHP3KktayJiIgkCiWP4lX9+lYPHWDr2ocfwsqVwVUdpTn7bFsRRq1rIiIih27cOOjeHe64I3xDnV94wbZ17722/US2aZM91n794Kmn4L33bIi4iIhIIlHyKF45Z9VHv/4Kv/8e9d2npsKLL0KdOnDppVHf/X7y5LFV18aNg61bg41FREQknqxZAzfcADVrWjVxuOTNa+1vtWrZ/KPZs8O37Vgyc6bNX5wwAd59F/73P/uIJiIikmiUPIpn110HBQvap5Uo+/RTWLDAqo5i4UNScjLs3AljxgQdiYiISHzYu9cSR1u2wODBUKhQeLdftCh88QUUKQJNm8K6deHdftAGDIC6dWHHDptv1KFD0BGJiIhEjpJH8axkSWjVyk7tRbHkZu9e6NrVuuaaN4/abrNUr54NpVTrmoiISPb06GELTrz2GpxySmT2Ub68zf9ZswZatLATPfFu1y649VZLvJ19ts2Kqlcv6KhEREQiK6LJI+dcI+fcXOfcAufcoxlcX8E5961z7jfn3EznXJNIxpOQOnXad8owSkaPhlmz4LHHrGUsFuTNax9KR4+G7duDjkZERCS2TZlif8dbtox8xcyZZ1qVzuTJtq94XoFt6VIbO/nOO/DII9auphXVREQkN4jYob9zLi/wFtAYOAVo65w78LzWE8BQ7/3pQBugV6TiSVjnngs1akRtcLb38PzzULEitGkTlV1mW3KyJY7Gjw86EhERkdi1ZQu0bQvHHQd9+kSn/bxVK3j2WSuW7to18vuLhPHj4YwzYN48GDHCZj/myxd0VCIiItERybqRs4AF3vtF3vvdwGDgwDU8PFA89P2RwKoIxpOY0gZnT51qddMR9u238Msv8PDDsbeSSMOGUKqUWtdERESycvvtsHgxDBwIJUpEb7+dO0O7dvDEE/H1t3rvXhuE3bgxlCtnH7lipW1fREQkWiKZPCoHLE/384rQZel1Aa51zq0AxgB3ZbQh51xH59xU59zU9evXRyLW+HbddTblMgrVR127wrHHwo03RnxXhyxfPmtd++KLxJipICIiEm4ffmjVP08/be1X0eQc9O1rRdPXX29JmFi3YQNcfjl06QLXXgs//wyVKwcdlYiISPQFPbGmLdDfe18eaAJ86Jz7T0ze+3e990ne+6TSpUtHPciYd9RR0Lq1nULcsiViu/nlF/j6a3jgAVvkLRa1bGlPwYQJQUciIiISW+bPt6qjBg2sCigIBQtay1eZMnDllbBiRTBxZMfUqVCnDnzzDfTuDR98AIULBx2ViIhIMCKZPFoJHJ/u5/Khy9K7GRgK4L3/CSgIHB3BmBJXx4624tqgQRHbRdeuVt7eqVPEdpFjF15oubRhw4KOREREJHbs3m1zjgoUgI8/toUmgnLMMVYlvHUrNG0a1QVjs8V7ePddW0HNe5g0yVZXi8ZsKBERkVgVyTF/U4DKzrkTsaRRG+CaA26zDLgI6O+cq44lj9SXdjjq1oWaNa11rWPHsG9+1ixbardLFyhWLOybD5sCBaBZM/j8c/ugXKBA0BGJiEh2bNhgrUwbN0LZspl/HXmkDuIPR+fOMG2aVf2ULx90NHDqqTBkCFxxhXXfDxsWGyu4bt8Od9wB/fvDpZdaou1ondYUERHB+Qiul+qcawK8BuQF+nnvn3fOPQNM9d6PDK2+1gcoig3Pfth7/2VW20xKSvJT46FJPghvvQV33mnr7yYlhXXT11xjZwmXLoWSJcO66bAbNcrOZI4dC40aBR1NYlm50j5Qn3SSdUrGwgd9EYl/u3fDJZfYPJl69WD1ali1CjZv/u9tCxXaP5lUrlzGSaYiRaL/OGLV+PH29/D22+2jQizp2RPuuceWvX/xxWBjWbjQ2t9nzICnnrKvICu0REREos05N817n2EyIaLJo0hQ8igL//5rn5ivucbW3g2TBQugalWbdfTyy2HbbMTs2gWlS8PVV9tgTsm5mTOhe3frikxJscuSkqBHDzjvvGBjE5H45j20bw8DBliVxzXpapS3bt2XSMrsa+VK2LHjv9stXjzrCqa0ryOOiNpDDcTatVCrlrWK/fqrJd9iifeW1Hr7bejXL7gFOUaOtMq3PHlsoHiTJsHEISIiEiQlj3KTm2+2OvBVq+yTcxh07Ggf6hcvhuOOC8smI65dOzvTumaNrcImh857GzzerZv9W6SIvb3uvhsmT4bHHrODtpYt4aWXoFKloCMWkXj0/PO2dHuXLrYC2KHy3iqUMkoqHXhZWvI7vVKlMk4qlSsHF10ERYvm+CEGZu9eS4J8/70Nf65RI+iIMpaSsi/OCROgYcPo7Ts11SqMXnjBhmN/+ilUrBi9/YuIiMQSJY9yk19/hbPPtmVBbr01x5tbscJalG65BXr1CkN8UTJiBFx1FXz1lX34l+zbvdsqjLp3t1lXxx0Hd91lg9LTtyxu3263efFF++B/9912AHjUUcHFLiLxZcgQaNPGlkAfMCCys4y8t7lKWVUxrVplJx327LH7HHecJcfbtYvPNt3u3eHBB62qJ5YXuwDYtAnOOQfWrbPVXU8+OfL7XLfOhoh/8w106GAtdLG6mqyIiEg0KHmUm3gPZ5xh30+fnuNP4vfdB2+8Ya1r8XQmbscOa1277jrLo8nBbdxoq8v07GkHUKeeaq2Kbdtm3daxahU8+SS8/74ll7p0sYOU/PmjFrqIxKGffoILLoAzz7REf6y0j+3ZA+vXw+zZVmE5daqtSdGzp8UaL6ZOhXPPtRmAn34aH0PGFyyw81/HHGPvj0iejPjpJ2jVyhKKvXoF1y4nIiISS7JKHsXheTTJknPWZ/b77zY4OwfWr7fF29q1i6/EEdhMh8svh+HD951BlowtWQL33gvHHw+PPgqnnALjxtmco/btD35AV7YsvPee5SpPO82qlGrWtMHlcZabFpEoWbTIVsYsX94qRWMlcQQ2IPnYY+Hii60Cpl8/a9s++2xr3V27NugID27LFkv8H3usjUCMh8QRWLXR8OE2uPrqqzNuM8wp7+2kWIMG9r776ScljkRERLJDyaNE1K6dDah5550cbeb112HnTksoxKOWLa0k/Ycfgo4kNk2ZYiumVapkq+9cdRX89pvNm7jsskM/2Khd26oHRo60D+dNm9rqSTNmRCZ+EYlPmzbZ8uypqTB6dGwvg54njyUW5s2zSswBA6BKFWsH27076Ogyd8cdlqD7+OPYXyH1QA0b2seXCROsHTqcJyG2brWPSHffDY0bW3VW7drh276IiEgiU/IoERUvbqccBw+2FdgOw7//wptvWkKhevUwxxclTZrY7IJhw4KOJHbs3WvJnYYN4ayzrMLowQftrPqAATn/EO2cJY1mz7YWj99+g9NPt5lZq1eH5zGISPxKSYHkZGtPGj7cVvKMB8WLwyuv2O+2evXs92atWjB2bNCR/deHH9rX00/H72qYN94IDz9ss5reeCM825wzx6rHhgyxIe2ffQYlSoRn2yIiIrmBkkeJqlMnm2j80UeHdfdevSyB9NhjYY4riooWtTOLw4ZZ0iQ327HDzuRWr26tIkuWQI8esHy5DYMtXz68+8uf39rXFiywuVkDBkDlyvDcc/a2FJHcJ21J9q+/tvlq558fdESHrmpVGDPGKqbSVjK74gqYPz/oyMyCBfYcN2gAnTsHHU3OvPACNG9uf0NymqT79FObV7Vuna3E+vjj8TkAXUREJEj605mokpJscPY77xxyzff27fDqq9CokS1bG8+Sk22g888/Bx1JMNavh//9DypUsMX3ihWzldQWLrQP5MWLR3b/JUpYe8eff1or3JNP2sHXRx8poSeS23TrBn372oF7+/ZBR5MzTZpYFdIrr8DEiVCjhlXKbN4cXEy7d1vRcf789js2b97gYgmHPHnscZx2mrVYz5596NtISbF2w1atbBGI336zWVYiIiJy6JQ8SmSdOtla67/8ckh3e+89Szo8/niE4oqiK66AAgXsrGNuMneuJYsqVLDVz+rWhe++szlHbdpAvnzRjefkk60C7PvvoUwZWwXv7LNh0qToxiEiwRg+HB55xIYgP/ts0NGER4EC1r42b57N0XnlFUuOf/BBMMnxJ56wGT7vvWcLICSCIkWs1bpoUWuJXrcu+/ddvRouusiqbO+6y/7+hLvKVkREJDdR8iiRtW1rn7gOYXD27t3w8stQv378zkpIr3hxuPRSS1wk+spf3lsyplkza0/r39+SNH/+CV98YXOOgl5xp0ED+PVXa2Nbvdp+Tk62SigRSUxTpsC111rCuH//xGsXOvZYeP99O09zwglWVXXOOYd83iZHvvzSkle33QYtWkRvv9FQvrwlkNautce2c+fB7zNxos3bmzbNhob37GnJPhERETl8CfYRTvZTrBhcc41Nh9y0KVt3+egjWLEi/mclpJecDMuW2RnZRJSaCkOHWnVRgwbw4492BnrpUpsrEmsDz/PksaTWvHlWgTBunMX44IPZfpuKSJxYtgyuvNIqDj/7DAoVCjqiyDnrLJg82SqPli2z38nt20d+sYC1a+H66611rnv3yO4rKElJdtJh8mRbgCGzk0HeW3vkhRfCkUfayYprrolurCIiIolKyaOARK0KplMnm5b84YcHvemePfDiizYq6bLLohBblFx5pbVpJVrr2tatdja1cmWbB/HPPzbofNkyeOYZO1iLZYULW5Jr/nw78OnRw9rb3nzT5lSISHzbvNlah7dvtwHTsf47KRzy5LHfZ/PmWZveoEFQpYpV9O7aFf797d1rCap//7UFVhM5OZecbIsufPwxdO363+s3b7bbPPSQDdqeMsUSaiIiIhIezsdZL09SUpKfmgAlJOedZ737lSvv/1Wlis0qCGtZ/5lnWgJp1qws+5aGDLF5OJ9+Ci1bhnH/MaBxY/swv2BB8K1bObVqlS1d/PbbVqmTtmx006bxPSD1999tsOk339jckG7d4PLL4//1EsmNUlMtcf/ll7ZS1iWXBB1RMBYsgPvvt9bhk0+2xSjC+XutRw/7vdm7t825S3TeW3Luo4+s4rZVK7t89my46ipYtMgSdffdp78dIiIih8M5N817n5ThdUoeBaNrV5g+3aouFizYf/nyI46ASpX+m1iqXBnKlTuMD0R9+0KHDvDDD5ZpyID3ULu2zTz644/Em0mR9hT89ps9zng0a5a1JAwcaFViV11lBw116wYdWfh4D6NG7RtCe9FF9phPOy3oyEQku7y3AcVvvWWtsx06BB1R8MaNg3vvtcUMGjWC116zJHlOTJtms5WuuMLm+uWWZMmuXdaWNn26zTaaNw86drQZh0OHJsa8RhERkaAoeRTjvLdqkvnz7UPQ/Pn7vhYu3L/UvXBhO3uZUWKpTJlMPjxu3Qply9qkyQ8+yDCGUaOscqV/f7jhhog8zED9/bcNNX30USt7jyc7d9qZ1k8+sdf/5pvtIOSkk4KOLHJSUqyyqksX2LgRbrrJ5iMdd1zQkUk8+/dfK8IsWtRWccotB9vR1rMn3HOPJYFfeSXoaGJHSoq15XbpYieM7r4bnnrKZvMcqi1brMV8506YMQNKlgx7uDFt3TobwL5+PWzbZgmjIUP0N0JERCSnlDyKY3v22ADrjBJLixZZa0CaYsUyTipVrgylnrgN90F/y1KVKLHfPryHc8+1oZ7z50P+/NF9jNFy8cWwfDnMmRM/B40pKdZC+MUX8OSTljTKTQcJGzdasu+NN2ylnEcftRaQwoWDjkziybp1Vu3Zu7dVV4L9DihSxBJJxYrt/29m3x/s+iOOiJ/fLZEyapSt+HjllVYNk2hVrOGwbh08/jj06welS8MLL9jcokN5rm64wVq3vvsu91ba/PGHtQC2amX/vxP1s4uIiEg0KXmUoFJTbUWttGRS+uTSkiU2SDPNUcVSqbxlOlXqFKdy02r7JZZ+/x0uuMBaDG6/PbCHE3Fvv23LGM+aBaeeGnQ0B7dnD7RrZ2dT33wT7rgj6IiCs2CBDZ8dPtyWbX7hBVtBRwemkpV//7XZWa++ahVH7dvbqk1bt9rXli0Z/3vg9+l/l2YlX77sJ5+KF7ckS6VKEX0Kour336F+fahWDb7/3pJzkrlp06z6aPJke1/27GltaAfz0Ue2YmWXLvD00xEPU0RERHIRJY9yod27YfHiA5JKA39l/vbyLN9zHN7vOz2eP79VsyxenNgrtaxZY917Tz1lH7pj2d69thzx++/DSy/Bww8HHVFsmDjRKo+mTbODrR49cu9Zd8ncjh2WcH3xRVuFsFUra3s8nBkz3tv2DpZkOpTLduywbR9xBHTubP+/jzgivM9BtK1caW1Eztny6Gofyh7vbY7dww9bYfC119rv/LJlM779woU2t+/0021xgXz5ohuviIiIJDYlj8T06wc338yOCT+w6Lh6/59YWrDA5h01bRp0gJHXsKEdTM6aFXQkmfPe5oW88Ya1qj3zTNARxZa9e+1g67HHrKWzdWtLImV2sCW5R0oKvPeeJYpWrbLBxM8/b7NhYklaO/Ijj1hlYZUq1lJ34YVBR3Z4tm6FBg3sJMWPP0KtWkFHFH+2brWKym7d7IRO5862YljBgvtus3u3VXYtWGBVXhUqBBeviIiIJKaskkdq+shNWreG4sUp1L83NWpA8+Z2tvPdd3NH4gggOdmW9J0zJ+hIMte5syWO7r8f/ve/oKOJPXny2Nn5uXOtguyzz6xN5vXX958BJrnH3r3w8cf2PrjtNqhY0dqmxo6NvcQRQN68cMIJMHiwrcKVmmorC153HaxdG3R0hyatvXbGDEuEKXF0eIoWtUTnX3/BJZfYTKQaNWDkSDuhAHYyYcoUWz1UiSMRERGJNiWPcpMiRezo5NNPYcOGoKMJxFVX2b/DhgUbR2a6drWzz5062Rno3D58NyuFC9u8jz/+gHr1bJj4mWfCzz8HHZlEi/c2TL52bUsoFitmA5t/+MEqYeLBZZdZQvvJJy35Uq2azWfL7pyloD30kCU4Xn8dmjQJOpr4d9JJMGIETJhgVUfNmlkF3TvvwMsvw6237vs7JiIiIhJNSh7lNh07wq5dMGBA0JEEolw5W1nu00+DjuS/Xn/dqo6uvRZ69VLiKLsqVYIxY+w1Xb/eXt9Onaw9URLXd99Z0vDKK22G0KBBMH26rb4Ub/93ChWy9tSZM22WzW232fv499+DjixrvXvbMPK774Y77ww6msRy8cX2+r/2GvzyiyWNatSwFl0RERGRICh5lNvUqgV169ppzDibdxUuLVvah/KFC4OOZJ++fa1ypkULG5KtVcQOjXP2uv71l7X7vfeeDUfu3z/Xvs0T1tSpVq1zwQWwbJn9KvvzT2jTJv7/31SrBl9/batpLV4MderY+3nLlqAj+6/x4+GuuyxZp4RGZOTPb/Pv5s+35OJnnyX2ohYiIiIS2+L8o7Yclk6dbGDMxIlBRxKIli3t31hpXRs0yArCGjWy77V6zuErVsza/aZPtyHEN95o7UuzZwcdWXQtWQJ//x10FOH11182s+zMM221vW7d7KC6Y0c7yE4UztkMoTlz7LG99hpUr26/r2IlETp7tq1gd+qp9jsrb96gI0pspUtbW+PJJwcdiYiIiORm2UoeOeeKOOfyhL6v4py70jmXQB/Xc5mrr4Yjj7RT9rnQCSfYAWgstK59/rmNoWrQwA4O43257lhRqxZMmmQVSH/9ZTNxHnrIVjRKVN7Dl19aVc6JJ8Ixx0BSkq1K9+231q0aj5YuhZtuskTF+PE252rRInjggcSuwihRwtrCJk+Go4+2xNkVV1hFUpDWrLFqo6JFbb5UsWLBxiMiIiIi0ZHdyqOJQEHnXDngS+A6oH+kgpIIK1wYrr/eshWJVp6QTcnJtmrN0qXBxfDll5bHS0qyob+FCwcXSyLKk8eSDnPnWgVSt25WwTF8eOxUcITDrl3WnnfaaZY4mjULnnvO2lwKF7bHfeGFULKkDTR+9VUbMh7rz8HatdayU6UKDBxo3y9aZCvsFS8edHTRU7euter16GEryNWoYUP1d++Ofizbt9sA57//tt9Z5ctHPwYRERERCUZ2k0fOe78duAro5b1vBdQ46J2ca+Scm+ucW+CcezST21ztnPvTOfeHc25g9kOXHOnUyY4++vcPOpJApLWuDR8ezP4nTYLmzS2ZMXaszt5HUqlS0KcP/PijJVBatrQKjkWLgo4sZzZssKW9K1a05BjYf+fFi23w+hNPWGfqP//Yalg332yP+f77rYqnfHlo394SM+vWBfhADrBpk8VeqRK89ZbluefPt+RJ6dJBRxeMfPngvvusiq5xY1vGvXbt6HYe791rr8WUKfaeqVMnevsWERERkeA5n43Tz86534DbgVeBm733fzjnZnnva2Zxn7zAPOASYAUwBWjrvf8z3W0qA0OBC733G51zx3jvszyMSUpK8lOnTs3GQ5ODql/fjhrnzo2/5YnC4PTTrTLjxx+ju98pU+Cii6BsWTv4O+aY6O4/N0tNhTfegKeesu87d7Z2tnhqF5w/3+bgvP++rTJ22WXWwnXxxdn7b7xsmS0DnvaVtipd7dpwySVw6aX2q6Fgwcg+jgNt326vzUsvwcaN0Lq1VU9VqRLdOOLB6NG2utmSJZYAfPnlyCfWHnsMXnwRune3BKSIiIiIJB7n3DTvfVJG12W38uhe4DFgRChxdBLw7UHucxawwHu/yHu/GxgMNDvgNh2At7z3GwEOljiSMOvY0Y5Ev/su6EgCkZxs80RWrozePmfOtIP9o4+2VZWUOIqutAqOOXOgaVMbQlurlr0Wscz7fdVqVava6nxt21qL2rhxlvTJbv63QgWrQho82HLHU6ZA165w1FGWlLrkEpu3c9ll1vI2c2ZkW9x277bZPiefDI8+am1a06dbfEocZezyy6318LHHbGW2atXsPbF3b2T216+fJY5uvdX+/4iIiIhI7pOtyqP97mCDs4t67zcf5HbJQCPv/S2hn68Dzvbe35nuNp9h1Un1gLxAF+/9uAy21RHoCFChQoU6S4McVJNIduyAcuWs1GDw4KCjibq5c+2gq2dPW3I60ubNg/POs5WhJk2yocYSrHHjrIJj4UJLxnTvDscdF3RU+6Sm2miy7t0tyVOqFNx2G9xxBxx7bPj3t22bzdWZMMFmcv0ZqhMtU2ZfVdLFF4fnOdqzx1bqShuAXb++JbHOOy/n285N/vjD3hOTJsG558Lbb0PNTGuCD90331gi8cILbUB2Iq1sJyIiIiL7y3HlkXNuoHOuuHOuCDAb+NM591AYYssHVAbOB9oCfZxzRx14I+/9u977JO99UuncOvQiEgoVsiEWw4fH1tCTKKla1YbPRmPVtSVLrFXNe/jqKyWOYkWjRrbs+NNPW5KmWjVrndqzJ9i4Nm+2wdYnnwxt2tgcoF69rOXs2WcjkzgCKFJk/6HaK1ZYe9xFF9lKZ9dfb+2WtWpZq9z48dZudii8t1UGa9e2lQaLF4cxY6yFU4mjQ1ejhiX83n/fEuKnnw4PP2yJwJyaM8dmhFWtCkOHKnEkIiIikptlt23tlFClUXNgLHAituJaVlYCx6f7uXzosvRWACO99yne+8VYFVLlbMYk4dCpE6Sk2PJMO3cGHU3UJSfbGfu1ayO3j1Wr7OB72zZLHFWrFrl9yaErWNBW8Jo921qm7r4bzjwTfv01+rEsWwYPPgjHH29zZU44wRItc+ZYdUm0V+QrV85m6nz8sS3RPn26zSQ65hgbZt2okbW4XXyxXf7bb1m3Tn37rVXHNG9uq8QNHgzTptkQ6Fw4di1snLPXae5c+/eVV+CUU2xQ+uFav97a4woUsIqjI48MV7QiIiIiEo+ymzzK75zLjyWPRnrvU4CD9btNASo75050zhUA2gAHfpT9DKs6wjl3NFAFiPM1kOJM9epW2vDGG3DSSbakUThOWceJ5GSrhBgxIjLbX7/eDqzXrbMWqVq1IrMfybnKle01GjLEEiV169qMl40bI7/vqVPhmmvsv+Brr1n1z5QpVlFy5ZWQJ7u/qSMoT559VS1ffWWDtseNs5bPdetsXtEZZ1hV1DXXWCXMihV23ylTrOXtwgvtsj59rLKpdevYeGyJolQpm330ww9W0dWsmSXqli07tO3s3Gn3W7XKElAVK0YkXBERERGJI9n92P4OsAQoAkx0zp0AZDnzyHufCtwJjAf+AoaGhm0/45y7MnSz8cAG59yf2ADuh7z3Gw79YUiODBxoR4PVq1svygknWCXSpk1BRxZxNWpYS0YkWtc2bbID5iVLbHWks84K/z4kvJyDq6+2Sp977rEkR9Wq8MEH4R8avXevHZg3bGiVTqNGwb332vyfQYMgKcNO49hRuPD+Q7VXrYIBA+yyb76Bm26yCqoTT7T3/m+/WW56/ny45Ra1QEVSvXpWJfbyyza/qnp1q0ZKSTn4fb23127yZPjwQzj77MjHKyIiIiKx75AHZv//HZ3LF0oQRVVSUpKfOnVqtHebe/z8Mzz/vB3JFitmk3nvuy+hlwV74glbSWjNGlsFLRy2brUBw9OmwRdf8kc6NAAAIABJREFU2AG1xJ/ff7d2sZ9/hgYNbO5QjRo52+b27ZZkefVVG6JeoYIlqm65xapFEoH3thLchAk2y6hOHUuMJcrjiydLl1or5siRcOqpNlC7Xr3Mb//00/DMM/DCC1ZNJiIiIiK5R1YDs7OVPHLOHQk8DTQIXfQ98Iz3/t+wRZlNSh5FyYwZtvTRJ5/YUJgOHeChh6B8+aAjC7vffrN2m759bQnznNqxw2aFTJxoT1+LFjnfpgRn71547z145BHYssVmET31lA2XPhRr1ticoN69YcMGqyx64AFrncyXLzKxi6T5/HNrMVy+3BKVL75obW7pffSRDTG/6Sb7fag5VCIiIiK5S45XWwP6AVuAq0Nfm4H3wxOexKTTTrPhL3/9ZTORevWygSwdOsCCBUFHF1a1a9tDC0fr2u7dlgz47jtrdVLiKP7lyWNv+7lz7cD65ZetDeizz7LXyvbHH5aUPOEEK+qrX98Si7/+av+1lDiSaGjWDP78084BvP++De7v33/fe3jSJHufXnCBJTiVOBIRERGR9LKbPKrkvX/ae78o9PU/4KRIBiYxompV6NfPEkYdO9oQjKpVbSLu7NlBRxcWzlnC56uvcjYcOTXVnpYxY+Cdd6Bdu/DFKMErXdr+K0yaZCtPtWhhw6wXL/7vbb23lq3Gja1VaNAgOzCfM8eSTuedp4Nzib6iRS35OX06VKkCN94I559vXcrNm9t8qmHDbIU1EREREZH0sps82uGcq5/2g3OuHrAjMiFJTDrhBHjzTZv+/MADNsinZk074pgyJejociw52ZI/h7u09d691uoxbJjNsunQIbzxSeyoX98Ovrt1s6Xna9SwDs/du+3rgw+smu3SS60l8rnnrFWoVy87YBcJWq1algTt08dmUzVtahV2o0dDiRJBRyciIiIisSi7M49OAwYAR4Yu2gjc4L2fGcHYMqSZRzHin3+gZ0/72rjRpkM//rgtHRWHJRXe23LUp5126Akk7+H2220Q7bPP2gBuyR2WL7dB0MOHQ+XKNih99WqrNrr/fqtEO+KIoKMUydz69bYKXsuWsb/Cn4iIiIhEVo5nHnnvZ3jvTwNqAbW896cDF4YxRok3JUtCly62lM/LL9ta3RdcYGUZY8aEf13zCHPODp7Gj4fNm7N/P+9thsjbb9tA5c6dIxejxJ7jj7dqs9GjbYB2zZowbpz9d7jxRiWOJPaVLm0rqylxJCIiIiJZyW7bGgDe+83e+7RD6/sjEI/Em2LFLHuyeLG1ta1YYUuN1aljE6j37Ak6wmxLTra2o1Gjsn+fZ56B7t3hjjvsACwOi64kDJo0sRa18ePhssv0PhARERERkcRySMmjA+jwSPYpVMgyKPPn21ThbdugVSvr3/ngA0hJCTrCg6pbF8qWzf6qa926WfFV+/bWvaeEgYiIiIiIiCSinCSP4qsvSaKjQAHr1/nzTxgyxH5u394mBffuDTt3Bh1hpvLkgauugrFjbXZNVnr3toKr1q2hb1+7r4iIiIiIiEgiyvKQ1zm3xTm3OYOvLUDZKMUo8ShvXrj6avj9d1uZ7dhjbar0SSdZn9fBsjMBSU62/NbYsZnfZsAAeyhNm8KHH9pDFREREREREUlUWSaPvPfFvPfFM/gq5r3PF60gJY45B1dcAZMnw9dfQ/Xq8OCDcMIJNjBo48agI9xP/fpwzDGZt64NG2aFVRddBEOHQv780Y1PREREREREJNrUbCPR4RxceKElkH76CerVg6eftiTSo4/C2rVBRwhYFdFVV9nqWdu373/dmDHQti2ccw58/jkULBhMjCIiIiIiIiLRpOSRRF/dujByJMyYYctUvfwyVKwId90Fy5YFHR3JyTbve/z4fZd9+y20bGlLsactyy4iIiIiIiKSGzjv42vudVJSkp86dWrQYUg4zZsHL75oA4Scg9NOg2LFMv4qWvTg1xUqlKOlz1JTbURTo0bw0UdWKHXJJZbf+u47OProsD1yERERERERkZjgnJvmvU/K6DrNLZLgVakC/fpZG9vrr8OcObBlCyxdav+mfWV3pba8ef+bZMoq6XTA9fmKFaP5RScy9POi/PyTo3Fjx3HHwYQJShyJiIiIiIhI7qPKI4kfqam2Slv6hNKBXwe7Pv1tdu3KdFfjuIzGjKMAuzm2xE4mfe+pUPPIKD5YERERERERkehR5ZEkhnz54Kij7CscUlIyTS5duHEbJe/eQYGUbXy18Rwq1F0F114Ld95pg49EREREREREcgkljyT3yp8fSpa0rwMUACbWhaOOKkS5dUPhrbdgwAB4911o2NCSSM2a2TZEREREREREEphWWxPJRI0aUK4ccPrp0LcvrFhhK8MtXQqtWsGJJ8Jzz8HatUGHKiIiIiIiIhIxSh6JZFepUvDQQ7BgAYwcadmlJ5+E44+3lraff4Y4myEmIiIiIiIicjBKHokcqrx5oWlTGD/eVoa77TZLJp1zDpx5JvTvn/2V4URERERERERinJJHIjlRtSq8/jqsXAm9esGOHXDjjVC+PDz2mLW4iYiIiIiIiMQxJY9EwqFYMatAmj0bvvkGGjSw+UgnnQQtWsDXX6ulTUREREREROKSkkci4eQcXHABDB8OixfDI4/ADz/AxRfDKafYqm1btgQdpYiIiIiIiEi2KXkkEikVKkDXrrB8OXzwARQtCnfeaUu43XWXzUsSERERERERiXERTR455xo55+Y65xY45x7N4nYtnXPeOZcUyXhEAlGwIFx/PUyZAr/8As2bw7vvQvXqcOmlNmx7z56goxQRERERERHJUMSSR865vMBbQGPgFKCtc+6UDG5XDLgH+CVSsYjEjLPOggEDrBrpuefgzz+hWTOoVMlmJG3YEHSEIiIiIiIiIvuJZOXRWcAC7/0i7/1uYDDQLIPbPQu8BGhtc8k9jjkGOneGJUvg00/hxBNtPlL58nDTTTB9etARioiIiIiIiACRTR6VA5an+3lF6LL/55w7Azjeez86qw055zo656Y656auX78+/JGKBCVfPmjZEr79FmbNgvbtYcgQqFMHzj0XBg6E3buDjlJERERERERyscAGZjvn8gA9gAcOdlvv/bve+yTvfVLp0qUjH5xIEE49FXr3hpUr4bXX4O+/oV07G7z9f+3deXxU9b3/8dcnIQYIASKgCEFZBFmEBgnoNWxqbUWUrSAqyGJdsFpEb+8tba8Wrd7qlXoBteIGIhcLiqJywaL8ioDXpQRk31GUTUGWkAABQr6/P74TZhIyAUKGyYT38/E4jzlzzpkz30mOo3n7+X7Oo49CZiZkZUV7lCIiIiIiInKOMedcZE5s9i/AKOfczwPPfwfgnPtz4HkNYBOQE3hJXWAP0MM5lxnuvOnp6S4zM+xukYojPx8+/hieew5mz4aCf1br1IFmzaBp08KPl14KVatGd8wiIiIiIiISk8xssXOu2BuZRTI8qgSsB64DtgGLgNudc6vCHP8J8JuSgiNQeCTnqO++g8WLYcMGWL/eP27YADt2FD4uNbVwqFSw3rgxnHdedMYuIiIiIiIi5V5J4VGlSL2pcy7PzB4A5gDxwATn3CozexzIdM59EKn3FqlwLr7YL0VlZ8PGjcFAqeDx7bdhz57gcXFx0LDhidVKTZvCJZdAfPxZ+ygiIiIiIiISWyJWeRQpqjwSOUW7dwcrlEKDpfXrIScneNx55/nKpKLVSk2bQv36YBa9zyAiIiIiIiJnRVQqj0QkymrV8stVVxXe7hz88MOJ1UobNsCcOXD4cPDYqlV9L6Wi1Uqpqb73knosiYiIiIiIVHgKj0TONWZQt65fOncuvC8/H7ZuPTFYWrYM3nsP8vIKH5+U5EOkOnXggguC60WfF6wrbBIREREREYk5Co9EJCguLthf6ac/Lbzv6FHYvNmHSdu3w65dwWXnTr9t2TL/PLR6KVTVquGDpeKeJyVF/COLiIiIiIhIyRQeicipSUgI9kQqiXO+kXdosFQ0aNq1C77/HpYvP7WwqaSgqUkTP7Wukr7OREREREREIkF/bYlI2TKD6tX90qTJyY93zjfwLilo2rXL92laudKv5+YWPkdiIrRqBa1bF17q1lXDbxERERERkTOk8EhEossMkpP90rjxyY93Dg4c8MHSzp2+L9OKFb6K6aOPYNKk4LG1akGbNoUDpVatoFq1yH0eERERERGRCkbhkYjEFjMf/lSr5sOmoneT273bh0kFy/Ll8NprPnAq0LhxMEwqCJc09U1ERERERKRY+ktJRCqWWrWga1e/FMjP982+Q0OlFStg5ky/D/zUt5YtC1cptWmjqW8VQV6eDxX37PHBYWJitEckIiIiIhJTzDkX7TGclvT0dJeZmRntYYhIRZCbC2vWnBgqbd8ePKZWrRN7KV1+uaa+RYtzcPCg733144/BnlgF68Vt27s3+Po6deDee+G++6Beveh9DhERERGRcsbMFjvn0ovdp/BIRKSIolPfVqzwzbpzcoLHhE59K1iaNtXUt9OVn+8rgk4WAIVuK9owvUBCAtSu7QOioo916kBSErz7rq84i4+Hfv1g+HC48kpVl4mIiIjIOU/hkYjImcrPh2+/9T2UQkOl9evh2DF/TEICNGvmp7+1aOEfW7b02861qVJZWbBxo1++/z58KLRnT3DqYFHJyeGDoOK2Va9+aiHQ11/DCy/4XlhZWdC+vQ+R+vU7935PIiIiIiIBCo9ERCIlNxfWrvVB0urVweXrr4OhSFwcNGlSOFRq0QKaN4/t6W/79vlwaMOGwo8bN/pgKFRcnJ8CWDT8CRcE1aoFlStHdvw5OfDGGzBuHKxbBxde6Kez3Xuv73UlIiIiInIOUXgkInK25eb6qqQ1a4KB0po1ftvRo8HjLrmkcKBU8JiSEr2xh9q7t/hwaMMGP70vVGqqn7p36aV+adrUh2b16/vPExcXnc9wMvn5MHeuD5FmzfIVZP37+2qk9u2jPToRERERkbNC4ZGISHlx9Chs2hQMlQoe166FQ4eCx9WtG5z2FhoqXXBB2ffn2b27+HBo40Y/rayAGTRoEAyGQkOixo2hSpWyHVc0bNgAzz8PEydCdjZcdZUPkX7xCzjvvGiPTkREREQkYhQeiYiUdwU9lUIDpYL1/fuDx51//omBUsuWvuonXKjknA+IiguHNm4sfDcyM7j44hPDoUsv9QFRpKeSlRf798OkSfDcc/5nddFFfkrbPff46W0iIiIiIhWMwiMRkVjlHGzfXjhUWrMGVq0qPG2sWrVgkNS8ORw4UDgkysoKHhsX56fLFVdB1KiRmkaHys+HOXP8lLa//91XH916q69Gatcu2qMTERERESkzCo9ERCqiXbtOnP62erUPm+LioGHD4iuIGjZUQFQa69b5SqTXX/fhXEaGD5F69/Z9kkREREREYpjCIxGRc0l2tg+H1KMnMrKyfE+k557zd9WrXx9+9Su4+25/pzgRERERkRhUUnhUTm99IyIipZacrOAokmrUgBEj/J3zZs70UwX/8AffTPzOO2Hp0miPUKTi+/hj6NIFBg+G998vfMMBERERKXMKj0REREojPh5uugk++sj3oBo6FKZNg7Zt/R+177wDeXnRHqWURlYWTJ8On3ziK/mk/PjhBxgwAH72M9i8GT74AHr1gtq1oW9fmDIF9u2L9ihFREQqHIVHIiIiZ6plS3jxRdi6FUaPhu++83/INm4MTz9duLl5eXLsmA9HYmwKe0RkZ8Obb0LPnnDBBdCvH1xzja80a9ECBg3yUxU//1xVLtGQnw+vvOJvCPD22/Doo74P2c6dvgpp8GD47DMYOND//m64AV5+2YdNIiIicsbU80hERKSsHTsG//u/MHYszJsHlSv7P2qHD4fWrcvm/NnZsH+/r5LZv7/4paR9+/cHq2oaNvRVVD16+Kqpc2Xa48GDMGuWrxibNQtyc30Pq1tugT59ICcHFi0KLt9/719XqRJcfjmkp0P79n65/HI1To+UVavg3nvh//4POneGl17yIVJR+fnw5ZcwYwa8+y5s2gRmvrl9795+adTo7I9fREQkRqhhtoiISLSsWOErViZP9uHENdfAr38NTZqcWshT3L4DB07+vma+/1X16sGlRo3Cz6tX98HWZ5/B3Lm+oiY5GX7+c7j5ZrjxRj8dqCLJzYUPP/SB0cyZPkC68EJfadS/P1x9tb9bYXG2bfMhUmZmMFDau9fvS0yEtLRgmJSeDpdd5qc3SukcOgRPPAH/9V/+Wh09GoYM8df2yTgHK1f6EGnGDFi2zG9PS/PBYO/e0KrVqZ1LRETkHKHwSEREJNp274bXXoPnn4ctW8IfZxY+6CkpBCq6LykpfAhSnIMH4R//8IHKzJmwY4d//dVX+yDp5pt9tUcs/rF95IjvTTVtmm+unJ3tQ7Ff/MIHRp07ly7kcc7fcS80TFq8OBjuVasG7doVrlBq1Cg2f4Zn28cfw333+eqhQYN8cHQmdzP8+utgRdLnn/vfXdOmPkTq08f/bk7nnxcREZEKSOGRiIhIeZGX56t8DhwoPgRKSop+uJCfD0uWBIOkr77y25s08SFSjx7QsWP5nqZ19KgPw6ZN86HBvn1Qs6YPCvr3h2uv9dPPytqxY74XT0GYlJnp78B3+LDff/75wTCp4LF+/bIfR6zauRMeesj3n2raFMaP97+rsrRjhw8RZ8zw10heHtSrF5za1rlz+b62RUREIkThkYiIiJTeli2+h9PMmf6P7cOHffDVrZsPk7p1g5SUaI/SBzfz5/vA6J13fLVXcrK/G1f//nD99dHp53TkiJ9CFTrlbeVKP16Aiy4qXJ2Unl7xpgueTH4+TJgA//7vvtfU737nl8qVI/u+e/f6flfvvgt//7ufKnf++f667tPHXzNVqkR2DCIiIuVE1MIjM7sBGAvEA686554qsv9h4C4gD9gF3Omc+7akcyo8EhERiaKcHF859cEH/o/unTv9lK9OnYLT25o2PXvjyc+HTz/1gdH06X48SUm+Oqp/f9+/KdIBRGkcPOgrkkKnvK1bF9zfsGHh6qSMjIrbyHz1at8Q+9NPfdXP+PH+Dndn28GDMGeOr0iaOdNXqyUl+XC0d2/o3t2HpiIiIhVUVMIjM4sH1gPXA1uBRcBtzrnVIcdcA3zpnDtoZvcBXZ1z/Us6r8IjERGRciI/H/75T/+H9gcf+Goa8I2iC4Kkq68u++lhzsEXX/jA6O23Yft2Xx3SvbsPjG68EapWLdv3PBuysvx0wdApb5s3+321a8OAAb5hdFpaNEdZdg4dgief9A2xk5NPryF2pB09Cp984iuS3nvP32kvIQGuu85XJPXo4Ruti4iIVCDRCo/+BRjlnPt54PnvAJxzfw5zfFvgeedcRknnVXgkIiJSTm3eHOyT9Mkn/g/w88/3Yc7NN/sqoNJWbjjnm1FPmwZvvQXffecrcbp184HRzTf7BtUVza5d/m54U6b4Pj1HjvjwaOhQuP322J3eVtYNsSMpP9+HlQUNt7/+2gdcHTsG+yQ1bBjtUYqIiJyxaIVHfYEbnHN3BZ7fAVzpnHsgzPHPA987554oZt89wD0AF198cbtvvy1xZpuIiIhE2/79fgrQzJkwe7bvP1SpEnTp4qs2br7Z33msJM7B8uU+MJo2zf/RXqkS/OxnPjDq2fPcmka0ezdMnQoTJ/ogLSHB/xyHDoUbbohMA/CytnMnPPywD8Mi1RA7kpyDFSuCQdLy5X5727bwy1/C4MEVM8QUEZFzQrkPj8xsIPAA0MU5d7ik86rySEREJMbk5fnboxdUJa1d67e3ahW8e1uHDr53EsCqVcEKo3Xr/PZrr/WBUe/evprpXLdiBbz+Okye7KuTLrwQ7rjDT/tq1SraoztRtBpiR9qmTT5ImjrVB3o1asBdd8EDD6gaSUREYk65nrZmZj8FnsMHRztPdl6FRyIiIjFu48ZgkLRggb/rWJ068NOf+kqOVav8tKCuXeGWW+AXvyi/U5qi7ehRX9n1+uv+jnh5eb7B9tChcOut5eMueOWlIXakffEFjBnjG7c75+/yN2KEn95WHvo4iYiInES0wqNK+IbZ1wHb8A2zb3fOrQo5pi0wHV+htOFUzqvwSEREpALZu9ffIn3mTH8Xt8su8xVGfftC3brRHl1s2bkT3nzTT2tbvhwSE32AMXSoD+YKKrvOlqINsZ95xldGxcWd3XGcbVu2wF//Ci+95K/vtm19iNS/v/+diIiIlFNRCY8Cb3wjMAaIByY45540s8eBTOfcB2Y2F2gN7Ai85DvnXI+SzqnwSERERKQEzsFXX/lqpClTYM8eqF/fN6YeMgSaNYv8GObOhWHD/LSuO+6Av/zl3KseO3gQ/ud/YOxYX3114YW+SfiwYbpTm4iIlEtRC48iobjw6OjRo2zdupXc3NwojUpOVeXKlUlNTSUhISHaQxEREan4Dh/2VV2vvw4ffuh7D119ta9GuuUWqF69bN9v507413/1ocmll/opatddV7bvEWuc82Ha2LEwa5a/S+Ctt8KDD8IVV0R7dCIiIsdV+PDom2++ITk5mVq1amGaU15uOefYvXs32dnZNDrZHXZERESkbO3Y4RtsT5zom5ZXqeL7SQ0d6vtLncl0svx8f95/+zffEHvkSPj972O/IXZZW78ennvO/6wOHIBOnfyUtp49z/60QhERkSJKCo8qxKTz3NxcBUcxwMyoVauWKsRERESi4aKL/N3OVq/2zZ0HDfJVSdddB40bwx//CN98c/rnXb3ah0933QWXXw7LlsHjjys4Kk6zZj482rrVT+XbssUHeE2a+Of79kV7hCIiIsWqEOERoOAoRuj3JCIiEmVmcOWVfkrZjh2+yfZll8Gf/uRDpK5dYdIkXxlTkkOH4JFHIC0NVq6E116DTz6pmHdSK2s1a8LDD/s7D777LlxyCfzmN5CaCg884CuUREREypEKEx6JiIiIyGmqUgVuuw3mzIFvv4UnnoBt23xj7bp14c47YeFC37cn1Ny50KaNP/7WW/00uDvvrPh3Uitr8fHQuzfMnw9Llvi7DL7yig/zuneHjz468WcvIiISBfo3fBnYt28ff/3rX0v12htvvJF9p1GiPGrUKEaPHl2q9xIREREJq0ED+MMffNXLwoW+ofbbb0PnztC0qQ+Kli71d0+7/nr/mrlz4Y034IILojv2iqBtW9/Y/LvvYNQoWLwYfv5zPxXwpZf83dtERESiROFRGSgpPMrLyyvxtbNnz6ZmzZqRGJaIiIjI6TODjh39NLTvv/dT2Bo08FPU2raFadP8+ooVupNaJFx4oe8/9e23/mefmAjDhvnfwciRvk+SiIjIWVYp2gMocyNG+P8rVpbS0mDMmLC7R44cyaZNm0hLS+P666+ne/fuPPLII6SkpLB27VrWr19Pr1692LJlC7m5uTz44IPcc889ADRs2JDMzExycnLo1q0bHTt25LPPPqN+/fq8//77VKlSJez7Ll26lGHDhnHw4EGaNGnChAkTSElJYdy4cYwfP55KlSrRsmVLpk6dyvz583nwwQcB33dowYIFJCcnl+3PSURERCqWpCTfWHvQIN9Me/ZsuPZa9TU6GxIT/c/9jjvg009h7Fh45hkYPdo32R4xAq66yod9IiIiEabKozLw1FNP0aRJE5YuXcozzzwDwJIlSxg7dizrAw0PJ0yYwOLFi8nMzGTcuHHs3r37hPNs2LCB+++/n1WrVlGzZk3eeeedEt930KBBPP300yxfvpzWrVvz2GOPHR/PV199xfLlyxk/fjwAo0eP5oUXXmDp0qUsXLiwxFBKRERE5ASNGsH99ys4OtvMoFMnmD4dNm2Chx7yPaquvto3Pn/zTThyJNqjFBGRCq7iVR6VUCF0NnXo0IFGjRodfz5u3DhmzJgBwJYtW9iwYQO1atUq9JpGjRqRlpYGQLt27di8eXPY82dlZbFv3z66dOkCwODBg+nXrx8Abdq0YcCAAfTq1YtevXoBkJGRwcMPP8yAAQPo06cPqampZfZZRUREROQsaNjQVx/98Y++19TYsTBggL9T269+BffeC3XqRHuUIiJSAanyKEKSkpKOr3/yySfMnTuXzz//nGXLltG2bVtyc3NPeE1iYuLx9fj4+JP2Swpn1qxZ3H///SxZsoT27duTl5fHyJEjefXVVzl06BAZGRmsXbu2VOcWERERkSirVs2HRWvW+KmErVv7PlQNGsAvfwkzZ8KePdEepYiIVCAKj8pAcnIy2dnZYfdnZWWRkpJC1apVWbt2LV988cUZv2eNGjVISUlh4cKFAEyePJkuXbqQn5/Pli1buOaaa3j66afJysoiJyeHTZs20bp1a37729/Svn17hUciIiIisS4uDrp189PYVq2CIUPgb3+DHj2gVi1/p7Zhw2DKFN+AW0REpJQq3rS1KKhVqxYZGRlcfvnldOvWje7duxfaf8MNNzB+/HhatGjBZZddxlVXXVUm7ztp0qTjDbMbN27MxIkTOXbsGAMHDiQrKwvnHMOHD6dmzZo88sgjzJs3j7i4OFq1akW3bt3KZAwiIiIiUg60bAnjx8N//zcsWuSbbC9c6MOkl17yxzRo4O+k16mTf2zVygdQIiIiJ2HOuWiP4bSkp6e7zMzMQtvWrFlDCzVvjBn6fYmIiIicJceOwYoVPkgqCJR27PD7ataEjIxgmJSe7u/yJiIi5yQzW+ycSy9unyqPREREREQqqvh4SEvzy69/Dc7BN98UDpNmzfLHJiZChw7BMOnqq6FGjeiOX0REygWFRyIiIiIi5wozaNzYL4MH+227dvkgqSBMevpp+M//9Me2aRMMkzp1gnr1ojt+ERGJCoVHIiIiIiLnsjp1oHdvvwAcOABffBEMkyZMgOef9/saNSocJl12mQ+ZRESkQlN4JCIiIiIiQUlJcN11fgE4ehSWLg2GSR9+CG+84ffVru2DpIIwqW1bSEiI3thJAfkZAAASWElEQVRFRCQiFB6JiIiIiEh4CQnQvr1fHnrI901av75w36T33vPHVq0KV10VDJRat4YLL1R1kohIjFN4JCIiIiIip87MT1e77DK46y6/bfv2wn2T/vQnHzKBb7pdcHzo0rQpVK4cvc8hIiKnLC7aAzhXVatWDYDt27fTt2/fYo/p2rUrmZmZJZ5nzJgxHDx48PjzG2+8kX379p3x+EaNGsXo0aPP+DwiIiIicg6oVw9uuQXGjYOvvoK9e+Gjj2DsWLj9dqhWDf7xD/iP/4B+/Xwj7qpVfePubt1gxAh48UV/zPbtweBJRETKBVUeRVm9evWYPn16qV8/ZswYBg4cSNWqVQGYPXt2WQ1NRERERKR0atSA66/3S6icHD/lbd06WLvWP65bBwsWQMj/ECU5GZo1C1YpNW8erFYK/HeviIicPRUuPBoxwvfzK0tpaTBmTPj9I0eOpEGDBtx///2Ar9qpVq0aw4YNo2fPnuzdu5ejR4/yxBNP0LNnz0Kv3bx5MzfddBMrV67k0KFDDB06lGXLltG8eXMOHTp0/Lj77ruPRYsWcejQIfr27ctjjz3GuHHj2L59O9dccw21a9dm3rx5NGzYkMzMTGrXrs2zzz7LhAkTALjrrrsYMWIEmzdvplu3bnTs2JHPPvuM+vXr8/7771OlSpWwn2/p0qUMGzaMgwcP0qRJEyZMmEBKSgrjxo1j/PjxVKpUiZYtWzJ16lTmz5/Pgw8+CICZsWDBApKTk0v7oxcRERGRiqRaNbjiCr+Eys+HbdsKB0rr1vlpcG++WfjYiy8uHCgVLKmp6q0kIhIhFS48iob+/fszYsSI4+HRW2+9xZw5c6hcuTIzZsygevXq/Pjjj1x11VX06NEDC/MvtRdffJGqVauyZs0ali9fzhUh/1J98sknOf/88zl27BjXXXcdy5cvZ/jw4Tz77LPMmzeP2rVrFzrX4sWLmThxIl9++SXOOa688kq6dOlCSkoKGzZs4G9/+xuvvPIKt9xyC++88w4DBw4M+/kGDRrEc889R5cuXXj00Ud57LHHGDNmDE899RTffPMNiYmJx6fKjR49mhdeeIGMjAxycnKorHnsIiIiInIycXHQoIFfilYrHTgAGzYUDpXWrYOJE30lU4GqVX21UtFQqVkzH1qJiEipVbjwqKQKoUhp27YtO3fuZPv27ezatYuUlBQaNGjA0aNH+f3vf8+CBQuIi4tj27Zt/PDDD9StW7fY8yxYsIDhw4cD0KZNG9q0aXN831tvvcXLL79MXl4eO3bsYPXq1YX2F/Xpp5/Su3dvkpKSAOjTpw8LFy6kR48eNGrUiLS0NADatWvH5s2bw54nKyuLffv20aVLFwAGDx5Mv379jo9xwIAB9OrVi169egGQkZHBww8/zIABA+jTpw+pqamn+FMUERERESlGUpKfChD479fjnPP9kUIDpbVr4YsvYNq0wn2T6tXzU+kqV47MUqVK4eeVKqkKSsqOc3DsWPQX5/y1Xq2a/+cyKenE9apVfRgsFU6FC4+ipV+/fkyfPp3vv/+e/v37AzBlyhR27drF4sWLSUhIoGHDhuTm5p72ub/55htGjx7NokWLSElJYciQIaU6T4HExMTj6/Hx8YWmx52OWbNmsWDBAmbOnMmTTz7JihUrGDlyJN27d2f27NlkZGQwZ84cmjdvXuqxioiIiIgUywzq1/fLtdcW3nfoEGzcGAyVNm70VUq5ucElO7vw89AlL+/MxhYXFz5oSkz0y3nnnfyxrPfFxyvUOtuOHYP9+2HfPr9kZQXXi3tedNv+/f4csaRKleKDpdNZL25fYqKu3yhSeFRG+vfvz913382PP/7I/PnzAV+1c8EFF5CQkMC8efP49ttvSzxH586defPNN7n22mtZuXIly5cvB2D//v0kJSVRo0YNfvjhBz788EO6du0KQHJyMtnZ2SdMW+vUqRNDhgxh5MiROOeYMWMGkydPPu3PVaNGDVJSUli4cCGdOnVi8uTJdOnShfz8fLZs2cI111xDx44dmTp1Kjk5OezevZvWrVvTunVrFi1axNq1axUeiYiIiMjZVaUKtG7tl9LIy4PDh8OHS2eyHDoER474gODwYb9+5EhwPXTbmYZYRZmdGCglJJRuOe+80r823Dni433wFh9/ZutxcWUXMhw9WrrQp+D5/v0nf4/kZKhZM7jUrw+tWvn16tWDP5toL2b++s3J8dNJDxw4tfWC53v2nLjvdIKxuLjCFU6hQWzocqrbTufYk73+HKi2imh4ZGY3AGOBeOBV59xTRfYnAm8A7YDdQH/n3OZIjilSWrVqRXZ2NvXr1+eiiy4CYMCAAdx88820bt2a9PT0k4Yo9913H0OHDqVFixa0aNGCdu3aAfCTn/yEtm3b0rx5cxo0aEBGRsbx19xzzz3ccMMN1KtXj3nz5h3ffsUVVzBkyBA6dOgA+IbZbdu2LXGKWjiTJk063jC7cePGTJw4kWPHjjFw4ECysrJwzjF8+HBq1qzJI488wrx584iLi6NVq1Z069bttN9PRERERCSqKlXyS6AFRNQcO+bDi5OFTKXddviwP3+4paBC68iRko8rWMpThYzZ6YVNodvM/Ofet6/wXQCLExfnp0TWrBl8bNKk8PPQpei26tX9+56LnPPX4OkEUaHrBdd1wXLokA/sim4P/WfgyJHIXKeffgohf6dXROZC5wKX5YnN4oH1wPXAVmARcJtzbnXIMb8C2jjnhpnZrUBv51z/ks6bnp7uMjMzC21bs2YNLVq0KOuPIBGi35eIiIiISAWUn39qIVPoEhpM5ecH++uUxXppX+fcidVA4YKgatXOiaqTCqUglC0uWAoXOJ1s3513+oqxGGdmi51z6cXti2TlUQdgo3Pu68AgpgI9gdUhx/QERgXWpwPPm5m5SCVaIiIiIiIiEhlxccGpRCLlVUGVme4MfloiGZHWB7aEPN8a2FbsMc65PCALqFX0RGZ2j5llmlnmrl27IjRcEREREREREREpKibq65xzLzvn0p1z6XXq1Al3zFkelZSGfk8iIiIiIiIisSWS4dE2oEHI89TAtmKPMbNKQA184+zTUrlyZXbv3q1gopxzzrF7924qqzxQREREREREJGZEsufRIqCpmTXCh0S3ArcXOeYDYDDwOdAX+Edp+h2lpqaydetWNKWt/KtcuTKpqanRHoaIiIiIiIiInKKIhUfOuTwzewCYA8QDE5xzq8zscSDTOfcB8Bow2cw2AnvwAdNpS0hIoFGjRmU1dBERERERERERCYhk5RHOudnA7CLbHg1ZzwX6RXIMIiIiIiIiIiJSejHRMFtERERERERERKJD4ZGIiIiIiIiIiIRlsXaHMjPbBXwb7XGUkdrAj9EehEgp6NqVWKVrV2KVrl2JVbp2JVbp2pVYdKbX7SXOuTrF7Yi58KgiMbNM51x6tMchcrp07Uqs0rUrsUrXrsQqXbsSq3TtSiyK5HWraWsiIiIiIiIiIhKWwiMREREREREREQlL4VF0vRztAYiUkq5diVW6diVW6dqVWKVrV2KVrl2JRRG7btXzSEREREREREREwlLlkYiIiIiIiIiIhKXwSEREREREREREwlJ4FAVmdoOZrTOzjWY2MtrjETlVZrbZzFaY2VIzy4z2eERKYmYTzGynma0M2Xa+mX1sZhsCjynRHKNIUWGu21Fmti3w3bvUzG6M5hhFimNmDcxsnpmtNrNVZvZgYLu+d6VcK+Ha1XevlGtmVtnM/mlmywLX7mOB7Y3M7MtA3jDNzM4rk/dTz6Ozy8zigfXA9cBWYBFwm3NudVQHJnIKzGwzkO6c+zHaYxE5GTPrDOQAbzjnLg9s+y9gj3PuqUB4n+Kc+200xykSKsx1OwrIcc6NjubYREpiZhcBFznnlphZMrAY6AUMQd+7Uo6VcO3egr57pRwzMwOSnHM5ZpYAfAo8CDwMvOucm2pm44FlzrkXz/T9VHl09nUANjrnvnbOHQGmAj2jPCYRkQrHObcA2FNkc09gUmB9Ev4/DkXKjTDXrUi555zb4ZxbEljPBtYA9dH3rpRzJVy7IuWa83ICTxMCiwOuBaYHtpfZ967Co7OvPrAl5PlW9OUkscMBH5nZYjO7J9qDESmFC51zOwLr3wMXRnMwIqfhATNbHpjWpmk/Uq6ZWUOgLfAl+t6VGFLk2gV990o5Z2bxZrYU2Al8DGwC9jnn8gKHlFneoPBIRE5HR+fcFUA34P7A9AqRmOT8vG3N3ZZY8CLQBEgDdgB/ie5wRMIzs2rAO8AI59z+0H363pXyrJhrV9+9Uu45544559KAVPwsp+aRei+FR2ffNqBByPPUwDaRcs85ty3wuBOYgf+CEoklPwR6GxT0ONgZ5fGInJRz7ofAfxzmA6+g714ppwI9N94Bpjjn3g1s1veulHvFXbv67pVY4pzbB8wD/gWoaWaVArvKLG9QeHT2LQKaBjqgnwfcCnwQ5TGJnJSZJQWaCGJmScDPgJUlv0qk3PkAGBxYHwy8H8WxiJySgj+8A3qj714phwKNW18D1jjnng3Zpe9dKdfCXbv67pXyzszqmFnNwHoV/E251uBDpL6Bw8rse1d3W4uCwG0exwDxwATn3JNRHpLISZlZY3y1EUAl4E1du1KemdnfgK5AbeAH4I/Ae8BbwMXAt8Atzjk1J5ZyI8x12xU/bcIBm4F7Q3rIiJQLZtYRWAisAPIDm3+P7x2j710pt0q4dm9D371SjplZG3xD7Hh8YdBbzrnHA3+3TQXOB74CBjrnDp/x+yk8EhERERERERGRcDRtTUREREREREREwlJ4JCIiIiIiIiIiYSk8EhERERERERGRsBQeiYiIiIiIiIhIWAqPREREREREREQkLIVHIiIiEhPMzJnZX0Ke/8bMRpXRuV83s75lca6TvE8/M1tjZvOKbG9oZofMbGnIMqgM37ermf1vWZ1PREREzi2Voj0AERERkVN0GOhjZn92zv0Y7cEUMLNKzrm8Uzz8l8DdzrlPi9m3yTmXVoZDExERESkTqjwSERGRWJEHvAw8VHRH0cohM8sJPHY1s/lm9r6ZfW1mT5nZADP7p5mtMLMmIaf5qZllmtl6M7sp8Pp4M3vGzBaZ2XIzuzfkvAvN7ANgdTHjuS1w/pVm9nRg26NAR+A1M3vmVD+0meWY2X+b2Soz+39mViewPc3MvgiMa4aZpQS2X2pmc81smZktCfmM1cxsupmtNbMpZmaB458ys9WB84w+1XGJiIjIuUPhkYiIiMSSF4ABZlbjNF7zE2AY0AK4A2jmnOsAvAr8OuS4hkAHoDsw3swq4yuFspxz7YH2wN1m1ihw/BXAg865ZqFvZmb1gKeBa4E0oL2Z9XLOPQ5kAgOcc/9WzDibFJm21imwPQnIdM61AuYDfwxsfwP4rXOuDbAiZPsU4AXn3E+Aq4Edge1tgRFAS6AxkGFmtYDeQKvAeZ442Q9TREREzj0Kj0RERCRmOOf240OT4afxskXOuR3OucPAJuCjwPYV+MCowFvOuXzn3Abga6A58DNgkJktBb4EagFNA8f/0zn3TTHv1x74xDm3KzCdbQrQ+RTGuck5lxayLAxszwemBdb/B+gYCM9qOufmB7ZPAjqbWTJQ3zk3A8A5l+ucOxgy3q3OuXxgaeCzZwG5+GqoPkDBsSIiIiLHKTwSERGRWDMGXxGUFLItj8B/15hZHHBeyL7DIev5Ic/zKdz/0RV5HwcY8OuQQKeRc64gfDpwRp+i9IqO81SF/hyOAQW9mjoA04GbgL+f4dhERESkAlJ4JCIiIjHFObcHeAsfIBXYDLQLrPcAEkpx6n5mFhfoEdQYWAfMAe4zswQAM2tmZkklnQT4J9DFzGqbWTxwG366WWnFAQX9nG4HPnXOZQF7Q6a23QHMd85lA1vNrFdgvIlmVjXcic2sGlDDOTcb30vqJ2cwThEREamgdLc1ERERiUV/AR4Ief4K8L6ZLcNXz5SmKug7fPBTHRjmnMs1s1fx07uWBBpM7wJ6lXQS59wOMxsJzMNXLs1yzr1/Cu/fJDA9rsAE59w4/GfpYGb/AewE+gf2D8b3ZqqKn2Y3NLD9DuAlM3scOAr0K+E9k/E/t8qBsT58CuMUERGRc4w5V9rKZxERERGJNDPLcc5Vi/Y4RERE5NylaWsiIiIiIiIiIhKWKo9ERERERERERCQsVR6JiIiIiIiIiEhYCo9ERERERERERCQshUciIiIiIiIiIhKWwiMREREREREREQlL4ZGIiIiIiIiIiIT1/wES2nMNZxCc+AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbtkTJaErwPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = []\n",
        "g = []\n",
        "for i in range(1):\n",
        "\n",
        "for data, target in testloader:\n",
        "\n",
        "                #print(\"target\",target)\n",
        "\n",
        "  data, target = data.to(device,dtype=torch.float), target.to(device,dtype=torch.float)\n",
        "\n",
        "\n",
        "                \n",
        "  data = data.float()\n",
        "  target = target.long()\n",
        "  data, target = Variable(data), Variable(target)\n",
        "\n",
        "\n",
        "\n",
        "  predictions = Model(data)\n",
        "                \n",
        "                \n",
        "                loss = criteria(predictions, target)\n",
        "                \n",
        "                validation_acc.update(predictions, target)\n",
        "                \n",
        "                total_test_data += target.size(0)\n",
        "\n",
        "                validation_loss += loss.item()*data.size(0)\n",
        "                \n",
        "                \n",
        "        training_loss = training_loss / 2700\n",
        "        \n",
        "        validation_loss = validation_loss / total_test_data\n",
        "\n",
        "        training_loss_array.append(training_loss)\n",
        "        \n",
        "        validation_loss_array.append(validation_loss)\n",
        "        \n",
        "        #tf.cpu() \n",
        "        \n",
        "        predictions = torch.argmax(predictions, 1)  #this needs gpu\n",
        "       \n",
        "\n",
        "        predictions = predictions.cpu()\n",
        "        predictions = predictions.numpy()\n",
        "        p.append(predictions)\n",
        "        \n",
        "        ground_truth = target.cpu().numpy()\n",
        "        g.append(ground_truth)\n",
        "        pred = predictions\n",
        "        l = len(pred)\n",
        "        ground_truth = target.cpu().numpy()\n",
        "        ground_truth = np.array(ground_truth)    \n",
        "        pred = np.array(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-30U_peB_03",
        "colab_type": "code",
        "outputId": "57849408-2820-4f36-8dca-649200ba0018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#import tensorflow as tf\n",
        "n_epochs = 50\n",
        "model,p,t = model_traing_and_validation_loop(Model, n_epochs, 'fire-flame.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 th epoch\n",
            "gt [2 2 2 2 0 0 0 1 0 0 2 2 1 1 2 2 2 2 2 1 2 0 2 2 1 0 2 1 1 2 0 2 1 0 2 2 2\n",
            " 1 2 2 0 1 1 2]\n",
            "pred [2 2 2 2 1 0 0 2 0 2 1 2 1 1 2 2 2 1 2 1 2 0 2 2 1 0 2 1 1 2 0 2 1 1 1 1 2\n",
            " 1 2 2 0 1 1 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "1 / 50 Training loss: 0.25591869212962964, Tran_Accuracy: 0.9055555462837219, Validation_loss: 0.7105598958333333, Validation_Accuracy: 0.7666666507720947\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.70      0.82        10\n",
            "     Neutral       0.62      0.91      0.74        11\n",
            "       Smoke       0.90      0.83      0.86        23\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.84      0.81      0.81        44\n",
            "weighted avg       0.86      0.82      0.82        44\n",
            "\n",
            "\n",
            "--------------------------Saving Model---------------------------\n",
            "1 th epoch\n",
            "gt [2 1 1 1 1 2 2 2 0 0 0 1 2 0 0 0 0 1 0 1 0 1 0 2 1 0 1 0 1 0 0 1 0 2 0 1 0\n",
            " 0 2 2 2 0 1 1]\n",
            "pred [2 1 1 1 2 2 2 2 0 0 0 1 2 0 2 0 0 1 0 1 0 1 0 2 1 0 1 0 1 0 0 1 0 2 0 2 0\n",
            " 0 2 1 2 0 2 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "2 / 50 Training loss: 0.2885170717592593, Tran_Accuracy: 0.8996296525001526, Validation_loss: 0.4416145833333333, Validation_Accuracy: 0.8333333134651184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.95      0.97        19\n",
            "     Neutral       0.92      0.80      0.86        15\n",
            "       Smoke       0.69      0.90      0.78        10\n",
            "\n",
            "    accuracy                           0.89        44\n",
            "   macro avg       0.87      0.88      0.87        44\n",
            "weighted avg       0.90      0.89      0.89        44\n",
            "\n",
            "\n",
            "--------------------------Saving Model---------------------------\n",
            "2 th epoch\n",
            "gt [1 2 2 2 2 2 1 1 0 2 0 0 0 2 1 2 2 1 2 2 2 2 2 1 0 2 0 2 0 2 1 0 1 0 0 1 2\n",
            " 1 2 2 2 1 1 2]\n",
            "pred [1 2 1 1 2 2 1 1 0 2 0 2 0 1 1 2 2 0 1 2 2 2 2 1 0 2 0 2 2 2 1 0 1 0 0 0 2\n",
            " 1 2 1 2 1 1 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "3 / 50 Training loss: 0.3287067780671296, Tran_Accuracy: 0.8877778053283691, Validation_loss: 0.5902734375, Validation_Accuracy: 0.79666668176651\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.80      0.80      0.80        10\n",
            "     Neutral       0.62      0.83      0.71        12\n",
            "       Smoke       0.89      0.73      0.80        22\n",
            "\n",
            "    accuracy                           0.77        44\n",
            "   macro avg       0.77      0.79      0.77        44\n",
            "weighted avg       0.80      0.77      0.78        44\n",
            "\n",
            "\n",
            "3 th epoch\n",
            "gt [1 0 1 0 1 2 1 1 0 2 0 2 1 2 1 0 1 2 1 2 2 1 0 1 2 1 1 2 1 0 2 0 0 2 2 0 1\n",
            " 1 2 1 2 0 1 2]\n",
            "pred [1 0 1 0 2 2 2 1 0 2 0 2 2 2 2 0 2 2 1 2 1 1 2 1 2 1 1 2 2 0 2 0 0 2 2 0 0\n",
            " 1 1 1 0 0 1 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "4 / 50 Training loss: 0.24946126302083332, Tran_Accuracy: 0.9144444465637207, Validation_loss: 0.5517578125, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.83      0.91      0.87        11\n",
            "     Neutral       0.85      0.61      0.71        18\n",
            "       Smoke       0.63      0.80      0.71        15\n",
            "\n",
            "    accuracy                           0.75        44\n",
            "   macro avg       0.77      0.77      0.76        44\n",
            "weighted avg       0.77      0.75      0.75        44\n",
            "\n",
            "\n",
            "4 th epoch\n",
            "gt [0 2 0 1 1 1 2 2 0 0 0 0 0 2 0 0 2 1 0 1 1 0 1 1 0 2 1 0 1 2 0 2 1 2 0 2 0\n",
            " 1 2 1 2 1 2 2]\n",
            "pred [0 2 0 1 1 1 2 2 0 1 0 0 0 2 0 0 0 1 0 2 1 0 0 1 0 2 1 0 2 2 0 2 1 1 0 2 0\n",
            " 1 2 1 2 1 2 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "5 / 50 Training loss: 0.1804000289351852, Tran_Accuracy: 0.9325925707817078, Validation_loss: 0.677568359375, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.88      0.94      0.91        16\n",
            "     Neutral       0.85      0.79      0.81        14\n",
            "       Smoke       0.86      0.86      0.86        14\n",
            "\n",
            "    accuracy                           0.86        44\n",
            "   macro avg       0.86      0.86      0.86        44\n",
            "weighted avg       0.86      0.86      0.86        44\n",
            "\n",
            "\n",
            "5 th epoch\n",
            "gt [1 0 1 1 0 0 0 0 1 1 2 0 0 1 0 2 0 0 2 0 1 0 1 0 1 2 2 0 0 2 1 1 1 0 2 2 1\n",
            " 0 1 0 1 2 1 2]\n",
            "pred [1 2 1 1 0 1 0 0 1 1 2 0 0 1 0 1 2 0 2 0 1 0 1 0 1 2 2 0 0 2 1 1 0 0 2 2 1\n",
            " 0 1 0 1 2 1 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "6 / 50 Training loss: 0.2953729021990741, Tran_Accuracy: 0.8929629921913147, Validation_loss: 0.4647721354166667, Validation_Accuracy: 0.8299999833106995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.94      0.83      0.88        18\n",
            "     Neutral       0.88      0.94      0.91        16\n",
            "       Smoke       0.82      0.90      0.86        10\n",
            "\n",
            "    accuracy                           0.89        44\n",
            "   macro avg       0.88      0.89      0.88        44\n",
            "weighted avg       0.89      0.89      0.89        44\n",
            "\n",
            "\n",
            "6 th epoch\n",
            "gt [0 2 1 0 2 0 1 0 2 2 0 0 2 1 0 0 2 0 1 2 1 1 0 2 2 1 0 1 0 2 2 1 1 0 0 2 2\n",
            " 1 2 1 2 0 0 2]\n",
            "pred [0 1 1 0 2 2 1 0 2 2 0 0 2 1 0 0 1 0 1 2 1 1 2 2 2 1 0 1 2 2 2 2 1 0 0 2 2\n",
            " 1 2 1 0 0 0 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "7 / 50 Training loss: 0.18419270833333334, Tran_Accuracy: 0.9348148107528687, Validation_loss: 0.5037044270833333, Validation_Accuracy: 0.8366666436195374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.81      0.87        16\n",
            "     Neutral       0.85      0.92      0.88        12\n",
            "       Smoke       0.76      0.81      0.79        16\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.85      0.85      0.84        44\n",
            "weighted avg       0.85      0.84      0.84        44\n",
            "\n",
            "\n",
            "--------------------------Saving Model---------------------------\n",
            "7 th epoch\n",
            "gt [1 1 0 1 0 1 2 2 1 1 1 0 2 0 2 2 1 0 1 1 1 0 1 0 1 1 0 1 0 2 0 0 2 1 2 1 2\n",
            " 2 0 1 0 0 1 1]\n",
            "pred [1 2 0 2 0 2 2 2 2 1 1 0 2 0 1 2 1 0 1 0 0 0 1 0 1 1 0 1 0 2 0 0 2 1 2 1 2\n",
            " 2 0 1 0 0 1 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "8 / 50 Training loss: 0.1431200267650463, Tran_Accuracy: 0.9548147916793823, Validation_loss: 0.46596354166666665, Validation_Accuracy: 0.8433333039283752\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.88      1.00      0.93        14\n",
            "     Neutral       0.93      0.70      0.80        20\n",
            "       Smoke       0.69      0.90      0.78        10\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.83      0.87      0.84        44\n",
            "weighted avg       0.86      0.84      0.84        44\n",
            "\n",
            "\n",
            "--------------------------Saving Model---------------------------\n",
            "8 th epoch\n",
            "gt [1 2 2 2 0 1 0 1 0 0 2 2 0 1 1 2 2 0 1 2 2 2 0 1 1 0 0 2 0 2 0 0 0 0 2 1 2\n",
            " 1 1 1 0 0 1 2]\n",
            "pred [1 2 1 2 0 1 0 1 0 0 2 1 0 1 1 2 2 0 0 2 2 2 2 2 1 0 0 2 0 2 0 2 0 0 1 1 2\n",
            " 2 1 2 0 0 1 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "9 / 50 Training loss: 0.13131483289930557, Tran_Accuracy: 0.9577777981758118, Validation_loss: 0.4607291666666667, Validation_Accuracy: 0.8333333134651184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.88      0.90        16\n",
            "     Neutral       0.75      0.69      0.72        13\n",
            "       Smoke       0.71      0.80      0.75        15\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.80      0.79      0.79        44\n",
            "weighted avg       0.80      0.80      0.80        44\n",
            "\n",
            "\n",
            "9 th epoch\n",
            "gt [1 1 1 0 2 1 2 0 1 0 0 2 1 2 1 1 0 2 1 0 2 1 1 1 2 0 0 0 2 1 2 0 2 0 2 1 1\n",
            " 2 2 1 1 0 0 1]\n",
            "pred [1 1 1 0 0 1 2 0 1 0 0 2 2 2 1 2 0 2 1 0 2 1 2 1 2 0 0 0 2 2 2 1 2 0 2 1 1\n",
            " 1 2 1 1 0 0 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "10 / 50 Training loss: 0.10203016493055556, Tran_Accuracy: 0.9692592620849609, Validation_loss: 0.5058170572916667, Validation_Accuracy: 0.8299999833106995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.92      0.92      0.92        13\n",
            "     Neutral       0.88      0.78      0.82        18\n",
            "       Smoke       0.73      0.85      0.79        13\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.84      0.85      0.84        44\n",
            "weighted avg       0.85      0.84      0.84        44\n",
            "\n",
            "\n",
            "10 th epoch\n",
            "gt [1 1 0 1 1 0 0 0 2 2 1 1 0 2 1 0 0 1 0 0 0 0 2 1 2 0 2 2 1 2 2 2 0 2 0 0 2\n",
            " 2 0 1 1 2 0 1]\n",
            "pred [0 1 0 1 1 0 2 0 1 2 1 1 0 2 1 2 0 0 0 0 0 0 2 1 2 0 2 2 1 2 1 2 0 2 0 0 2\n",
            " 2 2 1 1 1 0 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "11 / 50 Training loss: 0.08793683087384259, Tran_Accuracy: 0.9755555391311646, Validation_loss: 0.5803450520833333, Validation_Accuracy: 0.8266666531562805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.88      0.82      0.85        17\n",
            "     Neutral       0.79      0.85      0.81        13\n",
            "       Smoke       0.79      0.79      0.79        14\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.82      0.82      0.82        44\n",
            "weighted avg       0.82      0.82      0.82        44\n",
            "\n",
            "\n",
            "11 th epoch\n",
            "gt [2 2 1 1 0 1 0 1 1 1 1 2 2 0 1 0 2 0 1 2 1 0 2 0 2 2 0 0 0 2 2 2 1 1 1 2 0\n",
            " 1 0 1 1 1 0 2]\n",
            "pred [2 2 2 1 0 1 0 1 1 2 0 2 0 2 1 0 2 0 2 2 1 0 2 0 2 2 0 0 0 2 2 1 2 1 1 2 0\n",
            " 1 0 1 1 1 0 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "12 / 50 Training loss: 0.07376898871527778, Tran_Accuracy: 0.9788888692855835, Validation_loss: 0.5770638020833333, Validation_Accuracy: 0.8266666531562805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.86      0.92      0.89        13\n",
            "     Neutral       0.92      0.71      0.80        17\n",
            "       Smoke       0.71      0.86      0.77        14\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.83      0.83      0.82        44\n",
            "weighted avg       0.83      0.82      0.82        44\n",
            "\n",
            "\n",
            "12 th epoch\n",
            "gt [0 0 2 1 1 2 1 2 1 2 0 1 0 2 2 0 0 2 0 0 0 0 2 0 1 2 1 1 2 1 2 0 1 1 0 0 2\n",
            " 2 0 1 0 0 2 0]\n",
            "pred [0 0 2 1 2 2 1 2 1 2 0 1 0 2 2 0 0 1 0 0 0 0 2 1 1 2 1 1 1 1 2 1 1 1 0 0 2\n",
            " 1 0 2 0 0 2 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "13 / 50 Training loss: 0.0658615451388889, Tran_Accuracy: 0.9814814925193787, Validation_loss: 0.576162109375, Validation_Accuracy: 0.8366666436195374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.89      0.94        18\n",
            "     Neutral       0.67      0.83      0.74        12\n",
            "       Smoke       0.85      0.79      0.81        14\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.84      0.84      0.83        44\n",
            "weighted avg       0.86      0.84      0.85        44\n",
            "\n",
            "\n",
            "13 th epoch\n",
            "gt [1 2 2 0 2 0 0 2 2 1 2 1 1 0 0 2 1 2 0 1 1 0 2 0 1 1 0 1 0 1 2 1 2 0 2 1 0\n",
            " 1 2 1 2 2 0 1]\n",
            "pred [1 0 0 1 2 0 0 2 2 1 2 2 2 0 0 2 1 2 0 1 2 0 2 0 1 1 0 1 0 1 2 1 2 0 2 2 0\n",
            " 1 2 1 2 2 0 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "14 / 50 Training loss: 0.05855853045428241, Tran_Accuracy: 0.982962965965271, Validation_loss: 0.590400390625, Validation_Accuracy: 0.8299999833106995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.86      0.92      0.89        13\n",
            "     Neutral       0.92      0.75      0.83        16\n",
            "       Smoke       0.76      0.87      0.81        15\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.85      0.85      0.84        44\n",
            "weighted avg       0.85      0.84      0.84        44\n",
            "\n",
            "\n",
            "14 th epoch\n",
            "gt [0 0 1 0 2 0 1 0 0 2 2 0 0 2 2 0 1 1 2 2 1 0 1 1 0 2 0 0 2 2 1 2 2 1 1 0 1\n",
            " 2 1 2 2 0 0 1]\n",
            "pred [0 0 0 0 2 0 1 0 1 2 2 0 0 2 2 0 1 1 2 2 1 2 1 1 0 2 0 0 2 2 1 2 2 1 1 0 1\n",
            " 2 1 2 2 0 0 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "15 / 50 Training loss: 0.0465478515625, Tran_Accuracy: 0.987407386302948, Validation_loss: 0.540791015625, Validation_Accuracy: 0.8500000238418579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.88      0.90        16\n",
            "     Neutral       0.92      0.92      0.92        13\n",
            "       Smoke       0.94      1.00      0.97        15\n",
            "\n",
            "    accuracy                           0.93        44\n",
            "   macro avg       0.93      0.93      0.93        44\n",
            "weighted avg       0.93      0.93      0.93        44\n",
            "\n",
            "\n",
            "--------------------------Saving Model---------------------------\n",
            "15 th epoch\n",
            "gt [0 1 0 1 0 2 1 1 2 1 1 1 1 1 1 2 0 2 1 1 2 0 2 2 0 0 2 2 0 0 2 1 1 0 1 0 2\n",
            " 1 0 0 1 2 1 0]\n",
            "pred [0 1 0 1 0 2 1 1 2 1 2 2 1 1 1 2 0 1 1 2 2 0 2 2 1 0 2 1 0 0 2 1 1 0 1 2 2\n",
            " 2 0 0 1 2 1 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "16 / 50 Training loss: 0.05767216435185185, Tran_Accuracy: 0.9818518757820129, Validation_loss: 0.6378450520833333, Validation_Accuracy: 0.8299999833106995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.86      0.92        14\n",
            "     Neutral       0.82      0.78      0.80        18\n",
            "       Smoke       0.67      0.83      0.74        12\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.83      0.82      0.82        44\n",
            "weighted avg       0.84      0.82      0.82        44\n",
            "\n",
            "\n",
            "16 th epoch\n",
            "gt [1 1 2 1 1 1 1 0 2 2 1 2 2 2 2 1 0 2 1 1 1 1 2 2 0 2 2 0 0 0 2 2 1 0 1 1 0\n",
            " 2 0 1 1 0 1 0]\n",
            "pred [1 0 2 1 1 1 1 2 1 2 1 2 0 2 1 1 0 2 1 1 1 1 2 2 0 2 2 0 0 0 2 2 1 0 1 1 0\n",
            " 2 0 1 1 0 1 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "17 / 50 Training loss: 0.042350531684027776, Tran_Accuracy: 0.987407386302948, Validation_loss: 0.69396484375, Validation_Accuracy: 0.8366666436195374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.83      0.91      0.87        11\n",
            "     Neutral       0.89      0.94      0.92        18\n",
            "       Smoke       0.92      0.80      0.86        15\n",
            "\n",
            "    accuracy                           0.89        44\n",
            "   macro avg       0.88      0.88      0.88        44\n",
            "weighted avg       0.89      0.89      0.89        44\n",
            "\n",
            "\n",
            "17 th epoch\n",
            "gt [1 0 1 0 2 0 2 1 0 2 2 1 2 2 1 1 1 1 2 0 0 0 1 1 1 1 1 1 2 2 0 1 1 0 2 0 1\n",
            " 0 2 0 0 1 2 0]\n",
            "pred [2 0 1 0 2 2 2 0 2 2 2 0 2 1 1 1 2 2 1 0 0 0 1 1 1 1 1 1 1 2 0 1 1 0 2 0 2\n",
            " 0 2 0 0 1 1 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "18 / 50 Training loss: 0.028435194227430554, Tran_Accuracy: 0.992222249507904, Validation_loss: 0.7616145833333333, Validation_Accuracy: 0.8166666626930237\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.86      0.86      0.86        14\n",
            "     Neutral       0.75      0.67      0.71        18\n",
            "       Smoke       0.57      0.67      0.62        12\n",
            "\n",
            "    accuracy                           0.73        44\n",
            "   macro avg       0.73      0.73      0.73        44\n",
            "weighted avg       0.74      0.73      0.73        44\n",
            "\n",
            "\n",
            "18 th epoch\n",
            "gt [1 0 0 1 2 2 1 2 1 2 2 0 0 2 0 1 0 2 1 2 1 2 1 1 2 0 2 2 1 2 1 1 2 0 1 2 1\n",
            " 2 1 1 2 1 2 0]\n",
            "pred [1 0 0 1 2 2 1 1 2 2 2 0 0 2 0 1 0 2 1 2 1 2 1 1 2 0 2 2 1 2 0 2 2 0 1 2 1\n",
            " 2 1 0 2 1 2 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "19 / 50 Training loss: 0.041080457899305554, Tran_Accuracy: 0.9870370626449585, Validation_loss: 0.8024739583333333, Validation_Accuracy: 0.8366666436195374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.82      1.00      0.90         9\n",
            "     Neutral       0.93      0.76      0.84        17\n",
            "       Smoke       0.89      0.94      0.92        18\n",
            "\n",
            "    accuracy                           0.89        44\n",
            "   macro avg       0.88      0.90      0.89        44\n",
            "weighted avg       0.89      0.89      0.88        44\n",
            "\n",
            "\n",
            "19 th epoch\n",
            "gt [0 2 0 2 2 0 2 1 2 0 2 2 1 1 1 0 1 1 0 0 1 1 2 2 0 0 0 0 0 1 0 1 2 0 1 0 0\n",
            " 1 0 1 2 2 2 2]\n",
            "pred [0 1 0 2 2 0 2 1 2 0 1 2 1 0 0 0 1 2 0 0 1 2 2 1 2 0 0 0 1 1 0 1 1 2 2 0 0\n",
            " 1 0 1 2 2 2 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "20 / 50 Training loss: 0.05430881076388889, Tran_Accuracy: 0.9866666793823242, Validation_loss: 0.7476822916666667, Validation_Accuracy: 0.8333333134651184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.88      0.82      0.85        17\n",
            "     Neutral       0.62      0.62      0.62        13\n",
            "       Smoke       0.67      0.71      0.69        14\n",
            "\n",
            "    accuracy                           0.73        44\n",
            "   macro avg       0.72      0.72      0.72        44\n",
            "weighted avg       0.73      0.73      0.73        44\n",
            "\n",
            "\n",
            "20 th epoch\n",
            "gt [0 2 0 1 1 0 1 1 1 2 1 2 0 0 1 1 2 0 0 1 0 0 1 0 0 2 1 1 1 0 2 2 1 0 2 1 2\n",
            " 2 1 2 1 2 0 0]\n",
            "pred [0 2 0 1 0 0 1 1 1 2 2 2 0 0 1 1 2 0 2 1 0 0 1 2 0 2 1 1 1 2 2 2 2 0 2 1 1\n",
            " 2 0 2 1 2 0 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "21 / 50 Training loss: 0.04626374421296296, Tran_Accuracy: 0.9866666793823242, Validation_loss: 0.7672135416666667, Validation_Accuracy: 0.8333333134651184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.86      0.80      0.83        15\n",
            "     Neutral       0.93      0.76      0.84        17\n",
            "       Smoke       0.69      0.92      0.79        12\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.82      0.83      0.82        44\n",
            "weighted avg       0.84      0.82      0.82        44\n",
            "\n",
            "\n",
            "21 th epoch\n",
            "gt [1 2 2 1 0 2 1 2 0 1 2 1 0 1 2 1 2 1 0 0 0 0 0 1 2 1 1 1 1 2 2 0 0 1 2 1 2\n",
            " 2 2 2 1 0 2 2]\n",
            "pred [1 2 2 1 0 0 1 2 0 1 2 1 1 1 1 1 2 1 2 0 0 0 0 1 2 0 1 1 1 2 2 0 0 1 2 1 2\n",
            " 2 2 2 2 0 2 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "22 / 50 Training loss: 0.02574883355034722, Tran_Accuracy: 0.9944444298744202, Validation_loss: 0.74130859375, Validation_Accuracy: 0.8299999833106995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.82      0.82      0.82        11\n",
            "     Neutral       0.88      0.88      0.88        16\n",
            "       Smoke       0.88      0.88      0.88        17\n",
            "\n",
            "    accuracy                           0.86        44\n",
            "   macro avg       0.86      0.86      0.86        44\n",
            "weighted avg       0.86      0.86      0.86        44\n",
            "\n",
            "\n",
            "22 th epoch\n",
            "gt [2 0 0 0 0 0 0 1 2 0 1 1 1 2 1 1 2 2 2 0 2 2 1 1 2 1 1 1 2 0 0 1 2 1 2 2 2\n",
            " 1 1 2 2 0 0 0]\n",
            "pred [2 0 0 1 0 0 0 1 2 0 1 2 1 1 0 1 1 2 2 1 2 0 1 1 2 1 1 1 2 0 0 1 2 1 2 1 2\n",
            " 1 1 2 2 0 0 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "23 / 50 Training loss: 0.02114689579716435, Tran_Accuracy: 0.9937037229537964, Validation_loss: 0.7893489583333333, Validation_Accuracy: 0.8433333039283752\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.85      0.85      0.85        13\n",
            "     Neutral       0.72      0.87      0.79        15\n",
            "       Smoke       0.92      0.75      0.83        16\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.83      0.82      0.82        44\n",
            "weighted avg       0.83      0.82      0.82        44\n",
            "\n",
            "\n",
            "23 th epoch\n",
            "gt [0 2 0 1 1 2 1 1 2 2 2 1 2 1 1 0 1 0 2 2 0 0 1 1 1 0 1 2 0 1 0 1 2 2 0 2 2\n",
            " 0 0 0 2 2 1 0]\n",
            "pred [0 2 0 2 0 2 1 1 2 1 2 1 2 2 1 0 1 0 2 2 0 0 1 1 2 0 1 2 0 1 0 1 2 2 2 1 1\n",
            " 0 0 0 2 1 1 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "24 / 50 Training loss: 0.01925387912326389, Tran_Accuracy: 0.9944444298744202, Validation_loss: 0.883828125, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.93      0.93        14\n",
            "     Neutral       0.73      0.73      0.73        15\n",
            "       Smoke       0.73      0.73      0.73        15\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.80      0.80      0.80        44\n",
            "weighted avg       0.80      0.80      0.80        44\n",
            "\n",
            "\n",
            "24 th epoch\n",
            "gt [1 1 2 2 2 0 2 2 1 2 1 2 2 1 1 0 1 0 1 1 2 0 0 0 0 2 1 2 1 0 1 2 1 1 2 0 2\n",
            " 0 1 1 1 1 0 1]\n",
            "pred [1 2 2 1 2 0 2 1 1 1 1 2 2 1 1 0 1 0 1 1 2 2 0 0 0 2 0 2 2 0 1 1 0 1 2 0 2\n",
            " 0 0 1 1 1 0 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "25 / 50 Training loss: 0.036079191984953705, Tran_Accuracy: 0.9918518662452698, Validation_loss: 0.8292252604166667, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.77      0.91      0.83        11\n",
            "     Neutral       0.78      0.74      0.76        19\n",
            "       Smoke       0.77      0.71      0.74        14\n",
            "\n",
            "    accuracy                           0.77        44\n",
            "   macro avg       0.77      0.79      0.78        44\n",
            "weighted avg       0.77      0.77      0.77        44\n",
            "\n",
            "\n",
            "25 th epoch\n",
            "gt [1 1 1 2 2 2 2 2 1 0 2 0 0 2 0 2 2 0 1 1 1 0 2 1 1 1 2 0 1 1 0 0 1 2 2 0 0\n",
            " 2 0 1 1 0 2 1]\n",
            "pred [1 2 1 2 1 2 2 2 2 0 2 0 0 2 0 2 2 0 1 1 1 0 2 1 1 2 2 0 1 1 0 0 2 1 2 1 0\n",
            " 2 0 1 1 0 2 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "26 / 50 Training loss: 0.038312875253182874, Tran_Accuracy: 0.9855555295944214, Validation_loss: 0.7747005208333333, Validation_Accuracy: 0.8266666531562805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.92      0.96        13\n",
            "     Neutral       0.80      0.75      0.77        16\n",
            "       Smoke       0.76      0.87      0.81        15\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.85      0.85      0.85        44\n",
            "weighted avg       0.85      0.84      0.84        44\n",
            "\n",
            "\n",
            "26 th epoch\n",
            "gt [0 2 2 1 2 0 1 1 0 2 1 2 1 0 1 2 2 1 0 0 1 2 2 0 2 1 0 2 2 1 0 0 2 1 1 2 2\n",
            " 1 0 2 2 1 2 2]\n",
            "pred [0 1 1 1 2 0 0 1 0 2 1 2 2 0 1 2 2 0 0 0 1 2 2 0 2 1 0 1 2 1 2 0 2 1 1 1 2\n",
            " 2 0 2 2 1 2 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "27 / 50 Training loss: 0.012104352315266928, Tran_Accuracy: 0.9970370531082153, Validation_loss: 0.7306901041666667, Validation_Accuracy: 0.8266666531562805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.83      0.91      0.87        11\n",
            "     Neutral       0.71      0.71      0.71        14\n",
            "       Smoke       0.83      0.79      0.81        19\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.79      0.80      0.80        44\n",
            "weighted avg       0.80      0.80      0.79        44\n",
            "\n",
            "\n",
            "27 th epoch\n",
            "gt [1 0 0 0 1 1 1 0 2 0 0 2 1 0 0 2 1 0 0 1 1 1 2 2 0 2 1 2 2 0 1 2 0 1 2 1 2\n",
            " 2 0 0 2 2 1 2]\n",
            "pred [1 0 0 2 1 1 0 0 2 0 0 2 1 0 0 2 1 0 0 1 1 1 1 2 0 2 1 2 2 0 1 0 2 1 2 1 2\n",
            " 2 0 0 2 1 1 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "28 / 50 Training loss: 0.014345070167824074, Tran_Accuracy: 0.995555579662323, Validation_loss: 0.746171875, Validation_Accuracy: 0.8333333134651184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.87      0.87      0.87        15\n",
            "     Neutral       0.87      0.93      0.90        14\n",
            "       Smoke       0.86      0.80      0.83        15\n",
            "\n",
            "    accuracy                           0.86        44\n",
            "   macro avg       0.86      0.87      0.86        44\n",
            "weighted avg       0.86      0.86      0.86        44\n",
            "\n",
            "\n",
            "28 th epoch\n",
            "gt [0 1 1 0 1 0 0 0 2 0 0 0 0 2 1 2 0 1 0 1 0 0 1 2 1 2 1 1 2 0 1 1 1 0 1 2 1\n",
            " 1 2 2 1 1 2 0]\n",
            "pred [0 1 1 0 1 0 0 0 2 0 0 0 0 2 1 2 0 1 0 1 0 0 1 2 2 2 1 1 2 0 1 1 1 0 1 1 1\n",
            " 1 2 2 1 1 2 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "29 / 50 Training loss: 0.01766922562210648, Tran_Accuracy: 0.9948148131370544, Validation_loss: 0.7457194010416667, Validation_Accuracy: 0.8333333134651184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.94      0.97        16\n",
            "     Neutral       0.89      0.94      0.92        18\n",
            "       Smoke       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.93        44\n",
            "   macro avg       0.93      0.93      0.93        44\n",
            "weighted avg       0.93      0.93      0.93        44\n",
            "\n",
            "\n",
            "29 th epoch\n",
            "gt [2 2 0 1 0 2 1 1 2 2 0 1 0 1 1 1 2 0 1 0 2 0 0 2 0 1 0 0 1 1 1 1 0 0 0 2 2\n",
            " 2 1 1 0 0 2 2]\n",
            "pred [2 1 0 1 2 2 1 1 2 2 0 1 0 1 1 1 1 0 1 0 1 0 2 2 0 1 0 0 0 1 2 2 0 0 0 2 1\n",
            " 2 1 1 0 0 2 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "30 / 50 Training loss: 0.009212013527199074, Tran_Accuracy: 0.9981481432914734, Validation_loss: 0.8019270833333333, Validation_Accuracy: 0.846666693687439\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.88      0.90        16\n",
            "     Neutral       0.75      0.80      0.77        15\n",
            "       Smoke       0.69      0.69      0.69        13\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.79      0.79      0.79        44\n",
            "weighted avg       0.80      0.80      0.80        44\n",
            "\n",
            "\n",
            "30 th epoch\n",
            "gt [2 1 0 0 0 2 1 1 1 2 0 1 2 2 2 1 2 1 2 0 2 1 2 2 0 1 0 2 2 2 0 2 0 1 1 1 0\n",
            " 0 1 1 2 1 0 1]\n",
            "pred [2 1 0 0 0 2 1 1 1 1 0 1 1 2 1 1 0 1 1 0 2 1 2 2 0 1 0 2 2 2 2 2 0 1 1 1 1\n",
            " 0 1 0 2 1 0 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "31 / 50 Training loss: 0.0189453125, Tran_Accuracy: 0.9929629564285278, Validation_loss: 0.9284895833333333, Validation_Accuracy: 0.800000011920929\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.83      0.83      0.83        12\n",
            "     Neutral       0.75      0.94      0.83        16\n",
            "       Smoke       0.92      0.69      0.79        16\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.83      0.82      0.82        44\n",
            "weighted avg       0.83      0.82      0.82        44\n",
            "\n",
            "\n",
            "31 th epoch\n",
            "gt [2 2 2 2 0 1 2 0 0 0 2 0 2 0 0 1 2 2 2 0 1 0 2 0 2 0 1 0 1 0 0 2 0 0 1 2 1\n",
            " 1 1 1 1 2 2 2]\n",
            "pred [2 2 1 2 0 1 2 0 0 0 1 0 2 0 0 1 2 1 1 0 2 0 2 0 2 0 1 0 2 0 0 1 0 0 1 2 1\n",
            " 1 1 1 2 1 2 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "32 / 50 Training loss: 0.025133418330439816, Tran_Accuracy: 0.9918518662452698, Validation_loss: 0.8661653645833334, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      1.00      1.00        16\n",
            "     Neutral       0.53      0.73      0.62        11\n",
            "       Smoke       0.77      0.59      0.67        17\n",
            "\n",
            "    accuracy                           0.77        44\n",
            "   macro avg       0.77      0.77      0.76        44\n",
            "weighted avg       0.79      0.77      0.78        44\n",
            "\n",
            "\n",
            "32 th epoch\n",
            "gt [1 0 2 0 0 0 0 2 1 1 1 0 2 0 0 0 0 2 2 2 0 2 2 1 0 0 1 2 2 0 0 1 2 1 0 1 0\n",
            " 2 0 2 2 0 2 1]\n",
            "pred [1 0 1 1 0 2 0 2 1 1 2 0 2 0 0 0 2 2 0 2 0 2 2 1 0 0 1 2 1 0 0 1 2 1 1 1 0\n",
            " 1 0 2 2 0 2 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "33 / 50 Training loss: 0.015296715630425348, Tran_Accuracy: 0.9951851963996887, Validation_loss: 0.8105729166666666, Validation_Accuracy: 0.8299999833106995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.94      0.79      0.86        19\n",
            "     Neutral       0.64      0.90      0.75        10\n",
            "       Smoke       0.79      0.73      0.76        15\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.79      0.81      0.79        44\n",
            "weighted avg       0.82      0.80      0.80        44\n",
            "\n",
            "\n",
            "33 th epoch\n",
            "gt [0 1 1 2 0 0 2 2 1 1 1 0 1 0 0 2 0 0 2 2 0 0 0 0 2 2 1 2 0 0 0 0 0 2 2 0 2\n",
            " 0 2 1 1 0 2 2]\n",
            "pred [0 1 2 2 2 0 2 2 1 1 1 0 1 0 0 2 0 0 2 1 0 0 0 0 2 2 2 2 0 0 0 0 2 2 1 1 2\n",
            " 0 1 2 2 0 1 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "34 / 50 Training loss: 0.010591716059932003, Tran_Accuracy: 0.9970370531082153, Validation_loss: 1.0455078125, Validation_Accuracy: 0.8100000023841858\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.85      0.92        20\n",
            "     Neutral       0.45      0.56      0.50         9\n",
            "       Smoke       0.62      0.67      0.65        15\n",
            "\n",
            "    accuracy                           0.73        44\n",
            "   macro avg       0.69      0.69      0.69        44\n",
            "weighted avg       0.76      0.73      0.74        44\n",
            "\n",
            "\n",
            "34 th epoch\n",
            "gt [1 2 2 2 2 0 2 1 1 2 1 2 1 0 2 2 1 1 0 0 2 0 0 2 0 1 0 2 2 2 1 1 1 0 1 0 0\n",
            " 0 0 1 0 0 0 0]\n",
            "pred [1 2 2 2 1 0 2 1 1 2 2 2 1 0 2 2 1 1 0 0 2 0 0 2 0 0 0 1 2 1 0 1 2 0 1 0 0\n",
            " 2 0 1 0 0 0 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "35 / 50 Training loss: 0.005021373607494213, Tran_Accuracy: 0.9981481432914734, Validation_loss: 0.894765625, Validation_Accuracy: 0.8333333134651184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.88      0.88      0.88        17\n",
            "     Neutral       0.69      0.69      0.69        13\n",
            "       Smoke       0.79      0.79      0.79        14\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.79      0.79      0.79        44\n",
            "weighted avg       0.80      0.80      0.80        44\n",
            "\n",
            "\n",
            "35 th epoch\n",
            "gt [1 1 1 2 2 0 2 1 1 0 0 1 0 1 2 0 1 0 0 0 1 1 1 0 0 1 2 0 2 0 0 0 1 0 2 2 0\n",
            " 2 1 0 1 2 1 2]\n",
            "pred [1 2 2 2 2 0 2 1 2 0 0 1 0 1 2 0 1 0 0 0 1 1 1 0 0 2 2 0 2 0 0 0 1 0 2 2 0\n",
            " 1 1 2 1 1 1 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "36 / 50 Training loss: 0.018797711972837094, Tran_Accuracy: 0.9940740466117859, Validation_loss: 1.0595833333333333, Validation_Accuracy: 0.8133333325386047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.94      0.97        17\n",
            "     Neutral       0.86      0.75      0.80        16\n",
            "       Smoke       0.64      0.82      0.72        11\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.83      0.84      0.83        44\n",
            "weighted avg       0.86      0.84      0.85        44\n",
            "\n",
            "\n",
            "36 th epoch\n",
            "gt [1 0 1 0 2 0 2 1 2 2 1 0 1 0 0 2 2 1 2 1 2 1 1 0 2 0 1 1 0 0 1 1 1 2 1 0 1\n",
            " 1 1 1 2 0 0 0]\n",
            "pred [1 0 1 0 2 0 2 1 2 1 2 0 1 1 0 2 2 2 2 1 2 2 2 0 2 0 1 1 2 0 1 1 0 1 1 0 1\n",
            " 1 2 1 2 0 0 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "37 / 50 Training loss: 0.007977135976155599, Tran_Accuracy: 0.9981481432914734, Validation_loss: 0.9566666666666667, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.92      0.86      0.89        14\n",
            "     Neutral       0.81      0.68      0.74        19\n",
            "       Smoke       0.60      0.82      0.69        11\n",
            "\n",
            "    accuracy                           0.77        44\n",
            "   macro avg       0.78      0.79      0.77        44\n",
            "weighted avg       0.79      0.77      0.78        44\n",
            "\n",
            "\n",
            "37 th epoch\n",
            "gt [1 2 1 1 2 0 1 0 2 1 0 0 1 1 2 1 0 0 1 1 2 0 1 2 2 1 1 0 1 1 2 1 0 1 1 2 2\n",
            " 0 0 1 1 2 2 0]\n",
            "pred [1 2 1 2 2 0 1 0 2 0 0 0 1 1 2 1 0 0 2 0 2 0 0 2 1 1 1 0 0 1 2 0 1 1 1 2 2\n",
            " 0 0 1 1 2 2 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "38 / 50 Training loss: 0.005976765950520833, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.1028125, Validation_Accuracy: 0.8266666531562805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.69      0.92      0.79        12\n",
            "     Neutral       0.87      0.65      0.74        20\n",
            "       Smoke       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.80      0.83      0.80        44\n",
            "weighted avg       0.81      0.80      0.79        44\n",
            "\n",
            "\n",
            "38 th epoch\n",
            "gt [0 2 0 2 2 1 0 0 0 2 0 2 0 2 1 0 2 1 2 2 2 0 1 0 2 1 0 1 0 2 0 0 1 2 0 1 2\n",
            " 2 2 0 1 1 0 2]\n",
            "pred [0 2 0 2 2 1 0 1 0 2 0 1 0 1 1 0 2 1 2 2 2 0 1 1 2 1 1 1 0 2 0 0 0 2 0 1 1\n",
            " 2 2 0 1 1 0 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "39 / 50 Training loss: 0.007581278483072917, Tran_Accuracy: 0.9981481432914734, Validation_loss: 0.98408203125, Validation_Accuracy: 0.8166666626930237\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.82      0.87        17\n",
            "     Neutral       0.60      0.90      0.72        10\n",
            "       Smoke       1.00      0.82      0.90        17\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.84      0.85      0.83        44\n",
            "weighted avg       0.88      0.84      0.85        44\n",
            "\n",
            "\n",
            "39 th epoch\n",
            "gt [0 0 1 2 0 1 1 0 1 1 2 2 1 0 2 0 1 1 1 0 1 2 0 0 2 2 2 1 0 2 0 2 0 2 0 2 1\n",
            " 0 0 1 1 0 2 1]\n",
            "pred [0 1 1 2 0 1 1 0 1 0 2 2 1 0 2 2 0 1 1 0 1 1 0 0 2 2 1 1 0 2 1 2 0 2 0 2 1\n",
            " 0 0 2 1 0 1 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "40 / 50 Training loss: 0.006318763450339988, Tran_Accuracy: 0.9985185265541077, Validation_loss: 0.9545052083333333, Validation_Accuracy: 0.8366666436195374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.87      0.81      0.84        16\n",
            "     Neutral       0.71      0.80      0.75        15\n",
            "       Smoke       0.83      0.77      0.80        13\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.80      0.79      0.80        44\n",
            "weighted avg       0.80      0.80      0.80        44\n",
            "\n",
            "\n",
            "40 th epoch\n",
            "gt [2 0 1 2 1 1 2 1 1 1 2 0 2 0 2 1 1 1 2 1 0 0 0 2 2 0 1 2 2 2 0 1 1 2 1 2 1\n",
            " 1 0 2 1 0 0 2]\n",
            "pred [2 0 1 1 1 1 2 2 1 1 2 0 2 0 2 1 1 1 2 1 0 0 2 2 0 0 1 1 2 2 0 1 1 1 1 2 1\n",
            " 2 0 2 2 0 0 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "41 / 50 Training loss: 0.003971371120876736, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.04611328125, Validation_Accuracy: 0.8133333325386047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.91      0.91      0.91        11\n",
            "     Neutral       0.82      0.82      0.82        17\n",
            "       Smoke       0.75      0.75      0.75        16\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.83      0.83      0.83        44\n",
            "weighted avg       0.82      0.82      0.82        44\n",
            "\n",
            "\n",
            "41 th epoch\n",
            "gt [0 2 1 2 1 1 2 1 0 1 1 2 1 0 1 1 1 2 1 2 0 2 1 1 2 2 1 1 2 0 1 0 1 2 0 1 0\n",
            " 0 1 0 2 2 1 1]\n",
            "pred [0 2 1 2 1 1 2 2 0 1 2 1 1 0 1 0 1 2 1 2 0 2 1 0 2 2 1 1 1 0 1 0 1 2 0 2 0\n",
            " 0 2 0 2 2 1 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "42 / 50 Training loss: 0.005069749620225695, Tran_Accuracy: 0.9977777600288391, Validation_loss: 1.0043359375, Validation_Accuracy: 0.8166666626930237\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.83      1.00      0.91        10\n",
            "     Neutral       0.88      0.71      0.79        21\n",
            "       Smoke       0.73      0.85      0.79        13\n",
            "\n",
            "    accuracy                           0.82        44\n",
            "   macro avg       0.82      0.85      0.83        44\n",
            "weighted avg       0.83      0.82      0.82        44\n",
            "\n",
            "\n",
            "42 th epoch\n",
            "gt [0 1 2 2 0 0 1 2 0 0 1 1 0 1 2 1 1 0 2 2 0 1 0 0 2 0 2 2 2 0 2 0 0 0 0 2 0\n",
            " 1 2 0 0 1 1 0]\n",
            "pred [0 1 2 2 1 0 1 2 0 0 1 1 0 1 2 1 1 0 2 2 2 1 0 0 2 1 0 1 2 2 2 0 0 0 0 1 0\n",
            " 1 1 0 0 2 1 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "43 / 50 Training loss: 0.003029643871166088, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.0393229166666667, Validation_Accuracy: 0.8033333420753479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.94      0.80      0.86        20\n",
            "     Neutral       0.67      0.91      0.77        11\n",
            "       Smoke       0.75      0.69      0.72        13\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.79      0.80      0.78        44\n",
            "weighted avg       0.82      0.80      0.80        44\n",
            "\n",
            "\n",
            "43 th epoch\n",
            "gt [2 0 2 0 1 0 1 0 1 1 0 2 1 0 1 2 1 0 1 1 1 0 0 0 1 0 2 0 1 2 1 1 2 0 2 2 0\n",
            " 0 1 0 0 2 0 0]\n",
            "pred [2 0 1 0 1 0 1 0 2 1 0 2 2 0 1 1 1 0 1 2 1 0 0 0 1 2 2 0 1 2 1 1 2 1 2 2 0\n",
            " 0 1 0 0 2 0 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "44 / 50 Training loss: 0.004818064371744792, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.0077376302083334, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.89      0.94        19\n",
            "     Neutral       0.80      0.80      0.80        15\n",
            "       Smoke       0.67      0.80      0.73        10\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.82      0.83      0.82        44\n",
            "weighted avg       0.86      0.84      0.85        44\n",
            "\n",
            "\n",
            "44 th epoch\n",
            "gt [0 1 2 0 2 0 2 2 2 2 2 1 0 2 1 1 1 1 0 0 2 1 2 1 2 0 0 1 0 2 0 1 2 0 0 0 1\n",
            " 0 0 0 2 2 0 2]\n",
            "pred [0 1 2 0 2 0 2 1 1 2 2 1 0 0 1 1 1 0 0 0 2 1 2 2 2 0 0 1 0 2 0 1 1 2 0 1 1\n",
            " 2 0 0 2 2 0 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "45 / 50 Training loss: 0.0037723730228565355, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.0909114583333333, Validation_Accuracy: 0.8266666531562805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.88      0.82      0.85        17\n",
            "     Neutral       0.69      0.82      0.75        11\n",
            "       Smoke       0.80      0.75      0.77        16\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.79      0.80      0.79        44\n",
            "weighted avg       0.80      0.80      0.80        44\n",
            "\n",
            "\n",
            "45 th epoch\n",
            "gt [2 2 2 1 2 1 1 0 2 0 2 2 1 1 2 2 0 2 2 2 1 1 2 2 1 2 2 1 0 1 1 0 2 2 0 1 0\n",
            " 0 1 2 2 0 2 0]\n",
            "pred [2 2 2 1 1 1 1 0 2 2 2 1 1 1 2 2 0 2 0 2 1 1 1 2 1 1 1 2 0 1 1 0 2 2 0 1 0\n",
            " 0 1 2 0 0 2 0]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "46 / 50 Training loss: 0.004269775108054832, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.0515234375, Validation_Accuracy: 0.8033333420753479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.82      0.90      0.86        10\n",
            "     Neutral       0.71      0.92      0.80        13\n",
            "       Smoke       0.88      0.67      0.76        21\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.80      0.83      0.80        44\n",
            "weighted avg       0.81      0.80      0.79        44\n",
            "\n",
            "\n",
            "46 th epoch\n",
            "gt [2 0 2 2 1 1 1 2 0 2 2 2 2 1 1 0 0 0 0 0 1 2 1 0 0 2 0 1 1 1 1 1 0 2 1 1 2\n",
            " 1 2 1 2 2 2 1]\n",
            "pred [2 0 2 2 1 1 1 2 0 2 2 2 2 1 2 0 0 0 0 0 1 2 1 0 0 2 0 1 1 1 0 1 0 2 1 1 2\n",
            " 1 2 1 2 2 2 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "47 / 50 Training loss: 0.005408347800925926, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.02064453125, Validation_Accuracy: 0.8399999737739563\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.92      1.00      0.96        11\n",
            "     Neutral       1.00      0.88      0.94        17\n",
            "       Smoke       0.94      1.00      0.97        16\n",
            "\n",
            "    accuracy                           0.95        44\n",
            "   macro avg       0.95      0.96      0.95        44\n",
            "weighted avg       0.96      0.95      0.95        44\n",
            "\n",
            "\n",
            "47 th epoch\n",
            "gt [1 2 0 0 0 0 2 2 0 2 2 1 2 1 1 0 2 2 1 0 0 2 2 0 0 1 0 0 2 2 2 1 1 2 1 0 2\n",
            " 2 0 1 1 0 2 1]\n",
            "pred [0 2 1 0 0 0 2 2 0 2 1 1 1 2 1 0 2 1 1 0 0 2 2 0 0 1 0 0 2 2 2 1 1 2 1 0 2\n",
            " 2 0 1 1 0 1 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "48 / 50 Training loss: 0.0033510335286458335, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.0319140625, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.93      0.93        15\n",
            "     Neutral       0.67      0.83      0.74        12\n",
            "       Smoke       0.93      0.76      0.84        17\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.84      0.84      0.84        44\n",
            "weighted avg       0.86      0.84      0.84        44\n",
            "\n",
            "\n",
            "48 th epoch\n",
            "gt [2 1 1 2 1 2 0 0 2 0 0 2 0 2 0 2 0 0 0 0 2 0 1 2 2 1 2 1 0 2 2 2 1 0 0 0 1\n",
            " 2 0 2 0 0 0 1]\n",
            "pred [2 1 1 2 0 2 0 0 2 0 2 2 1 1 0 2 0 0 0 2 2 0 2 2 1 1 2 1 0 0 1 2 1 0 0 0 1\n",
            " 2 2 2 0 1 0 2]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "49 / 50 Training loss: 0.00189422607421875, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.0890494791666667, Validation_Accuracy: 0.8033333420753479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.88      0.74      0.80        19\n",
            "     Neutral       0.55      0.67      0.60         9\n",
            "       Smoke       0.71      0.75      0.73        16\n",
            "\n",
            "    accuracy                           0.73        44\n",
            "   macro avg       0.71      0.72      0.71        44\n",
            "weighted avg       0.75      0.73      0.73        44\n",
            "\n",
            "\n",
            "49 th epoch\n",
            "gt [1 1 1 2 2 2 0 2 2 2 2 0 1 2 2 1 1 2 2 2 0 2 2 1 0 0 1 1 0 1 2 2 0 2 1 0 2\n",
            " 1 0 0 1 1 1 2]\n",
            "pred [0 1 1 2 2 2 0 2 2 2 1 0 1 2 2 1 1 2 2 2 0 2 0 1 0 0 1 2 0 1 2 2 0 2 2 0 0\n",
            " 1 0 0 1 1 1 1]\n",
            "['Fire', 'Neutral', 'Smoke']\n",
            "50 / 50 Training loss: 0.006218689812554253, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.0199153645833334, Validation_Accuracy: 0.8199999928474426\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.77      1.00      0.87        10\n",
            "     Neutral       0.86      0.80      0.83        15\n",
            "       Smoke       0.88      0.79      0.83        19\n",
            "\n",
            "    accuracy                           0.84        44\n",
            "   macro avg       0.84      0.86      0.84        44\n",
            "weighted avg       0.85      0.84      0.84        44\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpYTl7fvHYBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for 20 epochs start @ 11:04 pm  ends @ 11:20 pm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7caXvxZaiqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for 50 epochs start @ 10:46 @11:59"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DATg56Aw2yY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for 200 epochs start @7:07"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ibes-kZ2m4k",
        "colab_type": "code",
        "outputId": "fba21d51-3f49-4e72-c951-c240bca6b4af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_epochs = 200\n",
        "model,p,t = model_traing_and_validation_loop(Model, n_epochs, 'fire-flame.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 th epoch\n",
            "gt [1 2 1 0 0 0 1 2 2 2 2 2 0 1 1 2 2 2 1 0 0 2 2 1 0 0 2 1 1 0 0 2 1 1 0 0 0\n",
            " 0 2 1 0 1 0 2]\n",
            "pred [0 2 1 0 0 2 1 1 1 2 2 2 0 1 1 0 2 2 2 0 0 2 2 2 0 1 2 2 2 1 0 2 1 0 0 0 0\n",
            " 0 2 2 1 1 2 2]\n",
            "1 / 200 Training loss: 0.9309541377314815, Tran_Accuracy: 0.652222216129303, Validation_loss: 0.713828125, Validation_Accuracy: 0.6966666579246521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.79      0.69      0.73        16\n",
            "     Neutral       0.55      0.46      0.50        13\n",
            "       Smoke       0.63      0.80      0.71        15\n",
            "\n",
            "    accuracy                           0.66        44\n",
            "   macro avg       0.65      0.65      0.65        44\n",
            "weighted avg       0.66      0.66      0.66        44\n",
            "\n",
            "--------------------------Saving Model---------------------------\n",
            "1 th epoch\n",
            "gt [0 2 2 2 2 2 2 0 1 2 2 0 2 2 0 2 1 1 0 0 2 0 0 1 0 2 2 0 0 1 1 1 2 1 0 2 2\n",
            " 0 1 1 2 0 0 2]\n",
            "pred [0 1 2 1 2 1 2 0 1 2 1 0 2 0 0 2 1 1 0 0 2 0 0 1 0 1 2 0 0 1 1 1 2 1 0 1 1\n",
            " 0 1 1 2 0 0 1]\n",
            "2 / 200 Training loss: 0.5857067418981482, Tran_Accuracy: 0.7907407283782959, Validation_loss: 0.6546809895833333, Validation_Accuracy: 0.7666666507720947\n",
            "--------------------------Saving Model---------------------------\n",
            "2 th epoch\n",
            "gt [2 1 2 0 1 2 1 1 1 2 2 2 2 1 0 1 0 0 0 2 0 0 0 2 0 1 2 2 0 0 0 0 0 0 2 1 0\n",
            " 2 1 2 0 1 2 2]\n",
            "pred [2 1 2 0 1 2 1 0 1 2 2 1 2 2 0 1 0 0 0 1 0 0 0 2 0 1 0 2 0 0 0 0 0 0 2 1 0\n",
            " 2 2 2 0 1 2 2]\n",
            "3 / 200 Training loss: 0.49116789641203706, Tran_Accuracy: 0.8151851892471313, Validation_loss: 0.6882877604166666, Validation_Accuracy: 0.7566666603088379\n",
            "3 th epoch\n",
            "gt [0 0 2 1 2 1 2 1 2 0 0 1 1 2 2 2 0 1 1 1 1 0 2 2 0 2 0 1 1 2 0 2 2 1 0 0 1\n",
            " 1 0 2 0 1 2 1]\n",
            "pred [2 0 2 2 2 1 2 1 2 0 0 1 2 2 2 2 0 0 1 2 2 0 2 1 0 2 0 2 1 2 0 2 2 0 0 0 2\n",
            " 1 2 2 0 1 2 0]\n",
            "4 / 200 Training loss: 0.5014644820601852, Tran_Accuracy: 0.8174074292182922, Validation_loss: 0.65150390625, Validation_Accuracy: 0.7366666793823242\n",
            "4 th epoch\n",
            "gt [0 2 0 1 0 1 2 2 2 1 0 1 0 0 2 2 2 0 0 2 0 0 1 0 0 1 1 2 0 1 1 0 0 0 0 2 1\n",
            " 1 2 2 2 1 2 0]\n",
            "pred [0 2 0 1 0 2 2 2 2 0 0 1 0 0 2 2 1 0 0 2 0 0 2 2 0 1 1 2 0 2 1 0 0 1 0 2 1\n",
            " 1 2 2 1 1 1 0]\n",
            "5 / 200 Training loss: 0.44951786747685185, Tran_Accuracy: 0.8333333134651184, Validation_loss: 0.5108072916666667, Validation_Accuracy: 0.7933333516120911\n",
            "--------------------------Saving Model---------------------------\n",
            "5 th epoch\n",
            "gt [1 1 0 1 0 2 1 2 2 1 2 0 1 0 1 1 2 1 0 0 1 0 0 1 1 0 2 1 0 2 1 0 2 0 1 2 0\n",
            " 0 0 0 1 2 0 2]\n",
            "pred [1 1 0 1 0 0 1 2 2 2 2 0 2 0 2 1 2 1 2 0 0 1 0 1 1 0 2 1 0 2 1 0 2 0 0 2 0\n",
            " 0 0 2 2 2 0 2]\n",
            "6 / 200 Training loss: 0.39550853587962964, Tran_Accuracy: 0.8448148369789124, Validation_loss: 0.6028385416666666, Validation_Accuracy: 0.7799999713897705\n",
            "6 th epoch\n",
            "gt [0 2 0 2 1 2 1 2 1 0 2 0 0 1 1 0 1 1 0 2 1 1 1 0 1 2 0 1 2 2 2 1 1 1 0 1 2\n",
            " 2 0 2 0 2 1 1]\n",
            "pred [0 2 0 2 1 2 1 1 2 0 2 0 0 2 1 0 1 1 0 0 1 0 1 0 1 2 0 2 2 2 1 1 1 1 0 1 2\n",
            " 2 0 2 0 2 1 0]\n",
            "7 / 200 Training loss: 0.36221100983796295, Tran_Accuracy: 0.8659259080886841, Validation_loss: 0.5359700520833334, Validation_Accuracy: 0.8199999928474426\n",
            "--------------------------Saving Model---------------------------\n",
            "7 th epoch\n",
            "gt [0 2 2 0 1 0 1 2 2 1 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 0 2 2 1 0 1 0 2 1 0 2 2\n",
            " 0 0 2 2 2 2 1]\n",
            "pred [0 2 2 0 2 0 1 2 2 1 0 0 0 0 1 1 1 2 1 0 1 1 2 1 1 0 1 2 1 0 2 0 2 1 0 2 2\n",
            " 0 0 2 1 2 2 1]\n",
            "8 / 200 Training loss: 0.3306325954861111, Tran_Accuracy: 0.8748148083686829, Validation_loss: 0.53892578125, Validation_Accuracy: 0.8133333325386047\n",
            "8 th epoch\n",
            "gt [1 1 2 0 1 0 1 0 0 2 2 2 2 2 1 1 2 2 2 0 1 0 1 2 2 1 1 1 0 0 0 1 2 2 2 2 1\n",
            " 0 0 0 0 2 1 1]\n",
            "pred [1 1 2 0 1 0 1 0 0 2 2 2 2 2 1 1 2 2 2 0 2 0 1 2 2 1 1 1 0 0 0 2 2 2 0 2 1\n",
            " 0 0 0 0 2 0 1]\n",
            "9 / 200 Training loss: 0.34273817274305557, Tran_Accuracy: 0.8718518614768982, Validation_loss: 0.5953255208333333, Validation_Accuracy: 0.800000011920929\n",
            "9 th epoch\n",
            "gt [1 2 2 2 1 0 1 0 1 0 2 0 1 2 1 2 2 0 2 1 2 0 0 2 1 0 1 0 1 0 0 0 1 0 1 0 1\n",
            " 2 2 0 1 2 0 2]\n",
            "pred [1 2 2 2 1 0 1 0 0 0 2 0 2 1 1 2 2 0 2 1 2 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 1\n",
            " 2 2 0 1 2 0 2]\n",
            "10 / 200 Training loss: 0.3207295283564815, Tran_Accuracy: 0.881851851940155, Validation_loss: 0.6447037760416666, Validation_Accuracy: 0.7933333516120911\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.94      1.00      0.97        16\n",
            "     Neutral       0.86      0.86      0.86        14\n",
            "       Smoke       0.92      0.86      0.89        14\n",
            "\n",
            "    accuracy                           0.91        44\n",
            "   macro avg       0.91      0.90      0.91        44\n",
            "weighted avg       0.91      0.91      0.91        44\n",
            "\n",
            "10 th epoch\n",
            "gt [0 2 2 0 2 2 2 2 1 2 2 1 0 2 0 0 0 1 0 1 2 1 1 1 2 2 0 1 1 0 2 0 2 0 2 1 1\n",
            " 1 1 2 2 0 0 0]\n",
            "pred [0 2 1 0 1 1 2 2 2 2 2 0 0 2 2 0 0 1 0 1 2 0 1 1 2 2 0 0 1 0 2 0 2 0 2 1 1\n",
            " 1 1 2 2 0 0 2]\n",
            "11 / 200 Training loss: 0.29414094147858794, Tran_Accuracy: 0.8948147892951965, Validation_loss: 0.6330729166666667, Validation_Accuracy: 0.800000011920929\n",
            "11 th epoch\n",
            "gt [2 1 0 2 2 2 2 2 0 2 2 1 2 2 0 0 0 2 1 1 0 0 0 0 2 1 0 0 2 2 2 2 2 2 1 2 2\n",
            " 1 2 1 2 1 1 0]\n",
            "pred [2 1 0 2 1 2 2 2 0 2 2 1 2 2 0 0 2 2 1 1 2 2 0 0 2 1 0 0 2 2 2 2 2 2 1 2 1\n",
            " 1 2 2 2 1 1 0]\n",
            "12 / 200 Training loss: 0.2863179976851852, Tran_Accuracy: 0.8981481194496155, Validation_loss: 0.6663248697916667, Validation_Accuracy: 0.7900000214576721\n",
            "12 th epoch\n",
            "gt [2 2 0 0 1 1 0 2 2 2 0 0 1 0 0 0 1 2 2 0 0 2 1 2 1 0 1 1 1 0 1 0 1 2 2 1 2\n",
            " 2 1 1 1 2 0 2]\n",
            "pred [2 2 0 0 2 1 0 2 2 1 0 0 1 0 0 1 0 2 2 0 0 2 2 2 2 0 1 1 0 0 1 0 2 2 2 1 2\n",
            " 2 1 1 1 1 0 2]\n",
            "13 / 200 Training loss: 0.2847996238425926, Tran_Accuracy: 0.8948147892951965, Validation_loss: 0.6112434895833333, Validation_Accuracy: 0.7933333516120911\n",
            "13 th epoch\n",
            "gt [1 0 0 1 1 0 1 0 0 0 0 0 2 1 1 0 2 1 2 2 1 1 0 1 2 1 1 0 1 1 0 0 2 1 0 0 0\n",
            " 2 2 1 2 2 0 1]\n",
            "pred [0 0 0 1 1 0 2 0 0 2 1 0 2 1 1 0 1 1 1 2 1 1 2 2 2 2 2 0 1 1 0 0 2 1 0 0 0\n",
            " 2 2 1 2 2 0 1]\n",
            "14 / 200 Training loss: 0.24694733796296298, Tran_Accuracy: 0.9092592597007751, Validation_loss: 0.6889973958333333, Validation_Accuracy: 0.7900000214576721\n",
            "14 th epoch\n",
            "gt [0 2 0 2 0 2 2 0 2 0 0 2 2 0 0 1 2 2 2 2 2 1 1 1 2 0 2 2 0 1 0 1 1 1 2 2 2\n",
            " 2 2 1 1 2 2 2]\n",
            "pred [0 2 0 1 0 1 1 2 1 0 0 1 2 0 0 2 2 2 2 2 2 0 2 1 1 0 1 2 0 1 0 1 1 1 2 1 2\n",
            " 2 2 1 1 2 1 1]\n",
            "15 / 200 Training loss: 0.24682725694444443, Tran_Accuracy: 0.903333306312561, Validation_loss: 0.5799869791666666, Validation_Accuracy: 0.7766666412353516\n",
            "15 th epoch\n",
            "gt [1 2 1 0 2 2 2 2 0 2 1 0 0 2 1 2 0 2 2 1 0 2 2 0 2 0 2 1 0 0 2 1 0 1 2 1 2\n",
            " 1 2 0 1 0 1 1]\n",
            "pred [1 2 1 0 2 2 1 1 0 2 1 0 1 2 1 2 0 2 2 2 0 1 2 0 2 0 1 2 0 0 2 1 0 2 2 1 1\n",
            " 0 2 0 1 0 1 1]\n",
            "16 / 200 Training loss: 0.23985460069444445, Tran_Accuracy: 0.9037036895751953, Validation_loss: 0.58931640625, Validation_Accuracy: 0.8033333420753479\n",
            "16 th epoch\n",
            "gt [0 1 2 0 1 1 2 0 2 2 2 1 2 0 1 0 2 1 1 1 2 1 2 2 2 0 1 2 1 2 1 1 2 1 1 0 0\n",
            " 1 1 1 2 0 2 1]\n",
            "pred [0 1 2 0 1 1 2 0 2 2 2 1 2 0 1 0 1 2 1 0 2 2 2 2 2 0 2 2 0 2 1 1 2 1 1 0 0\n",
            " 1 2 1 1 0 2 1]\n",
            "17 / 200 Training loss: 0.178837890625, Tran_Accuracy: 0.9422222375869751, Validation_loss: 0.7064388020833333, Validation_Accuracy: 0.8033333420753479\n",
            "17 th epoch\n",
            "gt [0 2 0 1 0 2 2 0 2 0 0 0 1 2 0 0 0 0 0 2 2 1 2 1 2 1 2 1 1 1 2 1 0 0 1 0 1\n",
            " 1 1 1 2 0 1 1]\n",
            "pred [0 1 0 1 0 2 2 0 2 0 2 0 1 1 2 0 0 0 0 0 2 1 2 1 1 1 2 1 1 1 2 1 0 0 1 0 0\n",
            " 2 2 2 2 0 2 2]\n",
            "18 / 200 Training loss: 0.1858474392361111, Tran_Accuracy: 0.9322222471237183, Validation_loss: 0.6451953125, Validation_Accuracy: 0.7900000214576721\n",
            "18 th epoch\n",
            "gt [0 0 2 2 2 1 0 0 1 1 2 0 1 1 0 1 2 2 2 1 0 0 2 1 0 1 2 1 2 2 2 1 1 1 1 1 1\n",
            " 2 2 2 0 1 0 2]\n",
            "pred [0 0 2 1 2 1 0 0 2 2 1 0 1 1 0 1 2 2 2 1 0 0 2 2 0 1 2 2 2 2 2 1 1 1 2 2 1\n",
            " 2 2 2 0 1 0 2]\n",
            "19 / 200 Training loss: 0.2003074363425926, Tran_Accuracy: 0.9262962937355042, Validation_loss: 0.6414583333333334, Validation_Accuracy: 0.7599999904632568\n",
            "19 th epoch\n",
            "gt [2 2 0 0 0 1 2 0 1 0 2 2 2 1 1 0 1 1 1 1 2 0 0 1 0 0 2 1 1 0 1 0 0 0 1 0 0\n",
            " 1 0 2 1 2 2 2]\n",
            "pred [2 2 0 0 0 1 1 1 2 0 2 2 2 2 2 0 1 0 1 1 2 0 1 1 2 0 2 2 2 0 2 0 0 0 1 0 0\n",
            " 1 0 2 1 1 2 2]\n",
            "20 / 200 Training loss: 0.17137912326388888, Tran_Accuracy: 0.9388889074325562, Validation_loss: 0.75478515625, Validation_Accuracy: 0.79666668176651\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.93      0.82      0.87        17\n",
            "     Neutral       0.67      0.53      0.59        15\n",
            "       Smoke       0.59      0.83      0.69        12\n",
            "\n",
            "    accuracy                           0.73        44\n",
            "   macro avg       0.73      0.73      0.72        44\n",
            "weighted avg       0.75      0.73      0.73        44\n",
            "\n",
            "20 th epoch\n",
            "gt [1 0 1 2 2 1 2 2 2 0 0 2 0 0 1 2 1 1 2 2 1 1 1 1 2 1 2 2 1 2 0 1 1 0 1 0 1\n",
            " 1 0 1 2 2 1 2]\n",
            "pred [1 0 2 2 2 1 1 1 2 1 0 2 0 0 1 2 0 1 2 2 0 1 1 1 2 0 1 2 0 2 0 1 2 0 1 0 1\n",
            " 1 0 1 2 2 1 2]\n",
            "21 / 200 Training loss: 0.10632281268084491, Tran_Accuracy: 0.9629629850387573, Validation_loss: 0.7054557291666667, Validation_Accuracy: 0.8166666626930237\n",
            "21 th epoch\n",
            "gt [2 1 0 1 2 0 1 0 0 2 1 2 0 1 1 2 0 2 1 0 1 0 2 1 0 1 0 0 0 2 1 1 2 1 1 1 1\n",
            " 0 2 2 1 1 1 0]\n",
            "pred [2 1 0 1 2 0 0 0 0 0 2 2 0 2 1 2 0 2 0 2 1 0 2 1 0 1 0 0 1 2 2 0 2 1 1 0 2\n",
            " 0 2 0 2 1 1 0]\n",
            "22 / 200 Training loss: 0.045631465205439814, Tran_Accuracy: 0.9896296262741089, Validation_loss: 0.7552604166666667, Validation_Accuracy: 0.800000011920929\n",
            "22 th epoch\n",
            "gt [2 1 2 1 2 1 0 1 1 0 2 1 0 1 0 0 2 0 0 0 0 0 2 0 2 0 1 1 1 1 1 2 1 0 1 1 0\n",
            " 1 1 2 2 0 1 1]\n",
            "pred [2 1 2 2 2 0 0 2 1 0 1 1 1 0 0 0 1 0 2 0 0 0 2 0 1 0 1 1 1 1 0 2 1 0 2 1 0\n",
            " 1 1 2 1 0 1 1]\n",
            "23 / 200 Training loss: 0.035304542824074074, Tran_Accuracy: 0.9914814829826355, Validation_loss: 0.7600911458333334, Validation_Accuracy: 0.8166666626930237\n",
            "23 th epoch\n",
            "gt [0 2 0 0 0 1 2 1 0 1 0 2 2 1 1 2 1 2 2 2 0 1 1 0 0 1 2 2 1 2 0 0 0 1 2 1 1\n",
            " 0 0 1 0 2 2 1]\n",
            "pred [0 2 0 0 0 1 2 1 0 1 0 2 2 1 1 2 0 2 2 2 1 1 1 0 0 1 1 2 2 2 0 0 0 1 2 2 1\n",
            " 0 2 1 0 2 2 2]\n",
            "24 / 200 Training loss: 0.024187825520833334, Tran_Accuracy: 0.9929629564285278, Validation_loss: 0.8271809895833333, Validation_Accuracy: 0.8066666722297668\n",
            "24 th epoch\n",
            "gt [1 1 2 0 0 1 1 0 1 1 1 1 0 2 0 0 0 0 2 2 2 0 2 1 1 1 2 1 2 0 1 1 1 1 0 2 0\n",
            " 2 0 1 2 1 1 1]\n",
            "pred [1 1 2 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 2 2 1 0 2 1 0 1 2 2 2 0 1 0 0 1 0 2 0\n",
            " 2 0 2 2 1 1 1]\n",
            "25 / 200 Training loss: 0.022704173900462962, Tran_Accuracy: 0.9933333396911621, Validation_loss: 0.9023046875, Validation_Accuracy: 0.79666668176651\n",
            "25 th epoch\n",
            "gt [1 2 0 2 1 2 1 0 1 0 1 1 2 0 1 1 2 0 2 2 2 2 0 0 0 1 2 2 2 1 1 2 0 2 0 1 1\n",
            " 2 1 2 1 0 0 2]\n",
            "pred [1 1 1 2 1 2 2 0 1 0 1 1 2 0 1 1 2 0 2 2 2 2 0 0 0 2 2 2 2 1 1 2 0 1 0 1 1\n",
            " 2 1 1 1 0 0 2]\n",
            "26 / 200 Training loss: 0.028294270833333333, Tran_Accuracy: 0.9907407164573669, Validation_loss: 0.8466796875, Validation_Accuracy: 0.8033333420753479\n",
            "26 th epoch\n",
            "gt [0 0 0 1 1 2 2 1 0 2 0 1 1 0 2 1 0 2 2 0 1 1 1 0 1 2 1 1 2 0 0 1 0 1 0 1 1\n",
            " 0 1 0 0 2 0 1]\n",
            "pred [2 0 0 1 2 2 1 1 0 2 0 1 1 0 2 1 2 2 2 0 1 1 2 0 1 2 1 0 2 0 0 1 1 1 0 1 1\n",
            " 0 2 0 0 2 0 1]\n",
            "27 / 200 Training loss: 0.013769796865957754, Tran_Accuracy: 0.9962962865829468, Validation_loss: 0.8812630208333333, Validation_Accuracy: 0.8066666722297668\n",
            "27 th epoch\n",
            "gt [2 1 1 1 2 1 0 0 0 2 2 1 1 1 1 1 2 1 1 2 0 0 0 1 0 0 1 0 2 2 0 1 2 2 1 1 1\n",
            " 1 2 2 0 1 1 1]\n",
            "pred [0 1 1 1 2 1 0 0 0 2 2 2 1 1 1 1 2 1 0 2 0 0 0 0 2 0 1 2 2 2 0 1 2 2 1 1 2\n",
            " 2 2 1 0 1 1 1]\n",
            "28 / 200 Training loss: 0.011374873408564815, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.0110286458333333, Validation_Accuracy: 0.7900000214576721\n",
            "28 th epoch\n",
            "gt [1 1 1 0 0 2 0 1 0 0 2 0 1 0 1 0 0 2 0 2 1 1 2 1 2 0 0 0 2 1 2 1 2 1 2 1 2\n",
            " 0 2 2 1 1 1 0]\n",
            "pred [1 2 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 2 2 1 2 1 2 0 0 0 1 1 2 1 2 2 2 2 2\n",
            " 0 2 2 0 1 1 0]\n",
            "29 / 200 Training loss: 0.013487413194444445, Tran_Accuracy: 0.9970370531082153, Validation_loss: 0.90228515625, Validation_Accuracy: 0.8033333420753479\n",
            "29 th epoch\n",
            "gt [1 1 0 1 2 0 0 1 2 1 2 2 1 0 0 1 2 2 2 1 0 2 2 1 1 0 0 0 1 0 2 2 2 1 0 2 1\n",
            " 0 1 2 1 1 0 1]\n",
            "pred [2 1 0 1 1 0 0 2 2 1 2 2 1 0 0 1 2 2 2 1 0 1 2 1 0 0 0 0 2 0 2 1 2 1 0 2 1\n",
            " 0 1 2 1 1 0 2]\n",
            "30 / 200 Training loss: 0.020413004557291666, Tran_Accuracy: 0.995555579662323, Validation_loss: 0.9586263020833333, Validation_Accuracy: 0.8066666722297668\n",
            "30 th epoch\n",
            "gt [1 0 2 0 0 1 2 0 2 1 1 1 2 0 1 2 1 1 0 2 0 0 1 2 1 0 0 0 2 2 0 0 2 1 2 0 1\n",
            " 1 1 1 0 0 2 1]\n",
            "pred [1 0 2 0 2 2 1 0 2 1 1 1 2 0 1 2 1 1 0 2 0 0 2 1 1 0 0 0 2 1 0 0 2 1 2 0 1\n",
            " 2 1 1 0 0 2 0]\n",
            "31 / 200 Training loss: 0.007792810510706018, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.0188020833333333, Validation_Accuracy: 0.8266666531562805\n",
            "--------------------------Saving Model---------------------------\n",
            "31 th epoch\n",
            "gt [1 2 1 1 0 0 2 1 0 2 2 2 0 0 1 1 1 1 2 1 2 1 2 1 1 0 0 1 2 2 0 2 0 2 0 2 2\n",
            " 0 0 1 2 2 2 0]\n",
            "pred [2 1 1 1 0 0 2 1 0 2 2 2 0 0 1 1 2 1 1 2 0 1 2 2 1 0 0 1 2 2 0 2 0 1 0 2 2\n",
            " 0 0 1 1 2 2 0]\n",
            "32 / 200 Training loss: 0.005670199924045139, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.0452408854166666, Validation_Accuracy: 0.8166666626930237\n",
            "32 th epoch\n",
            "gt [0 0 1 0 2 1 0 0 1 2 0 2 1 0 2 2 2 0 0 1 1 2 2 0 2 1 2 2 2 0 1 1 1 2 0 0 2\n",
            " 0 2 1 0 1 2 1]\n",
            "pred [0 0 1 0 2 1 0 0 1 1 0 2 1 0 0 1 2 0 2 1 1 2 2 0 2 2 2 1 2 0 1 2 1 1 0 0 2\n",
            " 0 1 2 0 1 2 1]\n",
            "33 / 200 Training loss: 0.005164111102068865, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.0817708333333333, Validation_Accuracy: 0.8133333325386047\n",
            "33 th epoch\n",
            "gt [2 1 1 0 1 2 0 0 0 2 2 0 1 2 0 0 0 1 2 1 0 0 2 1 0 1 0 2 2 1 2 2 0 0 0 2 1\n",
            " 0 0 0 1 2 1 2]\n",
            "pred [1 2 1 0 1 2 0 0 0 2 2 0 1 2 0 0 0 0 2 1 0 0 2 2 1 1 0 2 2 1 2 1 0 1 0 2 2\n",
            " 0 0 0 1 2 1 1]\n",
            "34 / 200 Training loss: 0.00904390123155382, Tran_Accuracy: 0.9974074363708496, Validation_loss: 1.1188671875, Validation_Accuracy: 0.8166666626930237\n",
            "34 th epoch\n",
            "gt [0 2 1 2 1 2 1 2 1 0 0 0 2 2 0 0 1 2 0 0 0 2 2 2 2 1 0 2 2 2 2 0 2 0 0 2 0\n",
            " 2 2 1 1 1 2 1]\n",
            "pred [0 1 1 2 2 2 1 2 0 0 0 0 2 2 0 0 0 2 2 0 0 2 1 2 1 1 0 2 1 2 2 0 1 0 0 2 0\n",
            " 2 1 1 2 2 1 1]\n",
            "35 / 200 Training loss: 0.010855000813802083, Tran_Accuracy: 0.9962962865829468, Validation_loss: 1.2035416666666667, Validation_Accuracy: 0.7833333611488342\n",
            "35 th epoch\n",
            "gt [2 1 1 0 2 0 2 1 1 1 1 0 0 2 2 2 0 0 2 2 1 2 0 1 0 0 0 0 1 2 0 0 0 2 1 1 0\n",
            " 0 0 2 0 2 0 2]\n",
            "pred [2 1 1 0 2 0 2 1 2 1 1 0 0 2 2 2 0 0 2 2 2 2 0 1 0 0 2 0 1 2 0 0 1 2 1 2 0\n",
            " 0 0 1 0 2 0 2]\n",
            "36 / 200 Training loss: 0.013309507016782407, Tran_Accuracy: 0.996666669845581, Validation_loss: 1.229326171875, Validation_Accuracy: 0.7933333516120911\n",
            "36 th epoch\n",
            "gt [1 2 0 1 0 2 1 2 2 1 0 1 2 1 2 1 1 2 2 1 0 0 1 2 1 1 0 0 0 0 1 0 2 2 0 2 1\n",
            " 0 0 0 2 1 1 0]\n",
            "pred [1 2 0 1 0 2 1 2 2 1 0 1 2 1 2 1 2 2 1 1 0 0 1 2 1 1 0 0 0 0 2 0 2 2 0 2 1\n",
            " 0 2 0 2 1 1 0]\n",
            "37 / 200 Training loss: 0.006528941966869213, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.2355729166666667, Validation_Accuracy: 0.8033333420753479\n",
            "37 th epoch\n",
            "gt [0 1 0 0 2 1 0 0 1 0 1 2 2 1 1 0 2 0 0 2 1 0 1 2 0 0 1 0 2 0 2 2 1 1 0 1 1\n",
            " 0 1 1 2 1 2 1]\n",
            "pred [0 1 0 0 2 1 2 0 1 0 1 1 2 2 1 0 2 0 0 2 1 0 1 1 0 0 1 0 2 0 2 0 2 2 0 1 1\n",
            " 0 1 2 2 1 2 1]\n",
            "38 / 200 Training loss: 0.00610624525282118, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.1233072916666667, Validation_Accuracy: 0.8100000023841858\n",
            "38 th epoch\n",
            "gt [0 0 2 2 1 0 0 2 0 0 2 2 0 0 1 1 2 1 1 0 2 0 0 2 0 0 2 1 0 1 1 0 0 0 2 1 0\n",
            " 1 2 0 2 0 2 0]\n",
            "pred [2 0 2 1 1 2 0 2 0 0 2 1 0 0 2 1 2 1 1 0 2 0 0 2 0 1 2 1 0 2 1 0 0 0 2 1 1\n",
            " 1 2 0 2 0 2 0]\n",
            "39 / 200 Training loss: 0.0070637738263165505, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.2819856770833333, Validation_Accuracy: 0.8133333325386047\n",
            "39 th epoch\n",
            "gt [2 2 2 1 2 0 0 2 0 2 1 2 1 0 1 1 0 2 1 2 0 2 0 2 0 1 0 1 0 2 1 2 2 1 0 1 2\n",
            " 2 2 0 2 0 1 0]\n",
            "pred [2 2 0 1 2 0 0 2 0 2 1 2 1 0 1 1 0 2 1 1 0 1 0 2 1 2 0 0 0 2 0 2 2 1 0 1 1\n",
            " 2 1 0 1 0 1 0]\n",
            "40 / 200 Training loss: 0.029997852466724536, Tran_Accuracy: 0.9907407164573669, Validation_loss: 1.2278385416666666, Validation_Accuracy: 0.79666668176651\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.81      0.93      0.87        14\n",
            "     Neutral       0.60      0.75      0.67        12\n",
            "       Smoke       0.92      0.67      0.77        18\n",
            "\n",
            "    accuracy                           0.77        44\n",
            "   macro avg       0.78      0.78      0.77        44\n",
            "weighted avg       0.80      0.77      0.77        44\n",
            "\n",
            "40 th epoch\n",
            "gt [2 0 1 2 1 0 2 0 2 0 2 0 1 2 0 1 1 1 2 2 2 2 1 0 2 2 0 0 1 1 0 2 1 0 2 2 0\n",
            " 0 2 1 2 2 0 1]\n",
            "pred [2 1 1 2 1 0 1 0 2 2 2 0 1 2 0 1 1 1 2 0 2 2 1 0 1 2 0 0 1 2 0 2 1 0 2 2 0\n",
            " 0 1 0 2 2 0 1]\n",
            "41 / 200 Training loss: 0.02207969382957176, Tran_Accuracy: 0.992222249507904, Validation_loss: 1.1008854166666666, Validation_Accuracy: 0.800000011920929\n",
            "41 th epoch\n",
            "gt [1 0 2 1 2 2 1 0 0 1 1 0 1 0 2 2 2 0 0 0 2 0 0 2 2 2 2 0 2 1 0 0 1 0 2 1 0\n",
            " 0 1 1 2 0 2 1]\n",
            "pred [1 0 1 0 2 2 1 0 0 1 2 0 2 2 2 2 2 0 0 0 1 2 0 2 2 2 2 0 2 1 1 0 2 0 1 1 1\n",
            " 0 0 1 2 0 2 1]\n",
            "42 / 200 Training loss: 0.022866442645037614, Tran_Accuracy: 0.9925925731658936, Validation_loss: 1.133671875, Validation_Accuracy: 0.7866666913032532\n",
            "42 th epoch\n",
            "gt [0 0 0 2 0 0 0 0 1 2 0 0 1 0 2 1 0 2 0 2 1 2 2 0 0 2 0 2 2 0 2 1 2 2 0 1 2\n",
            " 1 1 2 2 1 0 1]\n",
            "pred [0 0 2 2 1 0 0 0 1 2 0 0 1 0 1 1 0 2 0 2 2 1 2 0 0 1 0 2 1 2 2 1 2 2 1 1 2\n",
            " 1 1 2 1 2 0 1]\n",
            "43 / 200 Training loss: 0.006763887052182798, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.083203125, Validation_Accuracy: 0.79666668176651\n",
            "43 th epoch\n",
            "gt [1 0 1 2 1 2 0 2 1 0 2 2 0 1 0 1 0 2 0 2 2 2 1 1 2 0 2 1 1 1 2 2 0 2 1 2 0\n",
            " 2 2 2 1 2 1 0]\n",
            "pred [2 0 1 2 1 2 0 2 1 0 2 1 0 0 0 1 0 2 0 2 2 2 1 1 2 0 2 1 1 1 2 0 0 2 0 2 0\n",
            " 2 2 2 1 2 1 0]\n",
            "44 / 200 Training loss: 0.0036337690000180843, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.0923958333333332, Validation_Accuracy: 0.8166666626930237\n",
            "44 th epoch\n",
            "gt [0 2 1 0 2 0 2 1 1 2 1 2 0 2 1 2 1 1 1 1 0 1 2 2 0 2 0 0 1 0 2 1 2 0 0 1 2\n",
            " 1 2 2 0 1 1 1]\n",
            "pred [0 1 2 0 2 2 2 1 1 2 1 1 0 0 2 2 1 2 0 1 0 1 2 2 0 2 0 0 1 0 1 1 2 0 0 1 2\n",
            " 1 2 2 0 1 2 2]\n",
            "45 / 200 Training loss: 0.0038291366012008104, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.1875390625, Validation_Accuracy: 0.7933333516120911\n",
            "45 th epoch\n",
            "gt [0 1 1 0 2 2 2 1 1 1 0 0 2 2 0 2 0 0 1 0 0 0 1 2 1 1 1 1 2 0 1 0 1 2 1 0 2\n",
            " 2 2 0 0 2 2 1]\n",
            "pred [0 1 1 0 2 2 2 1 1 1 0 0 2 2 0 2 0 0 1 0 0 0 2 2 2 1 2 2 2 0 2 0 1 2 1 0 2\n",
            " 1 2 0 0 2 2 1]\n",
            "46 / 200 Training loss: 0.002784634519506384, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.1233463541666666, Validation_Accuracy: 0.8199999928474426\n",
            "46 th epoch\n",
            "gt [0 0 1 1 1 0 0 0 1 0 2 2 2 2 1 0 0 2 1 1 1 2 1 0 0 1 2 1 1 0 1 2 0 2 1 0 1\n",
            " 1 1 0 0 1 2 2]\n",
            "pred [0 0 2 1 1 0 0 0 1 0 2 2 2 2 2 0 0 2 1 1 2 2 1 0 0 1 2 1 2 0 1 1 0 2 1 0 1\n",
            " 1 2 0 0 1 2 2]\n",
            "47 / 200 Training loss: 0.0033156048810040507, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.1900390625, Validation_Accuracy: 0.8066666722297668\n",
            "47 th epoch\n",
            "gt [2 0 2 0 2 2 0 1 1 1 0 0 2 2 1 2 1 2 1 0 2 0 2 0 1 1 0 1 1 0 2 0 2 0 1 0 2\n",
            " 1 2 0 2 1 1 2]\n",
            "pred [2 2 2 2 2 2 0 1 1 1 0 0 1 2 0 2 1 1 1 1 2 0 0 0 1 2 0 2 1 2 2 0 2 0 2 0 0\n",
            " 1 2 0 2 1 0 2]\n",
            "48 / 200 Training loss: 0.02082847312644676, Tran_Accuracy: 0.9914814829826355, Validation_loss: 1.2696354166666666, Validation_Accuracy: 0.79666668176651\n",
            "48 th epoch\n",
            "gt [1 0 2 2 2 2 0 1 1 0 2 2 1 1 0 0 1 0 0 1 2 2 0 1 0 1 0 2 1 0 0 2 0 1 1 2 0\n",
            " 1 1 1 2 0 0 1]\n",
            "pred [2 2 2 2 2 2 0 1 1 0 0 2 1 1 0 0 2 0 0 1 2 2 0 1 0 2 0 2 1 0 0 1 0 1 1 2 0\n",
            " 1 1 1 2 0 0 1]\n",
            "49 / 200 Training loss: 0.02282883538140191, Tran_Accuracy: 0.9907407164573669, Validation_loss: 1.2456119791666667, Validation_Accuracy: 0.8033333420753479\n",
            "49 th epoch\n",
            "gt [1 0 0 1 2 0 1 2 0 0 0 1 1 2 2 0 2 1 1 1 1 2 2 1 2 2 2 2 2 2 1 0 1 0 2 1 0\n",
            " 0 1 0 2 2 0 1]\n",
            "pred [1 0 0 0 2 0 1 2 2 0 0 1 1 1 1 0 1 2 1 1 1 2 2 1 2 0 2 2 2 0 0 0 2 0 2 1 0\n",
            " 0 1 0 2 2 0 1]\n",
            "50 / 200 Training loss: 0.005168722647207755, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.1434635416666667, Validation_Accuracy: 0.79666668176651\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.75      0.92      0.83        13\n",
            "     Neutral       0.79      0.73      0.76        15\n",
            "       Smoke       0.79      0.69      0.73        16\n",
            "\n",
            "    accuracy                           0.77        44\n",
            "   macro avg       0.77      0.78      0.77        44\n",
            "weighted avg       0.78      0.77      0.77        44\n",
            "\n",
            "50 th epoch\n",
            "gt [2 1 2 0 0 1 1 0 1 1 2 2 0 1 1 2 2 1 2 2 2 2 2 0 2 1 1 2 1 0 1 2 1 2 0 0 0\n",
            " 2 2 2 1 0 2 0]\n",
            "pred [2 1 1 0 0 1 2 0 1 1 2 2 0 1 1 1 1 1 2 2 1 2 2 0 2 1 1 1 2 0 1 2 1 1 0 0 0\n",
            " 2 2 2 1 0 2 0]\n",
            "51 / 200 Training loss: 0.003368615044487847, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.20671875, Validation_Accuracy: 0.800000011920929\n",
            "51 th epoch\n",
            "gt [1 1 2 1 0 0 2 1 0 1 1 1 2 0 0 0 2 2 1 2 1 2 1 1 0 1 0 0 1 1 2 1 0 2 1 1 2\n",
            " 1 2 0 0 2 0 2]\n",
            "pred [1 2 2 1 0 0 2 2 0 1 2 1 2 0 0 0 2 2 1 2 1 2 1 1 0 2 2 0 1 1 2 2 0 1 1 1 2\n",
            " 1 2 0 0 1 0 2]\n",
            "52 / 200 Training loss: 0.004684848255581326, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.1634505208333332, Validation_Accuracy: 0.8033333420753479\n",
            "52 th epoch\n",
            "gt [1 0 1 1 1 0 2 2 2 2 0 2 2 1 2 0 0 2 0 1 1 0 2 0 0 0 0 0 0 2 0 0 2 2 2 1 2\n",
            " 1 2 1 1 2 0 0]\n",
            "pred [1 0 2 1 1 0 1 1 2 1 0 2 2 1 2 0 0 2 0 1 1 0 2 0 0 0 0 0 0 2 0 0 2 2 2 1 1\n",
            " 1 2 1 0 2 0 0]\n",
            "53 / 200 Training loss: 0.0024889515064380786, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2457486979166668, Validation_Accuracy: 0.8066666722297668\n",
            "53 th epoch\n",
            "gt [1 0 0 1 1 0 1 1 0 1 2 1 0 1 2 1 1 0 0 0 2 0 0 2 0 2 2 1 2 0 0 2 1 1 1 0 2\n",
            " 1 0 1 0 1 2 0]\n",
            "pred [2 0 0 1 2 0 1 1 0 1 2 2 0 1 1 1 2 0 0 0 2 0 0 2 0 2 2 1 2 0 0 2 1 1 1 0 2\n",
            " 1 0 1 2 1 2 0]\n",
            "54 / 200 Training loss: 0.002468287503277814, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2733984375, Validation_Accuracy: 0.8133333325386047\n",
            "54 th epoch\n",
            "gt [1 2 1 0 0 1 0 0 2 2 0 1 2 1 1 2 2 2 1 0 0 1 1 2 0 0 1 1 2 2 0 2 0 0 1 1 0\n",
            " 2 1 1 0 0 1 2]\n",
            "pred [1 2 2 0 0 0 0 0 2 2 0 1 2 0 2 2 2 2 1 0 0 1 1 1 0 0 2 1 2 2 0 1 0 0 0 1 0\n",
            " 2 1 1 0 0 1 2]\n",
            "55 / 200 Training loss: 0.0024750660083912037, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2186979166666667, Validation_Accuracy: 0.7866666913032532\n",
            "55 th epoch\n",
            "gt [0 1 0 0 0 0 0 2 0 2 2 2 1 0 1 0 1 1 1 0 1 2 1 2 2 2 0 1 1 2 1 2 1 2 1 0 0\n",
            " 0 0 2 0 2 0 1]\n",
            "pred [0 1 0 0 2 0 0 2 0 1 2 2 1 0 1 0 1 1 1 0 1 2 0 2 2 2 2 1 1 2 1 2 2 1 0 0 2\n",
            " 0 0 2 0 2 0 1]\n",
            "56 / 200 Training loss: 0.0019032333515308522, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2525651041666668, Validation_Accuracy: 0.79666668176651\n",
            "56 th epoch\n",
            "gt [2 1 2 1 1 2 1 2 2 1 2 2 2 0 2 2 1 1 0 1 2 1 2 2 2 2 0 0 1 2 0 1 2 2 2 0 2\n",
            " 2 2 2 0 2 0 1]\n",
            "pred [2 1 1 1 1 1 0 2 2 1 2 2 2 0 2 2 1 1 0 1 0 1 2 1 2 1 0 0 1 2 0 1 1 2 1 0 0\n",
            " 1 2 2 0 1 0 0]\n",
            "57 / 200 Training loss: 0.002302370424623843, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.124921875, Validation_Accuracy: 0.8033333420753479\n",
            "57 th epoch\n",
            "gt [1 2 2 0 0 1 1 0 2 0 2 2 0 0 2 2 1 0 1 2 0 0 1 2 2 0 2 0 2 0 2 0 2 1 1 0 0\n",
            " 1 2 2 0 0 2 2]\n",
            "pred [1 2 2 0 0 1 1 0 2 0 2 2 0 0 2 2 0 0 1 2 0 0 2 2 2 1 2 0 2 2 2 0 2 1 1 0 0\n",
            " 0 1 2 0 0 2 1]\n",
            "58 / 200 Training loss: 0.002704123037832755, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.1850130208333334, Validation_Accuracy: 0.8066666722297668\n",
            "58 th epoch\n",
            "gt [1 2 2 0 1 0 2 1 0 2 2 1 0 1 2 0 2 1 2 0 1 2 2 1 0 0 2 0 1 2 0 0 1 1 0 0 2\n",
            " 0 2 0 0 1 1 0]\n",
            "pred [1 2 2 0 1 0 1 1 0 2 2 2 0 0 2 0 1 2 2 2 1 2 1 1 0 0 2 0 1 2 0 0 2 1 0 2 2\n",
            " 0 1 0 0 1 1 0]\n",
            "59 / 200 Training loss: 0.0034070022017867476, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.183359375, Validation_Accuracy: 0.8133333325386047\n",
            "59 th epoch\n",
            "gt [2 1 2 2 2 0 0 0 2 2 0 2 1 1 2 1 0 1 1 2 1 0 2 2 0 1 0 0 2 1 1 0 2 0 1 2 0\n",
            " 0 2 2 0 2 0 2]\n",
            "pred [2 1 2 2 1 0 0 0 2 2 0 2 1 2 1 1 0 1 1 1 2 0 2 2 0 1 0 0 1 2 1 0 1 0 1 2 0\n",
            " 0 2 2 0 2 0 2]\n",
            "60 / 200 Training loss: 0.0027020103843123826, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2202864583333333, Validation_Accuracy: 0.8266666531562805\n",
            "60 th epoch\n",
            "gt [1 0 2 1 0 2 0 0 1 1 1 1 2 2 0 1 0 0 2 1 0 2 0 1 2 2 0 1 1 2 2 1 2 0 0 0 2\n",
            " 2 2 2 2 0 2 0]\n",
            "pred [2 0 2 1 0 2 0 0 1 1 1 1 2 0 0 1 0 0 2 0 2 2 0 0 2 1 0 2 1 2 1 1 1 2 0 0 2\n",
            " 0 2 2 1 0 2 0]\n",
            "61 / 200 Training loss: 0.016010151615849247, Tran_Accuracy: 0.9977777600288391, Validation_loss: 1.2118880208333334, Validation_Accuracy: 0.8033333420753479\n",
            "61 th epoch\n",
            "gt [2 2 2 0 0 2 1 2 1 0 2 0 1 0 0 2 0 1 1 2 2 0 1 0 2 1 0 1 2 2 1 0 2 1 1 1 0\n",
            " 2 2 1 1 0 2 2]\n",
            "pred [2 2 2 0 0 2 1 2 2 1 2 0 1 0 0 2 0 1 1 2 2 0 1 0 2 1 0 1 2 2 1 1 1 1 2 1 0\n",
            " 2 2 1 1 0 1 2]\n",
            "62 / 200 Training loss: 0.002290191650390625, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.1476106770833334, Validation_Accuracy: 0.800000011920929\n",
            "62 th epoch\n",
            "gt [1 1 2 0 1 2 1 0 2 0 0 1 2 1 0 2 0 2 0 1 2 1 1 1 1 2 0 1 1 1 1 0 0 0 1 0 2\n",
            " 0 0 0 1 0 2 0]\n",
            "pred [1 2 2 0 1 2 2 2 2 0 0 0 1 1 0 2 0 2 0 1 1 1 1 2 2 2 0 2 1 1 2 0 0 0 1 0 2\n",
            " 0 0 0 1 0 2 0]\n",
            "63 / 200 Training loss: 0.0033161869755497686, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.2683203125, Validation_Accuracy: 0.79666668176651\n",
            "63 th epoch\n",
            "gt [0 2 2 1 1 0 2 0 0 1 2 2 2 1 1 0 1 1 2 0 1 2 2 2 2 0 2 1 2 2 0 2 2 2 2 0 2\n",
            " 0 1 0 0 1 2 1]\n",
            "pred [0 2 2 2 1 0 2 0 0 0 1 2 1 1 1 0 1 1 2 0 1 1 1 2 1 0 2 0 2 2 0 2 2 2 2 0 2\n",
            " 0 1 0 0 1 2 1]\n",
            "64 / 200 Training loss: 0.001592958238389757, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.250234375, Validation_Accuracy: 0.7933333516120911\n",
            "64 th epoch\n",
            "gt [0 0 2 1 0 1 0 0 2 0 0 1 0 1 1 2 0 0 2 0 1 2 2 0 1 0 1 1 0 0 1 0 2 2 2 0 2\n",
            " 2 1 0 1 2 0 0]\n",
            "pred [0 0 1 1 0 1 0 0 2 0 0 1 2 0 1 1 0 0 2 0 2 2 1 2 1 0 1 1 0 2 1 0 2 2 2 0 2\n",
            " 2 1 0 1 2 0 0]\n",
            "65 / 200 Training loss: 0.0024011286982783563, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.266015625, Validation_Accuracy: 0.7900000214576721\n",
            "65 th epoch\n",
            "gt [2 2 1 1 0 0 1 2 0 2 2 0 0 2 0 2 0 1 1 2 2 0 1 2 1 0 1 0 1 0 2 1 1 0 2 0 2\n",
            " 2 1 1 2 2 0 0]\n",
            "pred [2 2 1 0 0 0 1 2 0 1 2 0 0 1 0 1 0 1 1 1 2 0 1 2 2 0 1 2 1 0 1 2 1 0 2 0 2\n",
            " 2 1 1 2 2 0 0]\n",
            "66 / 200 Training loss: 0.0018922565601490163, Tran_Accuracy: 1.0, Validation_loss: 1.2658072916666667, Validation_Accuracy: 0.800000011920929\n",
            "66 th epoch\n",
            "gt [2 1 0 2 1 2 0 1 1 2 1 0 2 1 0 2 2 1 1 2 1 0 2 1 0 2 0 2 2 0 0 2 2 2 2 2 1\n",
            " 2 2 2 1 2 0 1]\n",
            "pred [2 2 1 2 1 2 0 1 2 1 2 0 2 1 0 2 2 1 1 2 1 0 2 1 0 1 0 0 2 0 0 2 2 1 1 1 2\n",
            " 2 2 2 2 2 0 2]\n",
            "67 / 200 Training loss: 0.0029424427173755786, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2527604166666666, Validation_Accuracy: 0.800000011920929\n",
            "67 th epoch\n",
            "gt [2 0 0 1 0 2 1 1 0 0 1 1 0 2 1 0 1 0 0 1 1 0 1 1 2 0 2 1 0 2 0 2 1 0 2 0 0\n",
            " 2 1 2 0 2 2 2]\n",
            "pred [2 0 0 1 0 2 1 1 2 2 1 1 0 1 1 0 2 0 0 0 1 0 1 1 1 0 1 1 0 2 0 2 2 0 2 0 0\n",
            " 2 2 2 0 2 2 2]\n",
            "68 / 200 Training loss: 0.0031971910264756943, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.1905989583333334, Validation_Accuracy: 0.8066666722297668\n",
            "68 th epoch\n",
            "gt [2 1 0 0 0 2 2 1 2 2 1 0 0 0 2 1 0 2 2 1 1 0 1 0 1 2 1 1 2 2 2 0 2 2 1 0 2\n",
            " 0 2 1 1 1 1 0]\n",
            "pred [1 1 0 0 0 1 2 1 2 2 0 2 0 0 1 1 0 2 2 1 1 0 1 0 1 1 1 1 2 2 2 0 2 2 2 0 2\n",
            " 0 2 1 0 1 2 0]\n",
            "69 / 200 Training loss: 0.0017847612169053818, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.1837239583333334, Validation_Accuracy: 0.800000011920929\n",
            "69 th epoch\n",
            "gt [2 0 0 0 0 1 2 0 0 0 2 2 2 2 2 0 1 2 2 1 0 1 0 0 0 2 0 2 2 0 1 2 2 1 2 2 1\n",
            " 2 2 1 1 0 1 0]\n",
            "pred [2 0 0 0 0 1 1 2 0 0 2 2 2 2 1 0 1 2 2 1 0 1 0 0 0 2 0 2 2 0 2 1 2 1 2 1 1\n",
            " 2 2 1 1 0 1 0]\n",
            "70 / 200 Training loss: 0.0018014854855007596, Tran_Accuracy: 1.0, Validation_loss: 1.3139192708333334, Validation_Accuracy: 0.8066666722297668\n",
            "70 th epoch\n",
            "gt [1 0 2 2 1 1 1 2 1 1 1 0 1 0 2 1 1 1 2 0 1 2 1 0 0 1 1 1 2 2 1 0 0 0 2 0 2\n",
            " 0 0 2 2 0 2 2]\n",
            "pred [1 0 1 2 1 1 2 2 2 2 1 0 0 1 2 1 1 2 2 0 0 2 1 0 0 1 1 2 2 2 1 0 0 0 1 0 2\n",
            " 0 0 2 1 0 1 2]\n",
            "71 / 200 Training loss: 0.0021948298701533566, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2731770833333333, Validation_Accuracy: 0.8033333420753479\n",
            "71 th epoch\n",
            "gt [1 0 2 2 1 1 1 2 1 2 0 1 1 1 2 0 0 2 0 1 0 2 2 0 1 0 1 2 0 2 0 2 2 2 0 0 0\n",
            " 2 1 2 1 1 0 0]\n",
            "pred [2 0 2 2 0 0 2 1 1 1 2 1 1 1 2 0 0 1 0 1 0 2 1 0 2 2 1 2 0 2 0 2 2 2 1 0 0\n",
            " 2 0 2 1 1 0 0]\n",
            "72 / 200 Training loss: 0.0015662638346354166, Tran_Accuracy: 1.0, Validation_loss: 1.3458072916666666, Validation_Accuracy: 0.8033333420753479\n",
            "72 th epoch\n",
            "gt [1 2 2 1 2 0 0 1 2 1 0 2 1 1 2 1 2 1 1 0 1 1 0 2 2 2 2 2 1 2 0 2 1 1 2 2 1\n",
            " 2 1 0 0 2 1 1]\n",
            "pred [1 2 2 1 2 0 0 1 2 1 0 1 1 1 2 1 2 1 0 0 2 1 0 2 2 2 2 2 1 2 0 2 1 2 2 2 0\n",
            " 2 1 0 0 1 1 1]\n",
            "73 / 200 Training loss: 0.002410141273781105, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.1657682291666667, Validation_Accuracy: 0.8233333230018616\n",
            "73 th epoch\n",
            "gt [1 1 2 2 2 0 0 0 0 1 2 0 0 0 0 2 2 2 1 1 0 0 0 1 1 0 1 0 2 1 0 1 1 2 2 1 1\n",
            " 0 2 2 0 0 2 1]\n",
            "pred [1 2 2 1 2 0 0 0 0 1 2 0 0 0 0 1 2 2 1 1 0 0 0 2 1 0 1 2 2 1 0 1 2 0 2 2 1\n",
            " 0 2 2 0 0 2 1]\n",
            "74 / 200 Training loss: 0.001555793903492115, Tran_Accuracy: 1.0, Validation_loss: 1.3704361979166666, Validation_Accuracy: 0.7933333516120911\n",
            "74 th epoch\n",
            "gt [1 2 2 2 1 2 2 2 2 1 2 1 0 2 2 1 0 0 0 2 1 1 1 1 0 0 0 2 1 1 0 2 1 1 1 1 1\n",
            " 1 1 0 0 2 2 1]\n",
            "pred [1 2 2 1 2 2 2 2 0 2 1 0 0 2 2 0 0 0 0 0 1 1 0 1 0 0 0 2 1 1 0 2 1 1 1 1 1\n",
            " 1 2 0 0 2 2 1]\n",
            "75 / 200 Training loss: 0.0013347978945131656, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.240625, Validation_Accuracy: 0.8166666626930237\n",
            "75 th epoch\n",
            "gt [0 0 1 2 1 2 1 1 2 0 1 1 1 1 0 2 2 2 0 2 0 0 0 2 2 1 1 1 1 0 1 0 0 0 0 1 2\n",
            " 1 2 0 2 0 2 2]\n",
            "pred [0 0 1 2 2 2 1 1 2 0 1 0 2 1 0 2 2 2 0 1 1 1 0 2 2 1 1 1 0 0 1 0 0 0 0 1 1\n",
            " 2 2 0 2 0 2 2]\n",
            "76 / 200 Training loss: 0.0048040912769458915, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.2359505208333332, Validation_Accuracy: 0.800000011920929\n",
            "76 th epoch\n",
            "gt [2 2 1 0 0 1 1 0 0 1 2 2 1 0 1 1 0 0 1 0 1 1 2 2 1 1 0 0 2 1 0 2 2 1 0 2 1\n",
            " 1 0 2 2 0 0 2]\n",
            "pred [2 2 2 0 1 0 1 0 0 1 2 1 1 0 1 1 2 0 1 0 1 2 2 2 1 2 2 0 2 1 0 2 1 1 0 2 0\n",
            " 1 0 2 2 2 0 2]\n",
            "77 / 200 Training loss: 0.0013620065759729456, Tran_Accuracy: 1.0, Validation_loss: 1.2979427083333333, Validation_Accuracy: 0.7933333516120911\n",
            "77 th epoch\n",
            "gt [0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 2 0 1 1 1 1 1 2 2 1 2 1 0 0 2 1 1 2 1 1 2\n",
            " 0 2 0 2 1 0 0]\n",
            "pred [0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 2 0 1 1 1 1 2 2 2 2 2 1 0 0 2 1 1 2 0 1 2\n",
            " 0 2 0 2 0 1 0]\n",
            "78 / 200 Training loss: 0.0014273749457465279, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2601953125, Validation_Accuracy: 0.8033333420753479\n",
            "78 th epoch\n",
            "gt [1 0 2 2 2 1 0 0 1 0 2 1 0 2 1 1 0 2 0 0 1 0 0 2 1 2 0 0 2 1 2 0 2 0 1 1 1\n",
            " 1 0 0 2 2 1 0]\n",
            "pred [1 0 2 2 2 1 0 2 2 0 1 2 0 2 1 1 0 1 0 0 1 0 0 2 1 2 0 0 2 2 2 0 2 0 1 0 1\n",
            " 1 0 0 2 2 1 0]\n",
            "79 / 200 Training loss: 0.0012500274622881855, Tran_Accuracy: 1.0, Validation_loss: 1.2597265625, Validation_Accuracy: 0.8133333325386047\n",
            "79 th epoch\n",
            "gt [1 1 1 2 0 0 1 1 0 0 0 0 2 1 2 0 2 2 2 1 1 2 2 1 2 1 1 0 0 1 1 2 0 1 0 0 2\n",
            " 2 1 1 0 0 0 0]\n",
            "pred [2 2 1 2 0 0 1 1 0 0 0 0 2 2 2 0 2 1 2 1 1 1 2 1 2 1 1 0 0 1 1 2 0 2 0 0 2\n",
            " 2 1 1 0 0 0 0]\n",
            "80 / 200 Training loss: 0.0019505055745442708, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2970833333333334, Validation_Accuracy: 0.79666668176651\n",
            "80 th epoch\n",
            "gt [1 0 2 1 0 0 2 2 1 0 2 1 0 0 2 2 0 2 2 0 2 0 2 2 0 2 0 2 0 0 2 2 1 2 0 1 1\n",
            " 1 0 2 0 2 2 0]\n",
            "pred [1 0 0 1 0 0 1 1 1 0 1 1 0 0 2 2 0 2 2 0 2 0 2 2 0 2 0 1 0 0 2 2 2 1 0 1 1\n",
            " 1 0 2 0 2 2 0]\n",
            "81 / 200 Training loss: 0.0016851509941948784, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2781640625, Validation_Accuracy: 0.8133333325386047\n",
            "81 th epoch\n",
            "gt [0 0 2 2 0 2 0 0 2 0 2 0 0 1 1 0 2 2 2 0 1 0 0 1 2 2 2 2 2 2 0 1 2 2 1 0 1\n",
            " 1 0 1 2 1 0 0]\n",
            "pred [0 0 1 2 2 2 0 0 2 0 2 0 0 1 1 0 2 2 2 0 1 0 0 1 1 2 1 1 2 2 0 1 0 2 0 0 1\n",
            " 1 2 1 1 1 0 2]\n",
            "82 / 200 Training loss: 0.0031164225825557, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.24234375, Validation_Accuracy: 0.8100000023841858\n",
            "82 th epoch\n",
            "gt [1 2 1 1 2 0 0 2 0 2 2 0 0 2 1 1 2 1 1 2 2 1 2 2 1 2 0 2 2 2 1 2 2 0 0 0 1\n",
            " 1 2 1 2 2 2 1]\n",
            "pred [1 2 1 1 2 0 0 2 0 1 2 0 2 1 0 1 2 1 1 2 1 1 2 2 2 2 0 2 1 2 1 2 2 0 0 0 2\n",
            " 1 2 1 2 2 1 1]\n",
            "83 / 200 Training loss: 0.0012840059068467882, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.253359375, Validation_Accuracy: 0.8100000023841858\n",
            "83 th epoch\n",
            "gt [2 1 2 0 2 1 1 2 2 2 2 2 1 2 1 0 0 2 1 1 2 2 1 2 2 1 0 1 0 0 0 0 2 2 2 0 0\n",
            " 0 2 1 2 2 2 0]\n",
            "pred [2 1 2 0 2 1 2 2 2 2 1 2 1 2 1 0 0 2 0 1 2 2 1 1 2 1 0 1 0 0 1 0 1 2 0 0 0\n",
            " 0 2 0 2 2 2 0]\n",
            "84 / 200 Training loss: 0.0036648036815502025, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.20650390625, Validation_Accuracy: 0.8166666626930237\n",
            "84 th epoch\n",
            "gt [1 1 1 2 1 0 2 2 1 2 1 1 0 1 0 2 0 2 2 0 2 0 2 0 0 2 1 1 1 1 0 1 0 2 2 0 2\n",
            " 2 2 1 1 0 1 1]\n",
            "pred [1 1 1 2 1 0 2 2 1 2 2 1 0 2 0 1 2 2 2 0 2 0 2 0 0 2 2 0 2 0 0 1 0 2 2 0 1\n",
            " 2 2 0 1 0 1 0]\n",
            "85 / 200 Training loss: 0.0016599838821976273, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2384895833333334, Validation_Accuracy: 0.8233333230018616\n",
            "85 th epoch\n",
            "gt [1 0 0 0 1 1 0 1 2 0 0 1 0 2 0 0 2 2 2 1 1 0 0 2 1 0 1 1 0 2 2 2 0 2 0 0 0\n",
            " 1 0 2 0 0 1 1]\n",
            "pred [1 0 0 0 1 1 0 1 2 0 0 1 0 2 0 0 2 2 1 1 2 0 0 2 1 2 1 1 0 1 1 2 0 2 0 0 1\n",
            " 1 0 2 0 0 2 1]\n",
            "86 / 200 Training loss: 0.001267301771375868, Tran_Accuracy: 1.0, Validation_loss: 1.3004036458333332, Validation_Accuracy: 0.8066666722297668\n",
            "86 th epoch\n",
            "gt [1 1 1 2 1 0 2 2 2 0 0 1 1 2 2 0 1 1 2 0 0 2 0 2 1 2 1 0 2 1 0 2 0 2 2 0 1\n",
            " 0 0 1 2 0 0 2]\n",
            "pred [1 1 1 2 1 0 2 2 1 0 0 1 1 2 2 0 1 2 2 0 0 2 0 2 1 1 1 0 2 1 0 2 0 2 2 0 1\n",
            " 0 0 1 2 0 0 2]\n",
            "87 / 200 Training loss: 0.0017426639133029515, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2872623697916667, Validation_Accuracy: 0.800000011920929\n",
            "87 th epoch\n",
            "gt [0 2 1 1 0 0 2 1 2 1 2 1 0 1 0 1 1 0 0 1 0 2 0 2 1 1 1 2 0 0 1 0 0 1 2 0 1\n",
            " 2 2 2 0 1 0 2]\n",
            "pred [1 1 1 1 2 0 2 1 1 0 2 1 0 2 0 1 1 0 0 2 0 1 0 2 1 2 1 1 0 0 2 2 0 0 2 0 1\n",
            " 2 2 1 0 1 0 2]\n",
            "88 / 200 Training loss: 0.0017365773518880209, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3958333333333333, Validation_Accuracy: 0.7900000214576721\n",
            "88 th epoch\n",
            "gt [0 2 1 2 1 1 1 0 1 1 1 1 1 1 1 0 2 0 0 1 2 0 2 2 1 2 2 0 2 1 2 1 1 1 0 1 2\n",
            " 2 1 1 2 2 0 0]\n",
            "pred [0 2 0 2 1 1 2 2 1 1 2 1 1 2 1 0 2 0 0 0 2 0 1 2 1 2 2 0 2 1 2 2 1 1 0 0 1\n",
            " 2 1 1 2 0 0 2]\n",
            "89 / 200 Training loss: 0.0015846817581741898, Tran_Accuracy: 1.0, Validation_loss: 1.322421875, Validation_Accuracy: 0.8100000023841858\n",
            "89 th epoch\n",
            "gt [0 1 2 1 1 2 2 1 2 1 0 0 0 0 0 0 2 1 0 0 1 1 2 0 0 1 2 2 0 2 0 1 1 2 1 2 1\n",
            " 0 0 1 1 0 2 1]\n",
            "pred [0 1 0 1 1 2 1 1 2 1 2 0 0 1 0 0 2 2 0 0 1 2 2 0 0 2 2 2 1 2 0 2 1 2 1 1 1\n",
            " 0 0 1 1 0 2 1]\n",
            "90 / 200 Training loss: 0.0014873335096571181, Tran_Accuracy: 1.0, Validation_loss: 1.2521614583333334, Validation_Accuracy: 0.7866666913032532\n",
            "90 th epoch\n",
            "gt [1 2 1 1 1 0 0 0 2 2 0 1 0 0 0 1 2 0 1 1 2 0 2 0 0 2 2 1 0 1 1 2 1 1 0 2 0\n",
            " 0 0 2 1 0 2 2]\n",
            "pred [1 2 1 0 2 0 0 0 2 2 0 1 0 0 0 1 2 0 1 1 2 0 2 0 0 2 2 1 1 2 1 2 1 1 0 2 0\n",
            " 0 2 2 2 0 2 2]\n",
            "91 / 200 Training loss: 0.0015712582623517073, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2145833333333333, Validation_Accuracy: 0.8066666722297668\n",
            "91 th epoch\n",
            "gt [0 0 1 1 2 1 0 0 0 1 2 1 0 0 1 0 1 2 0 2 0 0 1 0 1 1 0 0 2 2 1 1 1 2 1 0 0\n",
            " 2 1 1 0 0 0 2]\n",
            "pred [2 0 1 1 2 1 0 0 0 1 2 1 0 0 1 0 0 2 2 1 0 0 1 0 1 0 0 0 2 2 2 1 1 2 1 0 0\n",
            " 2 2 1 0 0 0 2]\n",
            "92 / 200 Training loss: 0.004055958500614873, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.284453125, Validation_Accuracy: 0.7833333611488342\n",
            "92 th epoch\n",
            "gt [1 0 1 1 1 0 2 2 1 1 2 2 1 1 2 0 0 0 0 2 0 0 0 0 0 2 1 1 1 0 1 0 2 1 1 2 2\n",
            " 2 2 0 0 0 1 0]\n",
            "pred [1 0 1 1 1 0 2 2 1 1 1 2 1 1 2 0 0 0 0 2 0 0 0 0 0 1 2 2 1 0 2 0 2 2 1 2 2\n",
            " 2 1 0 0 0 1 0]\n",
            "93 / 200 Training loss: 0.0023575351856372976, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3487174479166666, Validation_Accuracy: 0.7866666913032532\n",
            "93 th epoch\n",
            "gt [2 2 1 1 1 1 2 2 0 1 1 0 2 0 1 0 1 0 1 2 1 1 2 2 2 1 2 0 1 2 0 1 2 0 1 0 2\n",
            " 2 2 2 1 0 2 0]\n",
            "pred [1 2 1 1 0 1 1 2 0 0 1 0 2 0 1 0 0 0 1 2 1 1 2 1 2 1 2 0 2 2 0 2 2 0 1 0 2\n",
            " 1 2 1 1 0 2 0]\n",
            "94 / 200 Training loss: 0.003261320326063368, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.3955078125, Validation_Accuracy: 0.7900000214576721\n",
            "94 th epoch\n",
            "gt [2 0 0 0 0 0 0 2 2 1 0 1 0 2 2 0 1 2 0 2 2 2 0 1 1 2 2 2 2 0 1 0 1 2 2 2 0\n",
            " 1 2 2 2 1 1 2]\n",
            "pred [2 0 0 0 0 0 0 2 1 1 0 1 0 2 2 0 1 2 0 2 2 2 0 1 2 1 2 1 2 0 1 0 2 2 2 2 0\n",
            " 1 1 1 2 1 2 2]\n",
            "95 / 200 Training loss: 0.0031328370836046005, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.2681315104166666, Validation_Accuracy: 0.800000011920929\n",
            "95 th epoch\n",
            "gt [2 1 2 2 0 2 0 1 1 2 1 2 0 2 0 0 1 0 2 0 2 2 0 0 1 1 2 1 1 1 0 0 2 0 0 1 1\n",
            " 0 0 0 2 1 2 1]\n",
            "pred [2 1 2 2 0 2 0 1 2 2 1 2 0 2 0 1 1 0 2 0 2 2 0 0 1 1 2 1 1 1 0 0 2 0 0 1 2\n",
            " 0 0 0 2 1 2 1]\n",
            "96 / 200 Training loss: 0.002056606434009693, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2834505208333333, Validation_Accuracy: 0.79666668176651\n",
            "96 th epoch\n",
            "gt [0 2 2 1 0 2 2 0 0 2 2 1 0 0 2 2 2 2 0 0 0 0 1 0 0 1 2 2 1 0 2 2 1 1 1 0 0\n",
            " 2 1 0 2 0 0 1]\n",
            "pred [2 2 1 1 0 2 2 0 0 2 2 1 0 0 1 2 2 2 0 0 0 0 2 0 0 1 2 2 1 2 2 2 1 1 2 0 0\n",
            " 1 1 0 1 0 1 1]\n",
            "97 / 200 Training loss: 0.0022938848424840855, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2455989583333333, Validation_Accuracy: 0.8166666626930237\n",
            "97 th epoch\n",
            "gt [1 0 0 0 1 2 0 2 2 0 2 1 1 2 2 0 1 0 2 0 2 2 0 0 0 0 2 2 1 1 0 0 0 0 0 0 1\n",
            " 0 0 2 1 0 2 0]\n",
            "pred [1 0 2 0 1 2 0 2 2 0 2 1 1 2 2 0 1 0 2 0 2 2 0 0 0 0 1 2 1 1 0 0 0 0 1 0 1\n",
            " 0 0 1 2 0 2 1]\n",
            "98 / 200 Training loss: 0.0016972666316562228, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.339765625, Validation_Accuracy: 0.7833333611488342\n",
            "98 th epoch\n",
            "gt [0 0 2 1 0 1 1 1 0 2 0 1 0 0 0 0 0 1 0 2 0 0 1 0 2 0 0 1 2 0 0 2 0 1 0 0 1\n",
            " 1 2 1 0 2 0 0]\n",
            "pred [2 0 2 2 0 2 1 1 0 2 0 2 0 0 1 0 2 0 0 0 0 0 1 0 2 0 0 1 2 0 0 2 0 1 1 0 1\n",
            " 1 2 1 0 1 0 2]\n",
            "99 / 200 Training loss: 0.0026842230337637443, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.2822395833333333, Validation_Accuracy: 0.7933333516120911\n",
            "99 th epoch\n",
            "gt [1 2 2 1 0 1 1 0 1 0 1 2 1 0 0 1 1 1 1 1 0 2 2 0 0 1 1 2 0 0 2 2 1 2 1 0 0\n",
            " 0 1 1 1 1 1 1]\n",
            "pred [1 2 2 1 0 2 0 0 1 0 1 2 2 0 0 2 1 1 1 1 0 2 2 0 0 0 2 2 0 0 2 2 2 2 1 0 0\n",
            " 1 2 1 2 1 0 1]\n",
            "100 / 200 Training loss: 0.001851981834129051, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3240364583333333, Validation_Accuracy: 0.7900000214576721\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.80      0.92      0.86        13\n",
            "     Neutral       0.92      0.55      0.69        22\n",
            "       Smoke       0.56      1.00      0.72         9\n",
            "\n",
            "    accuracy                           0.75        44\n",
            "   macro avg       0.76      0.82      0.75        44\n",
            "weighted avg       0.81      0.75      0.74        44\n",
            "\n",
            "100 th epoch\n",
            "gt [0 1 1 0 0 0 2 0 0 2 0 1 2 0 0 1 2 0 2 2 2 1 0 0 0 2 2 2 1 2 1 0 0 2 1 0 1\n",
            " 1 0 1 0 2 0 2]\n",
            "pred [0 0 1 0 0 0 2 0 2 0 0 0 1 0 0 1 2 2 2 2 1 1 0 0 0 2 2 2 1 2 1 0 0 2 1 0 1\n",
            " 2 0 1 0 2 0 2]\n",
            "101 / 200 Training loss: 0.0037759088586877894, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.1698828125, Validation_Accuracy: 0.8100000023841858\n",
            "101 th epoch\n",
            "gt [0 2 1 0 0 1 2 0 0 1 2 0 0 2 1 1 0 1 0 2 1 1 2 1 0 0 0 0 0 2 2 2 1 1 1 1 2\n",
            " 0 0 0 1 0 2 1]\n",
            "pred [0 2 2 0 0 1 1 0 0 1 2 0 0 2 0 2 0 1 0 2 1 1 1 2 0 0 0 0 0 2 2 1 1 2 2 1 1\n",
            " 0 2 0 1 0 1 1]\n",
            "102 / 200 Training loss: 0.0014146694430598507, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.312109375, Validation_Accuracy: 0.8133333325386047\n",
            "102 th epoch\n",
            "gt [0 2 2 1 0 2 1 2 0 1 0 2 2 1 1 0 2 1 0 2 2 1 1 0 2 0 1 2 2 0 2 1 2 1 1 2 2\n",
            " 2 0 2 0 2 2 2]\n",
            "pred [0 2 2 2 0 2 1 2 2 2 0 2 2 1 1 0 2 1 0 1 1 1 1 0 1 0 1 2 1 0 2 1 2 1 1 2 2\n",
            " 2 0 1 0 2 0 2]\n",
            "103 / 200 Training loss: 0.001232267838937265, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2923697916666668, Validation_Accuracy: 0.79666668176651\n",
            "103 th epoch\n",
            "gt [0 1 1 1 2 0 1 2 0 2 2 0 2 1 1 2 0 0 0 0 0 0 0 2 0 2 2 0 1 1 2 2 1 0 0 1 0\n",
            " 0 1 0 0 2 2 1]\n",
            "pred [2 0 1 1 2 0 1 2 0 2 2 0 2 1 2 1 0 0 0 0 0 0 0 1 1 2 2 0 1 1 2 2 0 0 0 2 0\n",
            " 0 1 0 0 1 2 1]\n",
            "104 / 200 Training loss: 0.002598797833478009, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.26515625, Validation_Accuracy: 0.8166666626930237\n",
            "104 th epoch\n",
            "gt [2 0 1 2 1 2 2 0 2 1 2 0 1 2 1 0 0 2 1 0 2 2 1 1 1 0 2 2 2 1 1 1 1 1 1 0 2\n",
            " 1 0 1 2 1 2 0]\n",
            "pred [2 0 2 2 0 1 1 0 2 2 2 0 2 2 1 0 0 2 1 0 2 2 1 1 1 0 2 2 2 1 1 1 2 2 1 0 2\n",
            " 1 0 1 2 1 1 0]\n",
            "105 / 200 Training loss: 0.0013100934911657262, Tran_Accuracy: 1.0, Validation_loss: 1.2951171875, Validation_Accuracy: 0.8100000023841858\n",
            "105 th epoch\n",
            "gt [0 0 2 1 1 2 0 0 2 2 1 1 1 2 0 0 0 1 0 0 2 0 0 1 0 2 1 0 2 1 1 0 1 1 2 1 1\n",
            " 2 2 0 0 1 2 2]\n",
            "pred [0 0 1 0 2 2 0 0 2 1 1 1 1 0 0 0 0 1 0 0 2 0 0 1 0 1 2 0 1 1 1 2 1 1 2 2 1\n",
            " 1 2 0 0 1 2 2]\n",
            "106 / 200 Training loss: 0.0020990339031925907, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3474739583333333, Validation_Accuracy: 0.8033333420753479\n",
            "106 th epoch\n",
            "gt [2 0 2 0 2 0 1 0 2 1 2 1 0 2 2 0 2 0 0 0 2 1 1 1 0 1 2 0 2 0 2 1 0 2 1 0 2\n",
            " 1 0 0 2 1 1 0]\n",
            "pred [2 2 2 0 2 0 1 0 2 2 2 1 0 2 2 0 2 0 0 0 2 0 1 1 0 2 2 0 2 0 1 0 0 2 1 0 2\n",
            " 1 0 2 2 2 1 0]\n",
            "107 / 200 Training loss: 0.0011620941868534795, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3167447916666666, Validation_Accuracy: 0.79666668176651\n",
            "107 th epoch\n",
            "gt [2 1 2 1 2 1 0 0 1 2 0 0 0 1 0 2 2 2 1 0 0 2 2 2 1 1 0 2 2 0 0 0 0 2 1 0 0\n",
            " 0 2 1 2 2 0 2]\n",
            "pred [1 1 2 0 2 1 0 0 1 1 0 0 0 1 0 2 2 2 1 0 0 2 2 1 1 1 0 2 2 0 0 0 0 1 1 0 2\n",
            " 0 2 1 1 2 0 2]\n",
            "108 / 200 Training loss: 0.001134786252622251, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2663997395833333, Validation_Accuracy: 0.8133333325386047\n",
            "108 th epoch\n",
            "gt [1 0 1 2 2 0 1 0 1 1 1 2 2 0 0 1 1 2 1 0 2 2 2 1 1 1 0 2 2 2 1 0 0 0 1 0 1\n",
            " 0 0 2 1 1 2 1]\n",
            "pred [1 0 1 1 2 0 0 1 0 2 1 2 1 0 0 1 1 2 1 0 2 2 1 2 1 0 0 2 2 2 1 0 0 0 1 0 1\n",
            " 0 0 2 1 1 2 0]\n",
            "109 / 200 Training loss: 0.0015874382301613137, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3018619791666666, Validation_Accuracy: 0.800000011920929\n",
            "109 th epoch\n",
            "gt [2 0 1 1 1 1 2 2 1 0 1 0 1 1 0 2 1 2 1 1 1 1 0 0 1 0 0 2 2 1 2 0 2 1 0 0 1\n",
            " 2 0 1 0 2 2 0]\n",
            "pred [2 0 2 1 2 1 2 2 1 0 2 0 1 2 0 2 1 2 2 1 1 1 0 0 2 0 0 2 2 1 2 0 2 1 0 0 1\n",
            " 2 0 1 0 2 0 0]\n",
            "110 / 200 Training loss: 0.001322175485116464, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3111458333333332, Validation_Accuracy: 0.8100000023841858\n",
            "110 th epoch\n",
            "gt [2 0 1 1 0 0 2 2 2 1 1 1 0 1 0 2 0 1 0 1 2 2 0 1 0 1 2 2 1 2 1 2 2 2 1 0 1\n",
            " 1 0 1 0 1 1 0]\n",
            "pred [2 0 1 0 2 0 2 2 2 1 1 0 0 0 0 2 0 1 0 1 1 2 0 1 0 2 1 2 1 2 1 2 1 2 1 0 1\n",
            " 0 0 1 0 1 2 0]\n",
            "111 / 200 Training loss: 0.0024437120225694444, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2439583333333333, Validation_Accuracy: 0.8133333325386047\n",
            "111 th epoch\n",
            "gt [0 2 2 2 0 1 0 1 1 0 1 0 0 0 0 0 1 0 2 2 0 0 0 0 2 0 1 2 2 2 0 0 1 2 2 2 0\n",
            " 1 0 1 0 2 2 0]\n",
            "pred [0 2 2 2 0 1 0 1 1 0 1 0 0 2 0 0 1 0 2 2 0 0 0 0 2 0 1 2 2 1 0 0 2 2 2 2 2\n",
            " 2 1 1 0 2 1 0]\n",
            "112 / 200 Training loss: 0.00133045408460829, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.4272786458333333, Validation_Accuracy: 0.7933333516120911\n",
            "112 th epoch\n",
            "gt [1 1 0 0 0 0 0 2 0 1 2 1 1 2 1 0 1 1 0 2 2 2 2 1 1 0 0 2 0 2 1 1 1 2 2 0 0\n",
            " 2 0 1 2 0 1 2]\n",
            "pred [1 0 0 0 0 0 2 2 0 1 1 1 2 1 1 0 1 1 0 2 2 2 0 2 1 0 0 1 0 2 2 1 1 2 2 0 0\n",
            " 2 0 2 2 1 1 2]\n",
            "113 / 200 Training loss: 0.0011730167600843642, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.1519140625, Validation_Accuracy: 0.800000011920929\n",
            "113 th epoch\n",
            "gt [0 2 1 0 2 0 0 1 2 1 0 1 1 0 2 2 1 2 1 0 2 2 0 2 1 2 0 2 0 2 2 0 1 1 1 0 1\n",
            " 1 2 0 0 1 1 2]\n",
            "pred [0 2 1 0 2 0 0 1 2 2 0 2 2 0 2 1 0 1 1 2 2 2 0 2 1 2 2 2 0 1 1 0 1 2 0 0 2\n",
            " 1 2 0 0 1 2 2]\n",
            "114 / 200 Training loss: 0.0020813683227256493, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.278984375, Validation_Accuracy: 0.8133333325386047\n",
            "114 th epoch\n",
            "gt [2 1 2 2 0 1 0 0 1 0 2 1 1 1 0 2 2 0 0 2 2 1 1 0 0 0 2 1 1 2 2 1 2 1 0 1 2\n",
            " 1 1 1 0 2 0 2]\n",
            "pred [2 1 1 2 0 1 0 0 0 0 1 1 1 1 0 1 2 0 0 2 2 1 0 0 0 1 2 1 1 2 1 0 1 1 0 1 2\n",
            " 1 1 1 0 2 0 2]\n",
            "115 / 200 Training loss: 0.001095499109338831, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2854036458333333, Validation_Accuracy: 0.800000011920929\n",
            "115 th epoch\n",
            "gt [2 2 1 0 1 2 0 2 1 1 2 0 1 1 2 2 0 2 2 2 1 1 1 2 1 0 1 1 1 2 1 0 2 2 0 1 2\n",
            " 2 0 0 0 0 0 0]\n",
            "pred [2 2 1 0 2 2 0 2 1 1 2 0 0 1 2 2 0 2 2 1 1 1 1 2 0 0 1 1 1 2 1 0 2 0 0 1 1\n",
            " 2 0 0 0 0 0 0]\n",
            "116 / 200 Training loss: 0.0016040250990125868, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2503190104166666, Validation_Accuracy: 0.8066666722297668\n",
            "116 th epoch\n",
            "gt [0 0 1 2 2 1 0 1 2 0 0 1 1 1 1 1 0 0 2 2 1 1 1 0 1 2 2 1 0 2 2 0 2 2 2 2 1\n",
            " 1 1 1 1 0 0 2]\n",
            "pred [0 0 1 1 2 1 0 1 2 0 0 2 1 0 1 1 0 0 2 2 2 1 2 0 1 1 2 2 0 2 2 0 2 2 2 2 1\n",
            " 0 1 2 1 0 0 2]\n",
            "117 / 200 Training loss: 0.0014954404477719907, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3227018229166667, Validation_Accuracy: 0.7900000214576721\n",
            "117 th epoch\n",
            "gt [2 1 1 1 2 0 1 2 1 0 1 0 2 2 0 2 0 1 2 0 1 0 0 1 1 0 2 0 1 0 2 1 0 2 2 1 2\n",
            " 1 0 1 2 1 0 0]\n",
            "pred [2 1 1 2 1 0 0 1 1 0 0 0 2 2 0 2 0 1 2 0 1 0 0 1 2 0 2 0 2 0 2 1 2 2 2 2 1\n",
            " 1 0 1 2 1 0 0]\n",
            "118 / 200 Training loss: 0.0016668319702148437, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3341927083333334, Validation_Accuracy: 0.7933333516120911\n",
            "118 th epoch\n",
            "gt [1 1 0 1 0 1 0 2 0 2 0 0 2 1 2 0 0 0 1 2 0 2 1 2 2 2 1 1 1 0 1 0 2 0 2 0 2\n",
            " 1 0 2 0 1 2 0]\n",
            "pred [1 2 0 0 0 2 1 2 0 2 0 0 2 1 2 0 0 0 1 2 0 2 1 1 0 2 1 1 1 0 1 0 1 0 2 0 2\n",
            " 2 0 2 0 1 2 0]\n",
            "119 / 200 Training loss: 0.0014872826470269096, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2380989583333333, Validation_Accuracy: 0.800000011920929\n",
            "119 th epoch\n",
            "gt [2 0 1 1 2 2 1 2 2 0 1 2 1 1 0 0 0 1 1 1 1 0 2 1 0 0 0 2 2 2 1 0 2 1 0 0 2\n",
            " 0 2 1 1 2 1 2]\n",
            "pred [2 0 1 0 2 1 1 1 2 0 1 1 0 0 2 0 0 1 1 1 1 0 2 1 0 0 0 2 2 2 2 0 2 1 0 0 2\n",
            " 0 2 1 1 2 1 2]\n",
            "120 / 200 Training loss: 0.0033961882414641205, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.218359375, Validation_Accuracy: 0.79666668176651\n",
            "120 th epoch\n",
            "gt [0 0 2 0 2 0 2 0 1 1 1 1 1 2 2 2 2 0 1 1 1 2 2 1 1 1 1 2 2 2 2 1 0 0 1 2 0\n",
            " 1 2 2 2 2 0 0]\n",
            "pred [0 0 2 0 2 0 2 0 1 0 1 1 1 2 2 2 2 0 1 1 1 1 2 1 2 1 2 1 1 1 2 2 0 0 2 1 0\n",
            " 1 2 2 2 2 0 0]\n",
            "121 / 200 Training loss: 0.001258027818467882, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2398177083333333, Validation_Accuracy: 0.800000011920929\n",
            "121 th epoch\n",
            "gt [1 0 2 1 0 2 2 2 0 2 1 2 2 2 1 1 0 1 1 0 0 0 1 2 0 2 0 2 1 0 0 2 0 0 1 2 1\n",
            " 1 1 0 2 0 0 2]\n",
            "pred [1 0 2 1 0 2 2 1 0 2 1 1 2 2 1 0 0 2 1 0 0 1 0 2 0 2 0 1 0 0 0 2 2 0 1 0 1\n",
            " 0 1 0 2 0 0 2]\n",
            "122 / 200 Training loss: 0.001470794677734375, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2854947916666666, Validation_Accuracy: 0.8033333420753479\n",
            "122 th epoch\n",
            "gt [0 0 2 2 0 1 0 1 1 0 2 0 1 2 1 1 0 1 2 1 1 2 1 2 2 2 2 0 0 1 1 0 1 0 2 0 0\n",
            " 1 1 1 2 0 2 2]\n",
            "pred [2 0 1 2 0 1 0 1 0 0 2 2 1 2 1 2 0 1 2 1 1 2 1 2 2 2 2 0 0 1 1 2 1 0 2 0 0\n",
            " 1 1 1 1 0 1 2]\n",
            "123 / 200 Training loss: 0.0026566088641131365, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.2698177083333333, Validation_Accuracy: 0.800000011920929\n",
            "123 th epoch\n",
            "gt [0 2 2 2 0 0 1 1 0 0 1 1 1 0 0 1 0 0 2 0 1 1 0 0 2 2 2 0 1 1 1 1 2 1 2 1 2\n",
            " 0 0 0 2 1 0 1]\n",
            "pred [0 2 1 2 0 0 1 1 0 0 2 1 1 1 1 1 0 0 2 0 2 0 0 0 2 2 2 0 0 1 0 2 2 2 2 1 2\n",
            " 0 0 0 2 2 0 2]\n",
            "124 / 200 Training loss: 0.0015091097796404802, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2209114583333334, Validation_Accuracy: 0.8100000023841858\n",
            "124 th epoch\n",
            "gt [0 1 1 1 0 1 1 2 1 2 1 0 2 0 2 0 2 1 1 2 1 2 1 0 2 2 2 1 2 0 0 0 0 1 0 1 1\n",
            " 0 0 2 2 2 0 0]\n",
            "pred [0 1 1 2 0 1 1 1 1 2 1 0 2 0 1 0 2 2 1 2 1 1 1 0 2 2 2 1 2 0 0 2 0 2 0 1 1\n",
            " 0 2 1 2 2 0 0]\n",
            "125 / 200 Training loss: 0.009498577824345341, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.2928776041666667, Validation_Accuracy: 0.8066666722297668\n",
            "125 th epoch\n",
            "gt [2 1 2 2 1 2 1 0 1 0 1 2 2 1 1 2 0 1 2 0 2 0 2 2 0 2 2 0 1 2 2 1 0 0 1 0 2\n",
            " 0 0 1 1 2 0 2]\n",
            "pred [1 0 2 1 1 2 2 0 1 0 1 1 2 2 1 1 0 1 2 0 1 0 2 2 0 2 2 0 1 2 1 1 0 0 1 0 2\n",
            " 0 0 1 1 2 0 2]\n",
            "126 / 200 Training loss: 0.0010406761699252658, Tran_Accuracy: 1.0, Validation_loss: 1.2698958333333332, Validation_Accuracy: 0.8033333420753479\n",
            "126 th epoch\n",
            "gt [1 1 0 1 0 0 2 0 2 2 1 0 0 0 0 0 2 0 1 0 2 1 2 1 1 1 2 2 0 0 0 2 2 1 2 0 0\n",
            " 1 1 0 1 1 0 0]\n",
            "pred [1 1 0 2 0 2 2 2 2 2 1 0 0 0 0 1 2 0 1 0 1 1 2 1 1 2 2 2 0 0 0 2 2 1 2 0 0\n",
            " 1 1 0 1 1 0 0]\n",
            "127 / 200 Training loss: 0.001535268712926794, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3446028645833332, Validation_Accuracy: 0.8066666722297668\n",
            "127 th epoch\n",
            "gt [2 0 2 1 0 1 2 2 2 1 2 1 0 1 1 1 2 1 0 0 0 0 0 0 2 2 2 1 1 0 2 0 1 0 0 1 0\n",
            " 0 1 2 0 2 2 1]\n",
            "pred [1 0 2 1 0 1 2 2 2 1 2 1 0 2 1 1 2 1 0 0 0 0 0 0 2 2 1 2 0 1 2 0 1 0 0 1 2\n",
            " 0 1 0 0 2 2 1]\n",
            "128 / 200 Training loss: 0.0013204221372251157, Tran_Accuracy: 1.0, Validation_loss: 1.2422916666666666, Validation_Accuracy: 0.8066666722297668\n",
            "128 th epoch\n",
            "gt [1 0 2 0 2 1 2 2 2 0 0 1 0 2 1 1 2 1 0 0 0 2 0 2 1 0 2 2 0 1 2 1 0 1 1 2 0\n",
            " 0 0 0 1 2 2 2]\n",
            "pred [1 0 1 0 2 2 2 2 2 0 0 2 0 1 1 1 1 1 0 0 0 2 0 2 1 2 2 2 0 2 1 1 0 1 1 2 0\n",
            " 0 0 0 1 2 1 2]\n",
            "129 / 200 Training loss: 0.0012620798746744793, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.33765625, Validation_Accuracy: 0.79666668176651\n",
            "129 th epoch\n",
            "gt [0 0 1 0 0 2 0 2 0 2 2 0 0 2 1 0 0 1 1 1 2 2 0 1 2 2 1 0 2 2 2 1 0 1 1 0 2\n",
            " 0 2 1 1 2 0 1]\n",
            "pred [0 2 2 0 0 2 0 2 1 1 2 2 0 2 1 0 0 1 1 1 2 2 0 1 2 2 1 0 2 2 1 1 0 1 2 0 2\n",
            " 0 2 1 1 1 0 1]\n",
            "130 / 200 Training loss: 0.0018158001369900174, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2935416666666666, Validation_Accuracy: 0.8133333325386047\n",
            "130 th epoch\n",
            "gt [1 1 1 1 1 2 1 2 2 0 2 1 1 1 0 0 0 2 2 1 1 2 1 2 2 1 1 1 1 1 1 1 2 0 2 2 1\n",
            " 0 0 0 1 0 2 0]\n",
            "pred [2 1 1 0 0 2 0 1 2 0 1 1 1 2 0 0 0 2 1 1 1 2 1 2 2 1 1 1 1 1 2 1 2 0 2 2 1\n",
            " 0 0 0 1 0 2 0]\n",
            "131 / 200 Training loss: 0.0017735601354528356, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.292890625, Validation_Accuracy: 0.79666668176651\n",
            "131 th epoch\n",
            "gt [2 1 1 2 1 0 0 2 1 2 0 2 1 2 0 2 1 2 0 0 0 2 1 1 1 1 0 2 1 1 2 2 0 1 1 2 1\n",
            " 0 0 1 0 2 2 1]\n",
            "pred [2 1 1 1 2 0 0 2 1 2 0 2 1 1 0 1 0 1 0 0 0 2 0 1 1 1 0 2 1 2 2 2 0 1 1 2 2\n",
            " 0 0 1 2 2 1 1]\n",
            "132 / 200 Training loss: 0.0016155994379961932, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3286979166666666, Validation_Accuracy: 0.7933333516120911\n",
            "132 th epoch\n",
            "gt [0 1 1 1 1 0 2 2 0 1 2 0 2 1 2 2 2 2 2 1 2 0 0 0 0 2 1 1 1 0 2 2 1 0 2 2 0\n",
            " 0 2 0 2 1 0 2]\n",
            "pred [0 1 1 2 1 0 2 1 0 1 1 0 1 1 2 1 2 2 1 2 2 0 0 0 0 2 0 1 1 0 2 2 1 0 1 2 0\n",
            " 0 2 2 2 1 0 0]\n",
            "133 / 200 Training loss: 0.001049183033130787, Tran_Accuracy: 1.0, Validation_loss: 1.3540885416666666, Validation_Accuracy: 0.7799999713897705\n",
            "133 th epoch\n",
            "gt [2 2 2 2 1 2 1 2 0 0 0 0 1 2 2 0 2 1 2 0 1 0 0 2 1 2 0 0 2 1 1 2 0 1 2 1 0\n",
            " 0 0 0 1 0 0 0]\n",
            "pred [2 2 2 2 1 2 1 2 0 0 0 0 2 2 1 0 2 1 1 0 0 0 0 2 1 2 0 0 1 1 2 2 0 1 1 2 0\n",
            " 0 0 0 1 0 0 0]\n",
            "134 / 200 Training loss: 0.0014453972710503473, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2249739583333332, Validation_Accuracy: 0.800000011920929\n",
            "134 th epoch\n",
            "gt [0 2 1 0 1 1 2 1 1 2 0 0 0 0 2 2 0 0 2 2 2 2 2 0 0 1 2 1 0 0 1 2 1 2 1 1 0\n",
            " 2 2 1 2 1 2 1]\n",
            "pred [0 2 2 0 1 1 2 1 1 1 0 0 0 0 1 2 0 0 2 2 2 2 1 0 0 1 2 1 0 0 1 2 1 1 2 1 0\n",
            " 2 2 1 2 2 1 1]\n",
            "135 / 200 Training loss: 0.0013450260515566225, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2683723958333333, Validation_Accuracy: 0.8033333420753479\n",
            "135 th epoch\n",
            "gt [2 0 2 1 0 2 1 0 0 0 2 0 1 1 0 2 2 1 2 0 0 1 0 0 1 1 1 0 1 2 2 2 2 2 2 2 1\n",
            " 1 0 2 0 0 1 0]\n",
            "pred [2 0 2 1 0 0 1 0 1 0 2 0 1 1 0 2 1 2 2 2 0 0 0 0 1 2 1 0 1 2 2 2 1 2 2 1 1\n",
            " 1 0 2 0 0 2 0]\n",
            "136 / 200 Training loss: 0.0018197674221462673, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2484375, Validation_Accuracy: 0.8066666722297668\n",
            "136 th epoch\n",
            "gt [0 2 2 2 2 2 2 1 1 2 0 1 1 0 2 0 0 1 2 0 2 0 1 0 2 2 2 2 2 0 1 1 2 2 0 2 0\n",
            " 2 1 1 2 1 0 1]\n",
            "pred [0 2 2 2 2 1 2 2 1 2 0 1 1 0 1 0 0 2 2 0 2 0 0 0 2 2 1 2 2 0 1 1 2 2 1 1 0\n",
            " 2 1 1 2 1 0 1]\n",
            "137 / 200 Training loss: 0.0011816236707899305, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3275260416666668, Validation_Accuracy: 0.7900000214576721\n",
            "137 th epoch\n",
            "gt [1 1 1 0 1 0 2 1 0 2 0 1 0 2 1 1 0 2 0 1 0 2 2 0 2 0 1 2 0 0 2 2 0 0 0 2 0\n",
            " 2 1 1 0 0 1 0]\n",
            "pred [2 0 1 2 2 0 2 2 0 2 1 2 0 2 1 1 0 1 0 1 0 2 2 0 2 0 1 2 0 0 2 2 0 2 0 2 0\n",
            " 2 1 1 0 0 1 0]\n",
            "138 / 200 Training loss: 0.0023057725694444445, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2396875, Validation_Accuracy: 0.8066666722297668\n",
            "138 th epoch\n",
            "gt [2 2 0 0 1 1 2 2 1 0 1 0 2 0 2 2 0 1 1 0 2 1 0 2 1 2 1 0 2 0 2 2 0 1 1 1 2\n",
            " 1 0 0 2 0 0 1]\n",
            "pred [2 1 0 2 1 1 1 2 1 0 2 0 2 0 2 1 0 0 1 0 2 2 2 2 1 2 1 0 1 0 2 2 0 1 1 1 2\n",
            " 2 0 0 2 0 0 1]\n",
            "139 / 200 Training loss: 0.001098963419596354, Tran_Accuracy: 1.0, Validation_loss: 1.3035807291666666, Validation_Accuracy: 0.7900000214576721\n",
            "139 th epoch\n",
            "gt [1 2 0 2 0 0 2 1 0 0 1 2 1 2 0 2 1 1 1 0 2 0 1 2 1 2 0 1 1 1 2 1 0 1 2 0 2\n",
            " 2 1 0 0 1 0 2]\n",
            "pred [1 1 0 2 0 0 2 0 0 0 1 2 1 2 0 1 1 2 1 0 2 0 1 2 2 2 0 1 2 1 2 1 0 1 1 0 2\n",
            " 2 1 0 0 1 0 2]\n",
            "140 / 200 Training loss: 0.0014355242693865741, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2796744791666668, Validation_Accuracy: 0.8133333325386047\n",
            "140 th epoch\n",
            "gt [2 2 0 1 0 2 2 0 2 0 2 0 1 2 1 2 1 1 2 0 1 1 2 2 1 2 1 2 0 1 0 2 1 0 2 1 1\n",
            " 0 1 2 1 1 2 1]\n",
            "pred [2 2 2 0 0 2 2 0 2 0 1 1 1 2 2 2 1 1 2 0 2 0 2 0 1 2 1 2 0 1 0 2 2 0 1 0 1\n",
            " 0 1 2 1 0 2 2]\n",
            "141 / 200 Training loss: 0.0011169807999222368, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.1813932291666667, Validation_Accuracy: 0.7866666913032532\n",
            "141 th epoch\n",
            "gt [0 1 1 1 1 0 0 1 0 0 1 2 1 1 1 0 0 2 2 1 0 1 2 2 2 2 0 1 1 1 2 0 0 0 2 1 2\n",
            " 0 1 0 0 1 2 2]\n",
            "pred [1 2 1 2 2 0 0 2 0 0 1 2 1 2 1 0 0 1 2 2 0 1 2 2 1 2 0 1 1 1 2 2 0 0 2 1 1\n",
            " 0 1 0 0 1 2 2]\n",
            "142 / 200 Training loss: 0.003825299298321759, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.3070182291666668, Validation_Accuracy: 0.8100000023841858\n",
            "142 th epoch\n",
            "gt [1 1 0 2 0 1 2 2 0 1 2 1 0 2 0 0 1 2 0 0 1 2 2 2 1 0 1 2 0 2 0 2 0 0 2 1 2\n",
            " 1 1 1 0 1 1 1]\n",
            "pred [1 1 0 2 0 2 2 2 2 1 2 1 0 2 0 0 1 2 1 0 1 2 1 1 1 0 0 2 0 2 2 2 0 0 2 2 2\n",
            " 1 2 1 0 2 0 1]\n",
            "143 / 200 Training loss: 0.000897888254236292, Tran_Accuracy: 1.0, Validation_loss: 1.2672526041666667, Validation_Accuracy: 0.7933333516120911\n",
            "143 th epoch\n",
            "gt [2 1 1 0 0 0 1 1 0 0 1 1 2 0 0 0 2 1 1 2 2 0 2 2 1 2 0 0 1 0 1 2 1 0 2 2 1\n",
            " 1 0 1 1 1 0 0]\n",
            "pred [2 1 1 0 0 0 1 1 0 0 1 1 2 0 0 0 2 1 2 1 1 0 1 2 2 2 0 0 1 0 2 2 2 0 2 2 2\n",
            " 1 0 2 1 1 0 0]\n",
            "144 / 200 Training loss: 0.0012134778058087384, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3710286458333334, Validation_Accuracy: 0.800000011920929\n",
            "144 th epoch\n",
            "gt [1 2 0 2 1 1 0 1 2 2 2 0 0 0 1 2 2 1 1 1 2 0 2 2 2 0 0 0 2 0 2 2 0 0 2 2 1\n",
            " 2 1 1 1 2 2 2]\n",
            "pred [1 2 0 2 1 1 0 0 1 2 2 0 0 0 1 2 2 1 2 1 2 0 2 0 1 0 0 0 2 0 2 2 0 0 2 2 2\n",
            " 2 1 1 1 1 2 2]\n",
            "145 / 200 Training loss: 0.0027365140561704283, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3232194010416667, Validation_Accuracy: 0.8100000023841858\n",
            "145 th epoch\n",
            "gt [0 1 0 0 0 0 1 2 2 2 0 2 2 2 2 2 2 2 1 0 2 1 1 1 2 0 2 0 2 0 0 1 2 1 1 0 2\n",
            " 0 0 1 1 1 1 0]\n",
            "pred [0 1 0 0 0 0 2 1 1 2 0 2 2 2 1 2 2 1 2 0 2 1 1 0 2 0 2 0 2 0 0 1 1 1 1 0 2\n",
            " 0 0 1 0 2 0 0]\n",
            "146 / 200 Training loss: 0.0032976546110930266, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.2878776041666666, Validation_Accuracy: 0.8033333420753479\n",
            "146 th epoch\n",
            "gt [2 2 0 0 1 2 2 0 0 1 0 1 2 0 0 2 1 1 2 1 2 2 1 0 2 0 1 0 1 2 2 2 1 2 2 1 1\n",
            " 2 0 2 1 0 2 1]\n",
            "pred [2 2 0 0 1 0 2 0 0 1 0 1 2 0 0 2 0 1 2 1 1 2 1 0 1 0 0 2 1 1 2 2 1 2 1 1 1\n",
            " 2 0 2 2 0 1 1]\n",
            "147 / 200 Training loss: 0.001337458822462294, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.1951692708333332, Validation_Accuracy: 0.8066666722297668\n",
            "147 th epoch\n",
            "gt [0 1 2 1 1 2 2 2 2 0 0 0 2 1 0 1 2 1 0 2 0 2 1 0 0 0 1 0 0 2 1 2 2 1 1 1 1\n",
            " 0 1 2 0 2 1 1]\n",
            "pred [0 1 2 1 1 2 1 2 2 0 0 0 2 1 0 1 2 2 0 2 0 2 0 0 0 0 1 0 0 0 1 2 2 2 1 1 1\n",
            " 0 1 2 0 2 0 1]\n",
            "148 / 200 Training loss: 0.0015603129069010416, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.33802734375, Validation_Accuracy: 0.8199999928474426\n",
            "148 th epoch\n",
            "gt [0 1 1 2 2 1 1 0 1 1 0 2 0 1 0 2 0 0 1 0 2 1 0 0 1 1 1 0 1 2 2 2 1 0 0 2 2\n",
            " 2 1 2 2 1 2 0]\n",
            "pred [0 1 1 1 2 1 2 0 1 0 0 2 0 1 0 2 0 1 2 0 2 1 0 2 0 1 1 0 1 2 1 2 2 0 0 2 1\n",
            " 2 2 2 2 1 1 0]\n",
            "149 / 200 Training loss: 0.0015134302775065105, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2579296875, Validation_Accuracy: 0.8033333420753479\n",
            "149 th epoch\n",
            "gt [1 1 0 2 0 2 2 2 2 2 0 1 0 1 0 0 2 0 2 2 2 1 1 2 2 0 1 2 0 0 2 0 1 1 2 2 1\n",
            " 2 0 2 1 2 2 0]\n",
            "pred [1 0 0 2 0 2 1 2 2 1 0 1 0 1 0 0 2 0 1 2 2 1 1 1 2 1 0 2 0 0 2 0 1 1 2 1 2\n",
            " 1 0 2 1 2 1 2]\n",
            "150 / 200 Training loss: 0.00303309405291522, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.249765625, Validation_Accuracy: 0.8033333420753479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.85      0.85      0.85        13\n",
            "     Neutral       0.50      0.73      0.59        11\n",
            "       Smoke       0.87      0.65      0.74        20\n",
            "\n",
            "    accuracy                           0.73        44\n",
            "   macro avg       0.74      0.74      0.73        44\n",
            "weighted avg       0.77      0.73      0.74        44\n",
            "\n",
            "150 th epoch\n",
            "gt [0 1 1 0 2 0 2 0 0 1 0 1 0 1 1 2 1 2 2 1 0 1 1 0 0 2 0 1 0 2 1 2 1 2 1 0 2\n",
            " 2 0 1 0 2 0 0]\n",
            "pred [0 2 2 0 2 0 2 0 0 1 0 1 0 1 1 2 1 1 0 2 0 0 1 0 0 2 0 2 0 1 2 2 1 2 2 0 2\n",
            " 1 0 1 0 2 0 0]\n",
            "151 / 200 Training loss: 0.0006268776787651909, Tran_Accuracy: 1.0, Validation_loss: 1.3081380208333333, Validation_Accuracy: 0.79666668176651\n",
            "151 th epoch\n",
            "gt [0 1 2 2 1 2 2 1 2 0 2 2 2 0 1 1 2 2 1 0 2 0 2 2 1 0 0 0 2 2 1 0 1 2 1 0 0\n",
            " 0 1 0 1 1 2 0]\n",
            "pred [0 1 2 2 1 1 2 1 2 0 2 1 1 0 1 2 2 2 1 0 0 2 2 1 2 0 0 0 2 2 1 0 1 2 1 0 0\n",
            " 0 1 0 1 2 1 0]\n",
            "152 / 200 Training loss: 0.0012962030481409143, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3115755208333333, Validation_Accuracy: 0.79666668176651\n",
            "152 th epoch\n",
            "gt [1 0 2 0 0 0 2 1 1 2 0 2 1 0 2 1 1 2 2 2 0 0 2 0 0 2 1 2 1 2 2 2 0 1 0 1 0\n",
            " 2 2 2 0 0 0 2]\n",
            "pred [1 0 0 0 0 0 2 1 1 1 0 2 1 0 1 1 1 2 2 2 0 0 2 0 0 2 0 2 1 1 2 2 0 1 0 1 2\n",
            " 2 2 2 0 1 0 2]\n",
            "153 / 200 Training loss: 0.001228109289098669, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2676171875, Validation_Accuracy: 0.8100000023841858\n",
            "153 th epoch\n",
            "gt [2 0 2 1 2 1 1 2 2 2 0 0 1 0 0 1 1 0 1 1 2 2 0 1 2 1 2 2 1 2 0 0 0 0 2 1 0\n",
            " 2 2 2 2 2 0 2]\n",
            "pred [2 0 1 1 2 1 2 2 2 2 0 2 2 0 0 1 1 0 2 1 2 2 0 1 1 2 1 2 1 1 0 0 0 0 2 2 0\n",
            " 2 2 2 2 2 2 1]\n",
            "154 / 200 Training loss: 0.00235330652307581, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.2320703125, Validation_Accuracy: 0.8100000023841858\n",
            "154 th epoch\n",
            "gt [0 0 2 1 1 1 1 2 0 0 1 0 2 1 2 2 1 1 2 1 2 1 1 0 1 0 2 0 1 0 0 2 1 2 1 2 0\n",
            " 0 0 0 2 2 1 1]\n",
            "pred [0 0 2 1 1 1 1 2 2 0 1 0 1 1 2 1 1 2 2 1 2 1 1 0 0 0 1 0 1 0 0 0 1 2 1 2 0\n",
            " 0 0 0 2 2 1 1]\n",
            "155 / 200 Training loss: 0.001729746836203116, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2138671875, Validation_Accuracy: 0.8066666722297668\n",
            "155 th epoch\n",
            "gt [2 1 2 2 0 0 0 2 0 1 2 1 0 2 2 2 0 1 1 1 2 2 2 2 1 0 1 1 1 1 0 0 1 1 1 0 2\n",
            " 0 0 2 0 2 1 1]\n",
            "pred [1 2 2 1 0 0 0 2 2 2 1 1 0 2 2 2 0 2 1 0 2 1 2 2 1 0 1 1 2 1 0 0 2 1 1 0 1\n",
            " 0 0 2 0 2 2 1]\n",
            "156 / 200 Training loss: 0.0019396478158456307, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2813151041666666, Validation_Accuracy: 0.7933333516120911\n",
            "156 th epoch\n",
            "gt [1 1 0 0 2 0 2 2 2 0 2 2 0 0 2 0 2 0 1 2 1 0 0 1 1 2 1 2 0 2 2 0 0 1 0 2 0\n",
            " 2 1 2 1 2 1 2]\n",
            "pred [1 1 0 0 2 2 2 2 1 0 2 2 0 0 2 0 1 0 1 2 1 0 1 1 1 2 1 2 1 1 2 0 0 1 0 2 0\n",
            " 1 0 2 2 1 1 2]\n",
            "157 / 200 Training loss: 0.0009139159873679832, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3548697916666668, Validation_Accuracy: 0.8166666626930237\n",
            "157 th epoch\n",
            "gt [1 2 0 2 2 1 1 2 2 1 0 2 2 2 2 2 1 2 2 0 2 2 0 1 1 0 0 2 0 1 1 2 1 1 1 0 2\n",
            " 0 0 1 0 1 1 0]\n",
            "pred [1 2 0 2 2 1 1 2 2 0 0 2 1 2 2 2 1 2 2 0 2 2 1 1 2 0 0 1 0 1 1 1 1 1 1 0 2\n",
            " 0 0 1 0 2 1 0]\n",
            "158 / 200 Training loss: 0.001111789279513889, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3039453125, Validation_Accuracy: 0.8133333325386047\n",
            "158 th epoch\n",
            "gt [1 2 2 2 2 0 1 0 1 0 0 0 1 1 1 1 1 0 0 2 0 1 2 0 2 2 1 0 2 0 0 0 0 0 2 1 2\n",
            " 1 0 2 1 2 0 1]\n",
            "pred [1 2 2 2 2 0 1 0 2 0 0 0 1 1 2 1 1 0 0 1 0 1 2 0 1 2 1 0 2 0 0 0 0 0 2 1 2\n",
            " 1 1 2 2 2 0 1]\n",
            "159 / 200 Training loss: 0.0014631737603081597, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.303125, Validation_Accuracy: 0.800000011920929\n",
            "159 th epoch\n",
            "gt [2 2 1 0 1 0 2 2 1 2 1 2 1 0 2 2 0 1 2 2 2 0 0 2 1 2 0 0 2 2 2 0 1 1 2 1 1\n",
            " 2 0 2 0 0 1 1]\n",
            "pred [2 2 1 0 2 0 2 2 0 1 1 2 1 0 2 2 0 1 0 2 2 2 0 2 2 2 0 0 2 1 0 0 1 1 1 1 1\n",
            " 2 0 2 0 0 1 2]\n",
            "160 / 200 Training loss: 0.0014236859922055845, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3258723958333334, Validation_Accuracy: 0.8100000023841858\n",
            "160 th epoch\n",
            "gt [0 1 0 0 0 0 0 0 2 1 1 1 2 1 1 2 0 1 2 1 1 0 2 1 2 2 1 0 0 0 2 1 0 1 0 1 0\n",
            " 2 2 2 2 0 1 0]\n",
            "pred [0 1 0 0 2 0 0 0 2 2 1 1 1 1 1 2 0 1 2 1 2 0 2 0 0 2 1 0 0 0 2 1 0 1 2 2 0\n",
            " 2 2 2 2 0 1 0]\n",
            "161 / 200 Training loss: 0.0015402786820023148, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3963411458333332, Validation_Accuracy: 0.7900000214576721\n",
            "161 th epoch\n",
            "gt [1 0 0 1 0 0 0 2 1 0 0 0 2 0 1 2 2 1 2 1 2 0 0 1 0 1 0 0 1 0 2 1 0 1 1 2 1\n",
            " 1 1 2 0 0 0 1]\n",
            "pred [1 0 0 1 0 0 0 2 1 0 0 0 2 0 1 2 2 1 2 1 2 0 0 1 0 1 0 0 1 0 2 1 0 1 2 1 1\n",
            " 1 1 2 0 0 0 2]\n",
            "162 / 200 Training loss: 0.0011818610297309028, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2316145833333334, Validation_Accuracy: 0.8033333420753479\n",
            "162 th epoch\n",
            "gt [0 0 0 1 1 0 1 0 2 1 2 1 1 0 0 2 2 0 0 2 2 2 1 1 2 2 0 2 1 0 2 0 2 0 1 2 0\n",
            " 1 0 0 2 1 2 1]\n",
            "pred [0 2 0 1 1 2 2 0 2 1 2 1 1 0 0 2 1 0 0 2 1 1 1 1 2 2 0 2 1 0 2 0 2 0 2 2 0\n",
            " 1 0 0 1 1 2 1]\n",
            "163 / 200 Training loss: 0.001191981280291522, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2515364583333333, Validation_Accuracy: 0.8066666722297668\n",
            "163 th epoch\n",
            "gt [0 1 2 0 0 0 0 2 0 2 1 2 1 0 1 0 1 2 2 0 0 1 2 1 1 2 0 0 1 0 2 2 2 1 2 2 1\n",
            " 0 2 2 1 0 1 2]\n",
            "pred [0 1 2 0 0 0 1 1 0 2 2 2 1 0 1 0 1 2 2 0 2 1 2 1 1 2 0 0 0 1 1 2 2 2 2 2 1\n",
            " 0 1 2 1 0 2 2]\n",
            "164 / 200 Training loss: 0.0014706221333256474, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2301041666666668, Validation_Accuracy: 0.8166666626930237\n",
            "164 th epoch\n",
            "gt [2 0 1 2 0 0 2 1 0 2 0 0 0 2 1 2 1 1 1 2 2 2 1 1 1 0 0 2 1 1 0 0 2 1 2 0 0\n",
            " 1 0 1 0 2 2 2]\n",
            "pred [1 0 1 1 0 0 2 2 0 0 1 0 0 2 1 2 1 1 0 1 2 1 0 2 1 0 0 2 1 1 0 0 2 1 2 0 0\n",
            " 1 0 1 0 2 2 2]\n",
            "165 / 200 Training loss: 0.0029721719247323497, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2843619791666667, Validation_Accuracy: 0.79666668176651\n",
            "165 th epoch\n",
            "gt [1 0 0 2 2 2 2 0 1 2 2 0 2 1 0 0 0 2 1 0 0 0 2 0 0 1 1 1 2 0 1 2 0 0 0 1 2\n",
            " 1 0 0 0 1 0 2]\n",
            "pred [1 0 0 2 2 2 2 0 1 2 2 0 1 1 0 0 0 2 1 0 2 0 2 0 0 2 1 0 1 0 1 2 2 0 1 1 2\n",
            " 1 0 0 2 2 0 2]\n",
            "166 / 200 Training loss: 0.0014253614566944264, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2132291666666666, Validation_Accuracy: 0.8033333420753479\n",
            "166 th epoch\n",
            "gt [1 2 2 1 0 0 0 0 2 0 0 1 2 1 2 2 0 1 0 2 1 2 1 1 0 1 2 0 1 1 0 0 2 2 2 0 1\n",
            " 1 0 0 2 1 0 1]\n",
            "pred [2 1 2 1 0 0 0 1 2 0 0 1 2 1 2 2 0 1 0 2 1 2 0 1 2 1 2 0 1 2 0 0 2 2 1 1 1\n",
            " 1 0 0 2 1 0 2]\n",
            "167 / 200 Training loss: 0.0011351684287742331, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2947005208333333, Validation_Accuracy: 0.8100000023841858\n",
            "167 th epoch\n",
            "gt [0 2 2 2 1 2 2 2 0 0 1 2 2 1 1 1 1 2 1 1 2 2 1 2 0 1 1 2 1 0 0 0 1 1 0 0 0\n",
            " 1 0 2 2 0 1 2]\n",
            "pred [0 2 2 2 1 2 2 2 1 0 1 2 2 1 1 1 2 2 1 1 2 2 1 2 0 1 1 2 1 2 0 0 2 2 0 0 0\n",
            " 0 0 1 2 0 1 2]\n",
            "168 / 200 Training loss: 0.0013188870747884115, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.301640625, Validation_Accuracy: 0.8100000023841858\n",
            "168 th epoch\n",
            "gt [1 1 2 1 1 0 0 2 2 2 1 2 1 2 2 2 0 2 1 0 0 0 1 0 2 0 0 2 1 1 1 2 2 0 1 2 1\n",
            " 1 1 0 2 0 0 0]\n",
            "pred [1 1 1 1 1 0 0 2 2 1 0 2 1 2 2 2 0 2 1 0 0 0 1 0 2 0 0 2 1 1 0 1 2 0 1 2 1\n",
            " 1 1 0 2 0 0 0]\n",
            "169 / 200 Training loss: 0.001196229722764757, Tran_Accuracy: 1.0, Validation_loss: 1.2691927083333334, Validation_Accuracy: 0.800000011920929\n",
            "169 th epoch\n",
            "gt [0 0 1 0 2 0 2 0 1 0 1 1 1 1 2 1 1 0 0 2 0 0 0 1 1 1 1 0 1 1 1 0 0 2 0 1 2\n",
            " 0 2 0 1 2 2 1]\n",
            "pred [0 0 1 0 2 0 2 0 2 0 1 2 2 1 1 2 1 1 0 2 0 0 0 1 1 1 1 0 1 0 1 0 0 2 0 1 2\n",
            " 0 2 0 1 1 2 1]\n",
            "170 / 200 Training loss: 0.0016374178285951967, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2220833333333334, Validation_Accuracy: 0.8066666722297668\n",
            "170 th epoch\n",
            "gt [1 2 1 1 0 1 2 0 2 1 0 0 1 1 1 0 0 1 2 1 0 0 2 1 0 0 0 0 1 2 0 2 1 1 0 2 1\n",
            " 2 1 2 1 0 0 2]\n",
            "pred [1 2 1 1 0 2 2 2 2 1 0 0 1 2 1 0 0 1 2 1 0 0 2 1 0 0 0 2 1 2 0 1 0 2 0 2 1\n",
            " 0 2 2 2 0 0 1]\n",
            "171 / 200 Training loss: 0.0018244383070203994, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3374348958333333, Validation_Accuracy: 0.7933333516120911\n",
            "171 th epoch\n",
            "gt [2 0 1 0 1 2 1 0 2 0 0 0 0 0 2 2 1 0 0 0 2 2 1 1 2 1 2 2 2 0 1 0 1 2 0 0 2\n",
            " 2 0 1 0 1 1 0]\n",
            "pred [2 0 2 1 1 2 1 0 1 0 0 0 0 0 2 2 1 0 0 0 1 2 1 1 2 2 2 2 2 0 1 0 2 2 0 0 2\n",
            " 2 0 1 0 1 1 0]\n",
            "172 / 200 Training loss: 0.0013735933657045717, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.27607421875, Validation_Accuracy: 0.8366666436195374\n",
            "--------------------------Saving Model---------------------------\n",
            "172 th epoch\n",
            "gt [2 1 0 0 0 2 2 0 2 1 1 1 2 2 1 0 2 1 1 1 2 1 2 2 2 0 2 0 1 1 2 1 0 0 1 2 1\n",
            " 2 1 2 1 2 0 2]\n",
            "pred [2 2 0 0 0 2 2 0 1 1 1 1 2 2 2 0 2 1 0 2 0 1 1 2 2 0 2 2 1 0 2 1 0 0 1 2 0\n",
            " 2 2 2 1 2 0 2]\n",
            "173 / 200 Training loss: 0.0016586967750831887, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2302604166666666, Validation_Accuracy: 0.8100000023841858\n",
            "173 th epoch\n",
            "gt [1 0 0 2 1 1 2 0 1 2 0 0 2 0 2 2 2 0 0 0 1 1 1 1 1 0 2 1 0 2 2 1 2 1 1 0 1\n",
            " 2 0 2 0 2 1 1]\n",
            "pred [1 0 0 2 1 1 2 0 1 2 0 0 1 0 0 1 2 0 0 0 1 1 2 2 1 0 1 2 0 1 2 1 2 1 1 0 0\n",
            " 2 2 2 0 2 2 1]\n",
            "174 / 200 Training loss: 0.001162694295247396, Tran_Accuracy: 1.0, Validation_loss: 1.3072786458333334, Validation_Accuracy: 0.7933333516120911\n",
            "174 th epoch\n",
            "gt [0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 2 1 1 2 2 1 0 2 1 0 1 0 0 2 2 1 2 1 1\n",
            " 1 0 2 0 0 2 0]\n",
            "pred [0 1 1 1 1 0 0 0 0 1 2 1 0 1 1 2 0 0 2 2 2 2 1 1 0 1 1 0 2 0 0 2 2 1 2 1 1\n",
            " 1 0 2 0 0 2 2]\n",
            "175 / 200 Training loss: 0.00198023760760272, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2699739583333334, Validation_Accuracy: 0.8100000023841858\n",
            "175 th epoch\n",
            "gt [2 0 0 2 0 1 1 0 2 0 2 2 0 0 1 1 0 2 2 1 0 2 2 0 0 1 1 0 2 1 0 0 2 0 2 0 2\n",
            " 0 2 0 0 1 1 1]\n",
            "pred [2 0 0 2 0 1 1 0 2 0 2 1 0 0 1 1 0 2 2 1 0 1 2 0 0 1 1 0 1 1 0 2 2 0 2 0 2\n",
            " 0 2 0 0 2 1 1]\n",
            "176 / 200 Training loss: 0.002127415692364728, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2987174479166668, Validation_Accuracy: 0.800000011920929\n",
            "176 th epoch\n",
            "gt [1 0 1 0 1 2 2 0 0 0 0 2 0 1 0 2 2 1 1 2 1 0 2 1 2 1 0 2 1 0 1 0 2 2 0 2 0\n",
            " 2 1 2 0 1 0 0]\n",
            "pred [1 0 1 0 0 2 2 0 0 0 0 2 0 2 0 1 2 2 0 1 2 0 2 1 2 1 0 2 1 2 1 1 2 2 0 1 0\n",
            " 2 2 2 2 1 0 0]\n",
            "177 / 200 Training loss: 0.0008505729392722801, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3513541666666666, Validation_Accuracy: 0.800000011920929\n",
            "177 th epoch\n",
            "gt [2 0 2 0 2 2 0 1 1 0 0 0 1 0 1 0 0 1 2 1 2 2 0 1 2 0 1 2 0 1 0 0 0 1 0 1 0\n",
            " 1 1 1 2 0 1 2]\n",
            "pred [1 0 2 0 1 2 1 1 2 1 0 0 2 0 0 0 0 2 2 1 2 2 0 1 2 0 1 1 0 1 0 0 0 1 0 1 0\n",
            " 1 1 2 2 0 2 2]\n",
            "178 / 200 Training loss: 0.0010049035814073352, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3169010416666667, Validation_Accuracy: 0.79666668176651\n",
            "178 th epoch\n",
            "gt [2 0 2 0 0 2 0 1 0 1 1 1 1 2 0 0 1 1 1 0 0 0 2 0 1 1 0 1 1 2 2 0 0 0 1 2 0\n",
            " 2 0 1 1 1 1 2]\n",
            "pred [2 2 1 0 0 2 0 1 0 1 2 1 1 2 0 0 0 1 2 0 2 0 2 2 1 1 0 1 1 1 2 0 0 0 1 1 0\n",
            " 2 0 0 1 1 2 2]\n",
            "179 / 200 Training loss: 0.0031502518830475983, Tran_Accuracy: 0.9981481432914734, Validation_loss: 1.270625, Validation_Accuracy: 0.8199999928474426\n",
            "179 th epoch\n",
            "gt [2 0 1 0 2 1 1 1 1 1 0 0 0 0 0 2 0 1 0 0 1 0 1 2 0 1 2 2 0 2 0 2 1 1 2 1 2\n",
            " 2 2 2 1 1 0 1]\n",
            "pred [2 0 1 0 2 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 2 2 0 1 2 2 0 2 0 2 1 1 2 2 2\n",
            " 2 2 2 0 1 0 1]\n",
            "180 / 200 Training loss: 0.0011314787688078704, Tran_Accuracy: 1.0, Validation_loss: 1.2676888020833332, Validation_Accuracy: 0.8066666722297668\n",
            "180 th epoch\n",
            "gt [2 1 2 2 0 1 0 2 2 0 1 0 2 1 1 2 2 2 0 2 2 2 2 2 0 2 2 2 0 0 1 1 1 0 0 1 2\n",
            " 1 0 0 1 1 1 2]\n",
            "pred [1 1 2 1 0 1 0 2 2 0 1 0 2 1 2 2 2 2 0 1 1 2 2 2 0 2 2 2 0 0 1 2 2 2 0 1 2\n",
            " 2 0 0 1 2 1 2]\n",
            "181 / 200 Training loss: 0.0012766068070023148, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3070963541666667, Validation_Accuracy: 0.7933333516120911\n",
            "181 th epoch\n",
            "gt [0 0 2 0 2 2 0 1 0 1 1 1 2 0 2 1 2 1 2 2 0 1 1 2 1 2 2 2 2 0 1 0 0 0 0 0 2\n",
            " 1 2 2 2 2 2 0]\n",
            "pred [0 1 2 0 2 1 0 2 0 1 1 1 1 0 2 1 2 0 2 1 0 2 1 2 0 2 1 1 0 0 2 0 2 0 0 0 2\n",
            " 1 1 2 2 2 1 0]\n",
            "182 / 200 Training loss: 0.0020741992526584203, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.3425, Validation_Accuracy: 0.7933333516120911\n",
            "182 th epoch\n",
            "gt [0 2 0 0 0 1 1 0 2 0 1 0 1 1 2 0 0 1 1 1 0 0 0 0 1 0 1 0 2 0 2 1 1 0 0 0 2\n",
            " 0 2 0 0 2 2 1]\n",
            "pred [2 2 2 0 0 1 1 0 1 0 1 0 2 1 2 0 0 1 0 2 0 0 0 0 1 1 0 0 2 0 2 1 1 0 0 0 2\n",
            " 0 2 0 0 1 2 1]\n",
            "183 / 200 Training loss: 0.001250412110929136, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3458854166666667, Validation_Accuracy: 0.8033333420753479\n",
            "183 th epoch\n",
            "gt [0 2 1 0 1 0 2 2 2 2 0 1 2 1 0 1 2 1 1 0 2 1 2 2 1 1 0 0 1 1 0 2 0 0 0 0 1\n",
            " 0 0 2 2 0 0 1]\n",
            "pred [0 1 2 0 1 1 2 2 1 2 0 1 2 2 0 1 2 2 2 0 2 2 2 2 1 1 0 0 2 1 0 2 0 0 0 0 1\n",
            " 2 0 2 1 0 0 1]\n",
            "184 / 200 Training loss: 0.0012543261492693866, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3831380208333333, Validation_Accuracy: 0.8100000023841858\n",
            "184 th epoch\n",
            "gt [0 1 0 2 1 2 2 0 0 2 2 1 0 2 2 1 2 1 0 0 1 2 2 0 2 2 1 0 2 2 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 2 2]\n",
            "pred [0 0 0 1 1 2 2 0 0 2 2 2 0 2 2 1 1 1 0 0 1 2 2 0 2 2 1 0 2 1 0 2 2 1 1 2 1\n",
            " 0 0 0 1 1 2 2]\n",
            "185 / 200 Training loss: 0.0009549289279513889, Tran_Accuracy: 1.0, Validation_loss: 1.2538671875, Validation_Accuracy: 0.800000011920929\n",
            "185 th epoch\n",
            "gt [2 2 1 2 0 0 0 1 0 2 1 2 0 2 1 2 2 2 0 2 1 1 0 1 2 2 0 0 1 2 0 1 2 1 1 2 2\n",
            " 0 1 2 1 1 2 0]\n",
            "pred [2 1 1 2 0 0 0 1 2 1 1 2 0 2 2 2 2 2 0 1 1 1 0 1 2 1 0 0 1 1 0 2 2 2 1 2 2\n",
            " 0 0 2 1 2 2 0]\n",
            "186 / 200 Training loss: 0.001059123233512596, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3151302083333334, Validation_Accuracy: 0.79666668176651\n",
            "186 th epoch\n",
            "gt [2 0 1 1 0 0 1 0 1 1 1 1 0 0 2 1 0 0 2 0 1 2 2 2 2 1 2 2 2 2 2 1 2 0 2 0 1\n",
            " 0 0 0 0 1 2 1]\n",
            "pred [2 0 1 1 0 0 2 0 1 1 1 1 0 0 2 1 0 0 2 0 1 2 2 2 2 2 2 2 2 2 0 1 2 0 2 0 1\n",
            " 0 0 1 0 1 2 1]\n",
            "187 / 200 Training loss: 0.001014660287786413, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2104036458333334, Validation_Accuracy: 0.8233333230018616\n",
            "187 th epoch\n",
            "gt [1 2 2 1 0 0 1 2 0 2 1 2 1 2 2 1 0 2 1 0 1 1 2 0 2 2 1 1 0 2 0 2 2 0 0 2 2\n",
            " 1 1 1 2 1 0 2]\n",
            "pred [1 2 2 2 0 0 1 2 0 2 1 2 1 2 2 1 2 2 2 0 1 1 1 0 0 2 1 1 0 1 0 2 2 0 0 2 1\n",
            " 2 1 1 1 1 0 0]\n",
            "188 / 200 Training loss: 0.001269816557566325, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2206119791666667, Validation_Accuracy: 0.800000011920929\n",
            "188 th epoch\n",
            "gt [1 0 2 2 1 2 1 2 1 2 1 1 2 0 2 0 1 2 2 0 2 1 2 2 0 1 0 0 2 2 1 1 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0]\n",
            "pred [1 0 2 2 2 1 2 2 2 2 1 2 1 0 2 0 1 0 1 0 1 0 2 2 2 1 0 0 2 2 0 1 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0]\n",
            "189 / 200 Training loss: 0.0010036482634367765, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2880598958333334, Validation_Accuracy: 0.800000011920929\n",
            "189 th epoch\n",
            "gt [1 1 1 1 2 2 0 1 2 0 2 2 0 0 2 1 1 1 0 1 2 2 2 0 2 0 2 0 2 0 2 0 2 1 1 2 0\n",
            " 2 1 2 0 2 0 2]\n",
            "pred [1 1 2 2 2 2 0 1 2 0 2 1 0 0 1 1 1 0 0 1 2 1 2 0 2 0 1 0 2 0 2 0 2 1 1 2 0\n",
            " 2 1 2 0 2 0 2]\n",
            "190 / 200 Training loss: 0.0024411434597439237, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2923307291666666, Validation_Accuracy: 0.8033333420753479\n",
            "190 th epoch\n",
            "gt [0 2 2 2 1 0 2 2 2 2 0 0 2 2 0 2 0 0 2 0 0 1 1 1 2 1 2 0 0 1 2 2 0 0 1 0 2\n",
            " 1 0 1 0 1 2 0]\n",
            "pred [0 2 2 1 1 0 2 1 2 2 1 0 1 2 0 2 0 0 2 0 0 1 1 1 1 1 2 0 0 1 2 2 0 0 1 0 2\n",
            " 2 0 1 0 1 2 0]\n",
            "191 / 200 Training loss: 0.0023617709124529804, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3365494791666668, Validation_Accuracy: 0.79666668176651\n",
            "191 th epoch\n",
            "gt [0 2 0 2 2 0 0 1 0 2 1 1 2 1 2 1 0 1 2 0 1 0 0 1 2 2 2 0 0 0 1 1 2 2 1 1 0\n",
            " 2 1 0 0 1 2 0]\n",
            "pred [0 2 0 2 2 0 0 2 2 2 1 1 2 1 2 1 0 1 1 0 1 0 0 2 2 2 2 0 0 0 1 1 2 2 1 2 0\n",
            " 2 1 0 2 2 2 0]\n",
            "192 / 200 Training loss: 0.0020358558937355322, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.2598697916666666, Validation_Accuracy: 0.800000011920929\n",
            "192 th epoch\n",
            "gt [0 0 0 0 1 0 1 2 2 1 0 1 2 0 1 2 2 0 1 0 1 0 1 0 2 1 0 2 1 2 1 1 1 2 0 1 0\n",
            " 0 1 2 1 2 1 1]\n",
            "pred [0 0 0 0 1 0 1 2 2 1 1 1 2 0 1 2 2 2 1 0 2 0 1 2 0 2 0 2 1 2 1 0 2 2 0 1 0\n",
            " 0 2 2 1 2 2 0]\n",
            "193 / 200 Training loss: 0.0012589009602864583, Tran_Accuracy: 1.0, Validation_loss: 1.317265625, Validation_Accuracy: 0.79666668176651\n",
            "193 th epoch\n",
            "gt [1 2 0 1 2 1 1 1 1 0 1 0 2 0 2 1 1 0 2 1 0 1 0 0 2 0 2 1 2 2 0 2 1 0 2 2 2\n",
            " 2 0 2 2 2 0 0]\n",
            "pred [0 2 0 1 2 1 2 1 1 2 1 0 1 0 2 1 1 0 2 1 0 1 0 0 1 0 2 1 2 0 0 2 0 0 2 1 2\n",
            " 2 2 2 2 1 0 0]\n",
            "194 / 200 Training loss: 0.0007937749226888021, Tran_Accuracy: 1.0, Validation_loss: 1.2930078125, Validation_Accuracy: 0.7933333516120911\n",
            "194 th epoch\n",
            "gt [0 0 2 0 0 1 2 1 2 1 0 0 2 1 2 0 2 0 1 2 1 0 1 1 2 1 2 1 0 1 2 0 1 0 2 0 1\n",
            " 1 0 2 2 1 1 2]\n",
            "pred [0 0 2 0 0 1 2 1 2 0 0 1 2 1 0 0 2 0 2 1 2 0 2 1 1 0 2 0 0 1 2 0 0 0 2 0 1\n",
            " 1 0 2 1 2 1 2]\n",
            "195 / 200 Training loss: 0.001664743776674624, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2211067708333334, Validation_Accuracy: 0.79666668176651\n",
            "195 th epoch\n",
            "gt [2 1 1 0 2 0 1 1 2 2 0 0 2 0 1 2 2 0 1 1 1 2 1 0 1 0 1 0 1 2 2 2 1 2 2 0 2\n",
            " 0 1 1 2 1 2 1]\n",
            "pred [1 1 1 0 2 0 1 1 2 2 0 0 2 0 1 2 2 1 1 1 1 2 0 0 1 0 1 0 1 2 2 2 1 2 1 0 2\n",
            " 0 1 2 2 0 2 1]\n",
            "196 / 200 Training loss: 0.0009119217484085648, Tran_Accuracy: 1.0, Validation_loss: 1.2335807291666667, Validation_Accuracy: 0.8066666722297668\n",
            "196 th epoch\n",
            "gt [1 1 2 2 2 2 2 0 0 2 0 0 0 1 2 0 1 0 2 1 0 2 0 2 0 1 1 1 2 1 2 2 0 0 1 0 0\n",
            " 0 2 0 1 1 0 0]\n",
            "pred [1 1 2 2 0 2 2 0 1 2 2 0 0 1 2 0 1 0 2 1 0 2 0 2 0 2 2 1 2 1 1 2 0 0 1 0 0\n",
            " 0 2 0 1 1 0 0]\n",
            "197 / 200 Training loss: 0.0009391600997359664, Tran_Accuracy: 1.0, Validation_loss: 1.3001953125, Validation_Accuracy: 0.800000011920929\n",
            "197 th epoch\n",
            "gt [2 0 2 1 2 0 0 2 0 1 1 1 1 2 2 2 2 1 0 1 1 1 0 1 1 1 1 1 1 2 2 0 1 1 0 0 0\n",
            " 0 0 1 1 2 2 2]\n",
            "pred [2 0 2 1 1 0 2 2 0 2 1 1 1 2 2 2 2 1 0 1 1 1 0 1 1 1 1 1 2 0 2 0 0 2 0 0 0\n",
            " 0 0 0 1 2 2 2]\n",
            "198 / 200 Training loss: 0.0012231211309079771, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2471614583333333, Validation_Accuracy: 0.8100000023841858\n",
            "198 th epoch\n",
            "gt [0 1 1 0 0 2 2 2 0 2 0 0 1 0 1 0 2 1 0 1 1 0 0 0 2 2 0 0 2 2 1 1 0 2 1 0 1\n",
            " 2 1 2 1 2 1 2]\n",
            "pred [0 2 1 0 0 2 2 2 0 2 0 0 1 0 2 0 2 1 0 0 1 0 0 0 1 2 0 0 2 2 1 1 0 2 1 0 1\n",
            " 2 1 2 1 1 2 2]\n",
            "199 / 200 Training loss: 0.0011386602896231192, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2353255208333334, Validation_Accuracy: 0.8133333325386047\n",
            "199 th epoch\n",
            "gt [0 1 2 0 2 0 2 1 0 1 0 1 2 2 2 2 1 2 1 0 0 2 1 2 2 0 1 2 1 2 1 2 2 1 0 2 2\n",
            " 2 2 2 1 1 1 1]\n",
            "pred [0 1 2 0 2 0 2 1 0 2 0 2 2 2 2 2 2 2 1 0 0 1 1 1 2 0 1 2 1 2 1 0 2 2 0 2 1\n",
            " 2 1 1 0 0 1 1]\n",
            "200 / 200 Training loss: 0.0014177703857421876, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3389322916666666, Validation_Accuracy: 0.8033333420753479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.75      1.00      0.86         9\n",
            "     Neutral       0.64      0.60      0.62        15\n",
            "       Smoke       0.78      0.70      0.74        20\n",
            "\n",
            "    accuracy                           0.73        44\n",
            "   macro avg       0.72      0.77      0.74        44\n",
            "weighted avg       0.73      0.73      0.72        44\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKEC-K3hm0YY",
        "colab_type": "code",
        "outputId": "78cd0f61-8f31-4d8f-8f19-172bd0e6f8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# batch = 120 trial\n",
        "n_epochs = 50\n",
        "model,p,t = model_traing_and_validation_loop(Model, n_epochs, 'fire-flame.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 th epoch\n",
            "gt [0 1 1 1 1 1 2 0 2 0 2 0 0 0 2 1 1 0 2 1 2 0 1 1 0 0 0 2 1 0 2 1 2 0 0 2 0\n",
            " 1 2 2 0 1 0 2 0 0 2 0 1 2 2 2 1 0 1 2 2 1 0 2]\n",
            "pred [2 1 1 0 1 1 2 0 2 0 2 0 0 0 1 2 1 0 2 2 2 0 1 0 0 0 0 2 1 0 2 1 2 0 1 2 0\n",
            " 1 1 2 0 1 2 1 0 2 2 2 1 1 2 2 1 0 1 1 2 1 0 2]\n",
            "1 / 50 Training loss: 0.001591067843967014, Tran_Accuracy: 1.0, Validation_loss: 1.0796875, Validation_Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.89      0.77      0.83        22\n",
            "     Neutral       0.70      0.78      0.74        18\n",
            "       Smoke       0.71      0.75      0.73        20\n",
            "\n",
            "    accuracy                           0.77        60\n",
            "   macro avg       0.77      0.77      0.77        60\n",
            "weighted avg       0.78      0.77      0.77        60\n",
            "\n",
            "--------------------------Saving Model---------------------------\n",
            "1 th epoch\n",
            "gt [2 1 0 0 1 1 1 0 0 1 1 1 2 2 2 1 2 2 2 2 0 0 1 1 0 2 2 1 0 2 0 0 1 1 2 1 0\n",
            " 1 2 2 0 1 2 0 2 1 1 2 1 1 0 0 1 1 1 0 0 1 0 2]\n",
            "pred [2 2 0 0 1 1 1 0 0 2 1 1 2 2 2 1 2 2 2 2 0 0 1 1 0 2 2 1 0 1 0 0 1 1 2 2 0\n",
            " 1 2 2 0 1 2 0 2 1 2 2 1 1 0 0 0 2 1 0 0 1 0 2]\n",
            "2 / 50 Training loss: 0.0029823886023627386, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.13955078125, Validation_Accuracy: 0.8199999928474426\n",
            "2 th epoch\n",
            "gt [1 0 2 2 0 2 2 1 2 2 0 0 1 1 2 2 1 1 1 2 1 2 2 2 1 1 2 0 0 1 0 1 2 2 2 2 2\n",
            " 2 0 1 1 0 0 1 2 2 2 1 2 1 1 1 2 2 2 0 0 2 0 1]\n",
            "pred [0 0 2 0 0 2 2 1 1 2 0 0 0 1 2 1 1 1 1 0 2 2 2 2 1 2 2 0 0 1 0 1 2 2 2 2 2\n",
            " 1 0 1 2 0 1 2 2 2 1 1 2 1 1 1 2 2 2 0 0 1 0 0]\n",
            "3 / 50 Training loss: 0.0013868967692057292, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.1205078125, Validation_Accuracy: 0.8133333325386047\n",
            "3 th epoch\n",
            "gt [1 0 0 0 1 2 0 0 2 2 2 1 2 0 0 0 1 2 2 2 1 0 2 2 0 1 1 1 0 0 1 2 1 0 0 0 0\n",
            " 2 2 2 0 1 2 1 1 1 1 1 2 0 2 0 2 2 1 2 2 2 0 1]\n",
            "pred [2 0 0 0 1 2 0 2 1 2 1 2 2 0 0 0 1 1 2 2 1 0 1 2 0 2 1 1 2 0 0 2 1 0 0 0 0\n",
            " 1 1 1 1 0 2 1 1 1 0 1 2 0 2 0 2 2 1 2 2 2 0 1]\n",
            "4 / 50 Training loss: 0.001986609564887153, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.201171875, Validation_Accuracy: 0.800000011920929\n",
            "4 th epoch\n",
            "gt [1 0 2 2 2 1 1 1 1 2 1 0 2 0 2 1 2 0 1 2 0 0 2 1 1 2 0 2 0 2 2 0 0 2 0 1 2\n",
            " 1 2 2 1 2 1 0 1 0 1 2 2 1 1 2 2 0 0 2 2 2 0 2]\n",
            "pred [1 0 2 0 2 2 1 1 2 1 1 0 2 0 2 1 1 0 2 2 0 0 1 1 2 2 2 1 2 2 2 0 0 2 0 1 2\n",
            " 1 2 2 2 1 1 0 1 0 1 2 2 1 1 2 2 0 0 1 2 1 0 2]\n",
            "5 / 50 Training loss: 0.0012306637234157985, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.140234375, Validation_Accuracy: 0.8033333420753479\n",
            "5 th epoch\n",
            "gt [1 2 0 1 1 0 0 0 0 0 0 2 2 2 2 2 2 0 2 1 1 0 0 1 2 1 2 2 2 2 1 0 1 2 1 2 0\n",
            " 0 2 1 2 2 0 2 0 2 1 2 2 0 1 2 2 0 0 1 2 1 1 2]\n",
            "pred [1 2 2 1 1 0 0 0 0 2 0 2 1 2 1 2 1 0 1 2 1 0 0 0 2 1 2 2 2 2 1 0 1 2 1 2 0\n",
            " 0 2 1 1 1 0 2 0 2 1 2 1 0 1 2 2 0 0 1 2 1 0 2]\n",
            "6 / 50 Training loss: 0.001993703842163086, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.20380859375, Validation_Accuracy: 0.8066666722297668\n",
            "6 th epoch\n",
            "gt [1 2 2 1 0 0 0 2 1 0 2 2 0 2 2 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1 1 2 0 0 2 2 2\n",
            " 0 0 2 2 1 0 0 2 2 1 1 0 2 1 0 2 1 1 1 0 0 0 1]\n",
            "pred [1 2 2 1 0 0 0 2 1 0 2 1 0 1 1 1 1 1 1 0 0 0 2 0 1 0 0 1 0 1 2 0 0 0 2 2 2\n",
            " 0 0 2 2 1 0 0 2 2 1 1 0 1 1 0 1 1 2 1 2 0 2 2]\n",
            "7 / 50 Training loss: 0.0021800491544935437, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.22119140625, Validation_Accuracy: 0.8066666722297668\n",
            "7 th epoch\n",
            "gt [0 0 2 0 0 0 2 0 2 0 1 1 1 2 0 0 0 2 0 1 1 0 1 0 2 1 2 1 1 2 0 2 1 1 2 1 0\n",
            " 1 1 2 2 1 2 2 1 2 1 0 1 1 2 2 1 1 1 1 2 0 1 0]\n",
            "pred [0 0 2 0 0 0 1 0 1 1 1 2 2 2 0 0 0 2 2 1 1 2 1 0 2 1 2 1 1 2 0 2 1 1 2 2 0\n",
            " 1 2 2 2 0 2 1 2 2 1 0 0 1 2 2 1 1 0 1 2 0 2 0]\n",
            "8 / 50 Training loss: 0.0021977053748236763, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2447265625, Validation_Accuracy: 0.8100000023841858\n",
            "8 th epoch\n",
            "gt [2 0 0 1 1 1 0 1 2 2 1 1 0 0 0 0 1 2 1 1 1 1 1 0 0 1 2 1 1 1 0 0 1 0 1 1 2\n",
            " 0 0 0 1 1 1 2 1 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2]\n",
            "pred [2 0 0 1 1 1 0 1 2 1 2 2 0 0 1 2 1 2 1 1 1 1 2 0 0 1 2 1 1 2 0 0 1 0 1 0 2\n",
            " 0 0 0 2 1 2 1 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2]\n",
            "9 / 50 Training loss: 0.002449867460462782, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2359375, Validation_Accuracy: 0.8100000023841858\n",
            "9 th epoch\n",
            "gt [2 2 2 2 2 2 0 2 1 0 0 1 2 2 0 2 1 1 2 2 2 0 2 1 0 1 2 2 0 1 0 0 1 0 2 1 0\n",
            " 2 0 0 1 1 1 2 1 0 1 2 2 1 1 2 1 1 2 2 1 0 0 2]\n",
            "pred [1 1 2 2 2 2 0 2 2 0 0 1 1 2 0 2 0 1 2 2 2 0 2 0 0 1 1 2 0 1 0 0 0 0 2 2 0\n",
            " 2 0 0 1 1 1 2 1 0 1 1 2 1 1 2 1 0 2 2 0 0 0 2]\n",
            "10 / 50 Training loss: 0.003601519266764323, Tran_Accuracy: 0.9985185265541077, Validation_loss: 1.33125, Validation_Accuracy: 0.8033333420753479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.76      1.00      0.86        16\n",
            "     Neutral       0.71      0.63      0.67        19\n",
            "       Smoke       0.91      0.80      0.85        25\n",
            "\n",
            "    accuracy                           0.80        60\n",
            "   macro avg       0.79      0.81      0.79        60\n",
            "weighted avg       0.81      0.80      0.80        60\n",
            "\n",
            "10 th epoch\n",
            "gt [2 2 2 0 1 0 2 0 0 1 0 0 1 0 1 1 1 0 2 0 0 2 0 1 2 1 2 1 2 0 2 2 2 1 1 2 2\n",
            " 0 2 0 0 2 2 0 1 2 1 1 0 2 2 2 2 1 0 2 2 0 0 0]\n",
            "pred [2 2 2 0 0 0 2 0 0 1 0 0 1 0 1 1 2 0 2 0 0 1 0 1 2 1 2 1 1 0 2 2 2 1 1 1 2\n",
            " 0 2 0 0 1 2 0 1 0 1 1 0 2 2 2 2 1 0 2 2 2 0 0]\n",
            "11 / 50 Training loss: 0.001233673095703125, Tran_Accuracy: 1.0, Validation_loss: 1.359375, Validation_Accuracy: 0.8066666722297668\n",
            "11 th epoch\n",
            "gt [1 1 2 2 2 1 2 2 0 0 0 0 1 1 2 1 0 1 1 1 1 1 2 2 1 0 0 2 1 1 1 1 2 2 2 2 2\n",
            " 0 2 1 1 2 1 1 0 1 2 0 0 0 2 0 2 0 0 0 1 1 0 2]\n",
            "pred [1 1 2 2 2 0 2 2 0 0 0 0 0 1 2 2 0 1 1 1 0 2 2 2 1 2 0 2 2 0 1 1 1 1 2 2 1\n",
            " 0 2 1 1 2 1 1 0 1 2 0 0 0 2 2 2 0 0 1 2 1 0 2]\n",
            "12 / 50 Training loss: 0.0011768711937798393, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3185546875, Validation_Accuracy: 0.8100000023841858\n",
            "12 th epoch\n",
            "gt [0 1 2 0 2 1 0 1 0 2 1 2 0 2 0 2 1 1 1 1 2 0 2 2 1 2 1 2 0 0 2 1 2 0 1 2 0\n",
            " 2 0 1 0 2 0 0 2 1 2 1 2 1 2 2 0 0 2 0 2 0 2 2]\n",
            "pred [0 1 2 0 2 1 0 1 0 2 1 1 0 2 0 1 1 2 2 1 2 0 2 2 2 2 1 1 0 0 2 0 1 0 1 2 0\n",
            " 2 0 1 0 2 0 2 2 1 1 1 2 1 2 2 0 0 2 0 2 0 1 2]\n",
            "13 / 50 Training loss: 0.0011268430285983615, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2884765625, Validation_Accuracy: 0.8133333325386047\n",
            "13 th epoch\n",
            "gt [1 2 1 1 0 1 0 0 1 1 0 1 1 0 0 2 1 0 0 2 0 2 1 1 1 1 2 2 0 0 2 0 2 1 1 1 0\n",
            " 2 0 1 1 1 2 0 2 2 0 1 1 0 2 2 2 0 0 0 2 1 2 0]\n",
            "pred [1 2 0 2 2 1 0 0 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 1 1 2 1 0 0 2 2 2 1 1 1 0\n",
            " 2 0 1 2 1 2 0 2 2 0 1 1 2 2 2 2 0 0 0 1 0 2 0]\n",
            "14 / 50 Training loss: 0.0011404381857977974, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.285546875, Validation_Accuracy: 0.8100000023841858\n",
            "14 th epoch\n",
            "gt [0 0 2 1 2 0 0 2 1 1 0 1 2 1 0 2 0 2 0 0 2 1 2 2 1 1 1 1 1 0 0 0 0 2 2 0 1\n",
            " 1 1 2 1 0 1 0 2 2 1 0 2 1 1 1 0 1 2 1 2 0 2 2]\n",
            "pred [2 0 2 2 1 0 0 2 1 1 0 1 2 2 0 1 0 2 0 0 2 0 2 2 2 2 1 0 1 0 0 0 0 2 1 0 1\n",
            " 1 0 1 2 0 1 0 2 2 1 0 2 1 1 1 1 1 2 1 2 0 2 2]\n",
            "15 / 50 Training loss: 0.0008532497617933485, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.26953125, Validation_Accuracy: 0.8133333325386047\n",
            "15 th epoch\n",
            "gt [1 1 2 1 0 2 2 2 1 1 0 0 0 1 2 0 1 1 2 0 0 1 0 1 2 1 2 2 0 1 2 0 1 0 2 2 0\n",
            " 0 0 2 2 1 2 0 2 0 1 2 2 0 0 2 1 1 1 0 2 1 0 1]\n",
            "pred [1 1 2 1 0 2 2 1 1 2 0 0 0 1 2 0 1 0 1 0 0 1 0 1 2 2 2 2 0 1 2 0 1 0 2 1 0\n",
            " 0 0 1 2 1 2 1 1 0 2 2 1 0 0 2 1 1 1 0 2 1 0 1]\n",
            "16 / 50 Training loss: 0.0010086152288648817, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2552734375, Validation_Accuracy: 0.8133333325386047\n",
            "16 th epoch\n",
            "gt [0 0 0 1 0 0 2 2 2 1 0 1 0 0 0 0 1 0 1 2 1 1 1 2 2 2 2 1 2 2 2 0 1 2 1 1 0\n",
            " 2 1 1 0 0 1 1 2 1 1 2 0 1 1 1 2 2 2 1 2 2 0 2]\n",
            "pred [0 0 0 1 0 0 2 2 2 1 0 2 0 0 0 0 1 0 1 2 1 1 1 2 2 0 2 0 2 0 2 0 1 2 0 1 0\n",
            " 1 1 1 0 2 1 1 2 1 1 1 0 2 1 1 2 1 2 2 2 1 0 2]\n",
            "17 / 50 Training loss: 0.0019770834181043837, Tran_Accuracy: 0.9988889098167419, Validation_loss: 1.23828125, Validation_Accuracy: 0.8100000023841858\n",
            "17 th epoch\n",
            "gt [0 2 0 0 1 2 2 1 1 1 0 0 1 1 0 0 2 1 1 1 2 1 0 0 0 0 2 1 0 2 1 2 0 0 1 0 0\n",
            " 2 1 1 2 1 2 2 0 2 2 2 2 0 1 0 1 0 0 1 2 0 0 2]\n",
            "pred [0 2 0 0 1 2 1 2 1 1 0 0 1 0 0 2 1 1 1 1 2 1 1 0 0 2 2 1 0 2 1 2 0 0 1 0 2\n",
            " 2 1 1 2 1 2 2 0 2 2 2 2 0 1 0 1 0 0 1 2 0 2 2]\n",
            "18 / 50 Training loss: 0.0012909862730238174, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2712890625, Validation_Accuracy: 0.800000011920929\n",
            "18 th epoch\n",
            "gt [1 0 2 0 2 0 2 2 2 2 1 1 1 2 0 2 0 0 1 1 1 1 2 0 1 1 0 1 2 2 1 0 1 2 1 2 2\n",
            " 2 1 0 0 2 0 0 0 2 0 0 2 2 0 0 0 1 0 1 0 1 2 1]\n",
            "pred [1 0 2 0 2 0 2 1 1 2 2 2 1 2 0 2 0 0 1 1 1 1 2 0 1 1 0 1 2 2 2 0 1 1 1 2 2\n",
            " 2 2 0 2 2 0 0 0 2 0 0 2 2 0 0 0 1 1 2 0 1 2 1]\n",
            "19 / 50 Training loss: 0.0008769432703653971, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2533203125, Validation_Accuracy: 0.8100000023841858\n",
            "19 th epoch\n",
            "gt [0 2 0 1 2 2 1 0 2 0 0 2 1 2 1 1 1 2 2 2 2 1 0 0 2 1 2 2 0 2 2 1 2 1 0 2 0\n",
            " 1 0 2 1 0 1 0 0 0 2 2 1 1 1 1 1 0 2 0 1 0 2 2]\n",
            "pred [0 2 0 1 2 2 1 0 2 2 0 2 1 2 1 1 2 2 0 2 1 1 0 0 2 1 1 2 0 2 1 1 2 1 0 2 0\n",
            " 1 2 2 1 0 0 0 0 0 2 2 2 1 2 1 1 0 2 0 1 0 2 2]\n",
            "20 / 50 Training loss: 0.001047862900627984, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3236328125, Validation_Accuracy: 0.8133333325386047\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.89      0.89      0.89        18\n",
            "     Neutral       0.83      0.79      0.81        19\n",
            "       Smoke       0.79      0.83      0.81        23\n",
            "\n",
            "    accuracy                           0.83        60\n",
            "   macro avg       0.84      0.83      0.84        60\n",
            "weighted avg       0.83      0.83      0.83        60\n",
            "\n",
            "20 th epoch\n",
            "gt [0 0 1 2 0 0 0 0 2 2 1 0 1 2 0 1 1 1 0 0 0 1 0 2 2 0 0 1 0 0 0 0 2 0 2 2 1\n",
            " 1 1 2 1 2 0 1 1 2 1 0 2 2 0 2 1 2 2 1 1 0 1 2]\n",
            "pred [0 0 1 2 0 0 1 0 2 2 1 0 1 0 0 1 1 1 0 0 0 1 2 2 2 0 0 1 0 2 0 0 2 0 1 2 2\n",
            " 1 1 1 2 0 0 0 2 2 1 0 2 2 0 2 1 2 2 1 1 0 1 2]\n",
            "21 / 50 Training loss: 0.0010701815287272136, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.29296875, Validation_Accuracy: 0.8033333420753479\n",
            "21 th epoch\n",
            "gt [2 2 1 2 2 2 0 1 1 1 0 1 1 0 1 2 0 2 2 0 2 1 1 2 2 0 1 2 1 1 0 1 0 2 2 2 1\n",
            " 0 0 0 1 1 0 1 1 2 0 0 1 1 0 1 2 1 2 1 2 2 1 1]\n",
            "pred [2 2 1 0 2 1 0 1 2 1 0 1 1 0 1 2 0 2 2 0 2 1 1 2 2 0 1 2 1 1 0 0 0 0 2 2 2\n",
            " 0 0 0 1 1 0 1 2 2 0 0 1 1 0 1 2 1 2 1 2 2 2 2]\n",
            "22 / 50 Training loss: 0.001768297619289822, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2642578125, Validation_Accuracy: 0.8166666626930237\n",
            "22 th epoch\n",
            "gt [1 1 1 2 1 1 0 0 1 2 2 2 2 1 2 1 2 2 1 2 0 2 2 0 2 0 2 0 0 2 1 2 1 0 1 0 1\n",
            " 0 2 0 1 2 2 0 1 0 2 1 2 2 0 1 0 1 1 2 0 1 0 1]\n",
            "pred [1 1 1 2 1 1 0 0 1 2 1 2 2 1 0 1 2 1 0 2 0 2 2 1 2 0 1 0 0 2 0 2 1 0 2 0 1\n",
            " 0 2 0 1 2 2 0 1 0 2 1 1 2 2 1 0 1 1 2 0 0 0 1]\n",
            "23 / 50 Training loss: 0.0009569883346557617, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.250390625, Validation_Accuracy: 0.8266666531562805\n",
            "--------------------------Saving Model---------------------------\n",
            "23 th epoch\n",
            "gt [0 0 2 1 0 1 1 0 0 1 1 2 2 0 2 1 2 2 1 0 0 1 2 0 0 0 0 1 2 1 2 0 2 0 1 2 0\n",
            " 0 0 1 1 1 1 0 2 0 1 1 1 0 0 0 1 2 1 2 0 2 0 0]\n",
            "pred [0 0 2 1 1 1 1 2 0 1 1 2 2 0 2 1 2 2 1 0 0 1 2 0 0 1 0 1 1 1 2 0 2 0 1 1 0\n",
            " 0 0 1 1 1 2 0 2 0 1 2 1 2 2 0 1 2 1 2 0 2 0 0]\n",
            "24 / 50 Training loss: 0.0014137241575453016, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.42265625, Validation_Accuracy: 0.8199999928474426\n",
            "24 th epoch\n",
            "gt [2 0 1 2 0 2 2 0 1 1 0 0 1 1 2 1 1 1 0 0 2 1 1 0 2 2 1 0 1 0 2 1 0 1 0 0 2\n",
            " 1 2 2 1 1 2 1 1 2 0 0 0 1 0 1 2 1 1 2 1 1 1 0]\n",
            "pred [1 0 2 2 0 1 2 0 1 1 0 0 1 1 1 2 1 2 2 0 2 2 1 0 2 2 2 0 1 0 2 1 1 1 0 0 2\n",
            " 1 2 2 1 1 2 0 1 2 0 0 0 1 2 1 1 2 1 0 1 1 2 0]\n",
            "25 / 50 Training loss: 0.0010770877202351888, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3037109375, Validation_Accuracy: 0.8166666626930237\n",
            "25 th epoch\n",
            "gt [0 1 2 2 0 1 0 2 0 2 0 2 1 0 0 1 0 1 0 2 1 2 0 0 2 2 0 2 2 2 1 2 2 1 0 1 1\n",
            " 2 2 1 0 0 2 2 2 0 2 1 1 2 1 0 2 2 0 0 0 0 1 2]\n",
            "pred [0 1 1 2 0 1 0 2 0 2 0 2 1 0 0 2 0 1 0 2 1 1 0 0 2 2 0 1 2 2 2 2 2 2 0 1 1\n",
            " 1 2 1 0 0 1 2 2 0 2 1 1 2 0 0 2 2 0 1 0 2 1 2]\n",
            "26 / 50 Training loss: 0.0008501026365492079, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.26015625, Validation_Accuracy: 0.800000011920929\n",
            "26 th epoch\n",
            "gt [0 2 0 2 1 1 0 1 1 2 1 0 2 2 1 2 2 2 1 2 0 2 1 2 1 0 2 2 1 2 2 0 2 1 1 2 2\n",
            " 1 2 2 1 1 2 2 1 1 2 0 1 2 0 0 1 0 2 0 1 0 0 2]\n",
            "pred [0 1 0 2 1 1 0 1 1 2 1 0 2 2 1 2 2 2 1 2 0 1 1 2 0 0 2 2 2 2 2 1 2 1 1 2 2\n",
            " 2 0 2 0 0 2 2 1 1 2 0 1 2 0 0 1 0 2 0 1 0 0 2]\n",
            "27 / 50 Training loss: 0.001359611087375217, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.266796875, Validation_Accuracy: 0.8166666626930237\n",
            "27 th epoch\n",
            "gt [1 1 1 0 0 2 1 1 2 0 2 2 2 1 0 2 1 2 2 2 2 0 2 1 1 2 2 2 0 1 2 1 0 1 2 0 2\n",
            " 1 1 2 1 2 2 2 0 0 1 0 2 1 0 2 2 2 2 1 0 1 2 0]\n",
            "pred [2 1 1 0 0 2 1 1 1 2 1 2 2 2 0 2 1 1 1 2 0 0 2 1 0 2 2 2 0 0 2 1 0 1 2 0 2\n",
            " 1 1 2 1 2 1 1 0 0 1 0 2 1 0 2 2 1 2 1 0 1 2 0]\n",
            "28 / 50 Training loss: 0.0009914398193359374, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.37109375, Validation_Accuracy: 0.7866666913032532\n",
            "28 th epoch\n",
            "gt [2 1 0 1 0 0 1 0 0 1 2 1 2 2 2 2 1 1 2 2 2 2 2 1 1 1 0 2 1 2 1 2 1 2 2 0 1\n",
            " 0 1 2 1 2 2 0 2 1 1 0 0 0 2 1 1 0 1 1 0 1 0 2]\n",
            "pred [2 1 0 1 0 0 1 0 0 1 2 2 2 2 2 1 1 2 2 0 1 2 2 1 1 1 0 2 1 1 1 2 1 2 2 0 2\n",
            " 0 2 2 1 1 2 0 1 1 0 0 0 0 2 1 2 2 1 1 0 1 0 2]\n",
            "29 / 50 Training loss: 0.001252105500962999, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.27734375, Validation_Accuracy: 0.8133333325386047\n",
            "29 th epoch\n",
            "gt [1 1 2 2 1 2 0 1 2 1 0 0 2 0 1 1 2 0 0 2 2 1 0 2 0 2 1 1 0 0 2 0 1 0 1 0 0\n",
            " 0 2 2 2 1 0 2 2 2 1 2 0 1 0 0 0 2 1 1 2 1 2 2]\n",
            "pred [1 2 2 1 2 2 0 0 2 1 0 0 2 0 1 1 1 0 2 2 2 1 0 2 0 1 1 1 0 0 2 0 1 0 1 0 0\n",
            " 2 2 2 2 1 0 2 2 2 0 2 0 1 0 2 1 2 1 2 2 1 2 2]\n",
            "30 / 50 Training loss: 0.0012561639149983725, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.254296875, Validation_Accuracy: 0.8066666722297668\n",
            "30 th epoch\n",
            "gt [2 0 2 1 0 0 0 0 0 2 2 2 1 1 2 1 1 1 1 0 2 0 0 2 0 2 0 1 2 2 2 1 0 0 2 0 2\n",
            " 2 1 1 0 0 0 2 2 2 1 2 2 1 0 2 2 0 1 1 2 0 1 1]\n",
            "pred [2 0 2 1 2 0 0 2 0 2 2 1 1 1 2 0 2 1 1 2 2 0 0 2 0 2 0 1 1 2 2 1 0 0 2 0 2\n",
            " 2 1 2 0 0 0 2 2 1 1 2 2 1 0 1 2 0 1 1 1 0 1 1]\n",
            "31 / 50 Training loss: 0.001452032725016276, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2724609375, Validation_Accuracy: 0.8233333230018616\n",
            "31 th epoch\n",
            "gt [1 0 0 2 2 0 1 2 2 1 1 1 1 1 0 1 0 2 2 1 0 1 0 2 2 1 1 1 0 2 2 0 0 1 0 1 1\n",
            " 2 1 0 1 2 2 2 1 1 1 0 2 0 1 0 1 2 2 2 0 2 0 1]\n",
            "pred [1 2 0 2 2 0 0 2 2 0 1 1 1 1 0 1 0 2 0 1 0 0 0 2 2 1 1 1 2 2 2 0 0 1 0 2 1\n",
            " 2 1 0 1 2 2 2 1 1 1 2 2 0 1 0 1 2 2 1 0 2 0 2]\n",
            "32 / 50 Training loss: 0.0013639132181803386, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3037109375, Validation_Accuracy: 0.8066666722297668\n",
            "32 th epoch\n",
            "gt [2 0 1 0 0 1 1 0 0 2 1 2 2 2 1 1 1 0 1 1 1 0 1 2 2 0 0 1 2 2 1 2 0 2 1 2 1\n",
            " 2 1 0 2 1 0 1 0 0 1 1 2 1 0 0 0 0 1 2 1 1 0 2]\n",
            "pred [2 0 1 0 0 1 1 2 0 2 2 1 2 0 1 1 1 0 1 1 1 0 2 2 2 0 0 1 2 2 1 1 0 2 1 2 1\n",
            " 2 1 0 2 2 0 2 0 0 2 2 2 2 0 0 0 0 1 2 1 1 0 2]\n",
            "33 / 50 Training loss: 0.0008492761188083225, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2748046875, Validation_Accuracy: 0.8166666626930237\n",
            "33 th epoch\n",
            "gt [2 2 0 1 0 1 1 1 2 1 0 2 0 2 0 1 0 2 0 1 1 2 1 0 2 1 0 0 2 0 2 1 0 1 0 0 2\n",
            " 0 1 0 0 0 0 0 1 1 2 2 2 1 2 1 0 2 2 2 1 1 2 1]\n",
            "pred [1 1 0 1 0 2 1 1 2 1 0 2 0 1 2 1 0 2 0 2 1 2 0 0 2 1 0 0 2 0 1 2 1 1 0 2 2\n",
            " 0 1 0 0 0 0 0 1 1 2 2 2 1 2 1 2 2 1 1 1 2 2 2]\n",
            "34 / 50 Training loss: 0.0010422759585910373, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.33203125, Validation_Accuracy: 0.8100000023841858\n",
            "34 th epoch\n",
            "gt [1 1 1 0 1 1 2 0 0 1 1 0 1 2 2 2 0 1 0 2 0 2 2 2 2 0 2 2 1 1 2 0 2 0 1 2 1\n",
            " 1 0 2 2 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1]\n",
            "pred [2 1 1 0 1 1 2 0 0 1 1 0 1 1 2 1 0 2 0 2 0 2 2 2 2 1 2 2 1 1 2 0 2 0 1 2 2\n",
            " 2 0 1 2 1 1 1 0 0 0 1 1 1 0 0 0 2 1 2 1 0 1 1]\n",
            "35 / 50 Training loss: 0.0013768408033582899, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2908203125, Validation_Accuracy: 0.800000011920929\n",
            "35 th epoch\n",
            "gt [2 2 1 0 0 1 2 0 2 1 0 0 0 2 0 2 1 0 2 2 2 2 0 1 2 0 0 1 0 2 2 1 0 2 2 0 2\n",
            " 2 0 0 0 0 2 0 1 2 1 1 2 1 0 1 1 0 2 0 2 0 2 1]\n",
            "pred [1 2 2 0 0 1 2 0 2 1 0 0 0 2 0 1 1 0 2 1 2 2 0 1 2 0 0 1 0 2 2 1 0 2 2 2 2\n",
            " 2 0 0 2 0 2 0 1 2 1 1 2 0 2 1 1 0 2 0 2 0 2 1]\n",
            "36 / 50 Training loss: 0.0013207409116956922, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.31396484375, Validation_Accuracy: 0.8066666722297668\n",
            "36 th epoch\n",
            "gt [2 2 0 1 2 0 2 1 1 2 0 2 0 1 0 2 0 1 0 2 1 1 1 2 2 0 0 2 2 1 1 0 2 0 0 2 1\n",
            " 0 0 2 2 0 0 2 2 0 0 1 0 0 0 1 1 1 0 0 0 2 1 0]\n",
            "pred [1 2 2 1 2 2 2 1 1 2 0 2 0 1 0 2 0 2 2 1 1 1 2 2 2 0 0 2 2 1 1 0 2 0 0 2 1\n",
            " 0 0 2 2 0 1 2 2 0 0 1 0 0 0 1 1 1 0 0 0 2 1 0]\n",
            "37 / 50 Training loss: 0.001072602801852756, Tran_Accuracy: 1.0, Validation_loss: 1.3150390625, Validation_Accuracy: 0.8066666722297668\n",
            "37 th epoch\n",
            "gt [1 1 1 2 1 2 1 2 0 2 1 2 2 0 0 1 1 1 1 1 0 0 2 2 0 0 0 2 1 2 0 0 1 2 0 2 2\n",
            " 2 0 2 2 2 2 2 2 2 1 0 2 2 1 2 0 2 0 1 1 2 1 0]\n",
            "pred [2 1 1 2 2 2 1 2 0 2 0 2 2 0 0 1 1 0 1 1 0 0 1 1 0 0 0 2 2 2 0 0 2 2 0 2 2\n",
            " 2 2 1 2 0 2 1 2 2 1 0 2 2 1 2 0 2 0 1 1 1 1 0]\n",
            "38 / 50 Training loss: 0.0007456355624728733, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.2724609375, Validation_Accuracy: 0.8033333420753479\n",
            "38 th epoch\n",
            "gt [1 2 0 2 0 0 0 2 2 2 1 2 2 0 1 0 2 1 1 1 2 0 2 1 2 0 2 1 1 2 0 1 2 0 1 2 2\n",
            " 2 2 1 1 2 1 2 2 1 0 1 2 0 0 0 1 0 1 1 1 2 2 0]\n",
            "pred [2 2 0 1 0 0 0 2 1 2 1 2 2 0 1 0 2 1 1 1 1 0 2 1 1 0 2 1 1 2 1 2 2 0 1 2 2\n",
            " 2 2 1 1 2 0 2 2 2 0 1 2 0 0 0 1 2 1 1 0 2 2 0]\n",
            "39 / 50 Training loss: 0.0009934955173068576, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.27607421875, Validation_Accuracy: 0.8199999928474426\n",
            "39 th epoch\n",
            "gt [2 2 1 0 0 1 1 1 2 2 2 0 1 0 1 2 0 0 1 2 2 0 2 2 2 2 0 2 0 0 1 1 2 0 1 2 1\n",
            " 2 2 0 1 1 0 1 1 0 2 1 0 1 2 0 1 0 1 1 2 1 1 2]\n",
            "pred [2 2 2 0 0 1 1 1 2 2 2 0 1 0 2 2 0 0 0 2 2 0 2 2 2 2 0 1 0 0 2 1 1 0 1 2 1\n",
            " 2 2 0 1 2 0 0 1 0 2 1 0 1 2 0 1 0 1 1 2 1 2 2]\n",
            "40 / 50 Training loss: 0.0010220713085598416, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.31162109375, Validation_Accuracy: 0.8199999928474426\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       0.89      1.00      0.94        17\n",
            "     Neutral       0.88      0.68      0.77        22\n",
            "       Smoke       0.79      0.90      0.84        21\n",
            "\n",
            "    accuracy                           0.85        60\n",
            "   macro avg       0.86      0.86      0.85        60\n",
            "weighted avg       0.85      0.85      0.85        60\n",
            "\n",
            "40 th epoch\n",
            "gt [1 1 2 2 0 2 2 2 2 2 2 0 0 0 2 2 1 2 0 0 1 1 0 1 2 0 2 1 0 2 1 0 1 0 2 0 2\n",
            " 0 0 1 0 2 1 2 2 2 1 1 0 1 0 1 2 0 1 2 2 2 2 2]\n",
            "pred [1 1 2 2 0 2 1 2 1 2 1 0 0 0 2 2 1 2 0 0 1 1 0 1 2 0 2 1 0 1 1 0 1 0 2 0 1\n",
            " 0 0 1 0 0 2 2 2 2 1 1 0 1 0 1 2 0 0 2 2 2 1 2]\n",
            "41 / 50 Training loss: 0.000906682014465332, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.3314453125, Validation_Accuracy: 0.8166666626930237\n",
            "41 th epoch\n",
            "gt [2 1 2 0 2 0 0 0 0 2 0 2 2 1 1 1 1 1 0 0 2 1 0 2 2 2 2 0 1 2 2 0 2 1 0 2 2\n",
            " 0 0 2 0 1 1 1 2 2 0 2 2 2 2 0 2 2 2 1 2 1 0 1]\n",
            "pred [0 1 2 0 1 0 0 2 0 2 0 2 2 1 1 1 1 1 0 0 2 1 0 1 1 2 2 0 1 1 2 0 2 0 0 2 1\n",
            " 0 0 1 0 2 2 1 2 2 2 2 2 2 2 0 1 2 2 1 1 2 0 1]\n",
            "42 / 50 Training loss: 0.000981744130452474, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.317578125, Validation_Accuracy: 0.8100000023841858\n",
            "42 th epoch\n",
            "gt [1 0 1 2 0 0 2 1 0 2 1 0 2 0 0 0 2 2 1 0 1 0 0 2 2 0 0 2 2 2 2 0 2 1 0 1 0\n",
            " 1 2 0 0 1 1 0 1 2 0 1 2 1 2 1 1 1 0 1 2 0 2 1]\n",
            "pred [2 2 1 2 0 2 2 1 0 2 1 0 2 0 0 0 2 2 1 0 1 0 0 2 2 0 0 2 2 2 2 0 2 1 0 1 0\n",
            " 1 2 0 0 1 1 0 1 2 0 1 2 1 1 2 1 1 1 1 2 0 2 2]\n",
            "43 / 50 Training loss: 0.0011833747227986654, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.335546875, Validation_Accuracy: 0.8066666722297668\n",
            "43 th epoch\n",
            "gt [0 0 0 1 0 2 0 0 1 0 0 0 1 1 2 2 1 0 1 1 1 0 0 2 2 1 2 0 1 1 1 2 1 1 2 1 1\n",
            " 0 2 0 2 1 1 0 1 0 0 1 1 0 1 1 1 0 1 2 2 1 2 1]\n",
            "pred [0 0 0 1 0 2 0 0 0 0 0 0 1 1 2 2 0 0 1 1 1 0 2 2 2 1 2 0 2 1 2 2 1 1 2 1 2\n",
            " 0 2 0 2 2 1 0 1 2 0 0 1 2 1 1 0 0 2 2 1 1 2 1]\n",
            "44 / 50 Training loss: 0.0006264183256361219, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.40546875, Validation_Accuracy: 0.8133333325386047\n",
            "44 th epoch\n",
            "gt [0 0 0 0 1 2 1 0 0 2 1 2 2 0 0 0 2 1 1 2 1 1 1 2 1 0 0 2 0 1 0 0 0 1 2 2 2\n",
            " 0 0 1 0 0 2 1 2 2 1 0 2 0 0 2 2 0 1 2 1 0 2 2]\n",
            "pred [0 0 2 0 2 2 1 2 0 2 2 2 2 0 0 0 2 1 1 2 1 1 1 2 1 0 0 2 0 1 0 0 0 2 2 1 2\n",
            " 0 0 1 0 2 2 1 2 1 1 0 1 0 0 2 1 0 2 1 1 0 2 2]\n",
            "45 / 50 Training loss: 0.0009903589884440104, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.2935546875, Validation_Accuracy: 0.8166666626930237\n",
            "45 th epoch\n",
            "gt [1 2 0 2 0 0 2 0 0 2 0 1 0 2 1 2 0 1 2 0 2 0 1 2 0 1 0 2 0 2 1 2 1 2 2 0 1\n",
            " 0 1 2 1 0 0 0 2 0 1 1 2 0 0 2 0 2 1 1 0 0 2 0]\n",
            "pred [2 2 0 1 0 0 2 0 0 2 0 2 0 2 1 2 0 1 2 0 2 0 2 1 0 1 0 2 0 1 1 2 1 2 2 2 1\n",
            " 0 1 1 2 0 0 0 2 0 1 1 2 0 0 2 0 1 1 1 0 0 2 0]\n",
            "46 / 50 Training loss: 0.0009880423545837401, Tran_Accuracy: 1.0, Validation_loss: 1.308984375, Validation_Accuracy: 0.800000011920929\n",
            "46 th epoch\n",
            "gt [0 1 0 0 1 0 2 2 1 0 1 1 0 2 0 1 1 1 0 0 0 2 2 1 0 2 2 0 1 0 1 0 2 0 2 1 0\n",
            " 0 0 0 2 2 0 2 0 2 2 1 0 0 2 0 2 2 0 1 1 1 2 1]\n",
            "pred [0 2 0 0 1 0 2 2 1 0 1 1 0 2 0 1 1 1 0 0 0 0 2 2 2 2 2 2 1 0 1 0 2 0 2 1 0\n",
            " 0 0 0 1 2 1 2 0 2 2 1 0 0 2 0 2 1 0 1 1 1 2 1]\n",
            "47 / 50 Training loss: 0.0007209009594387479, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.330078125, Validation_Accuracy: 0.8033333420753479\n",
            "47 th epoch\n",
            "gt [2 1 0 0 1 1 1 0 0 0 0 1 0 0 2 1 2 0 2 2 1 0 0 1 1 1 2 0 2 2 1 2 0 2 1 2 1\n",
            " 0 1 2 2 0 1 1 0 1 1 1 1 2 2 1 0 1 2 0 0 1 1 1]\n",
            "pred [2 1 0 0 1 1 2 0 0 2 0 1 0 0 2 1 2 0 2 1 2 0 0 1 1 1 0 0 2 2 2 2 0 2 1 2 2\n",
            " 0 2 2 2 0 2 1 0 1 1 1 1 2 2 1 0 0 2 2 0 2 1 2]\n",
            "48 / 50 Training loss: 0.0010522339079115125, Tran_Accuracy: 0.9992592334747314, Validation_loss: 1.28203125, Validation_Accuracy: 0.8066666722297668\n",
            "48 th epoch\n",
            "gt [0 1 2 2 1 0 0 0 2 2 0 2 0 2 0 1 1 1 0 2 1 2 0 0 2 0 0 2 2 0 0 1 2 0 2 2 2\n",
            " 0 1 2 0 0 2 1 1 1 1 2 0 0 1 0 0 1 1 1 0 0 2 1]\n",
            "pred [0 1 2 1 1 0 2 0 2 1 1 2 0 2 0 0 1 1 0 2 1 2 0 0 2 0 0 2 1 0 2 1 1 2 2 2 2\n",
            " 0 1 2 0 0 2 1 0 1 1 2 0 0 1 0 0 2 1 1 0 0 2 2]\n",
            "49 / 50 Training loss: 0.0007038805219862196, Tran_Accuracy: 1.0, Validation_loss: 1.3431640625, Validation_Accuracy: 0.8166666626930237\n",
            "49 th epoch\n",
            "gt [1 2 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 1 2 0 0 1 1 2 2 1 0 0 1 2 1 0 1 2 2 1 0\n",
            " 2 0 0 2 2 0 2 1 1 1 1 2 1 0 1 0 0 0 2 2 2 1 0]\n",
            "pred [1 1 2 1 1 1 2 0 1 0 0 1 1 0 0 0 1 1 2 2 0 2 1 2 2 1 0 0 1 2 2 2 1 2 1 1 0\n",
            " 2 0 0 2 2 0 2 2 1 1 2 2 2 0 1 0 2 0 2 2 1 2 0]\n",
            "50 / 50 Training loss: 0.00111973418129815, Tran_Accuracy: 0.9996296167373657, Validation_loss: 1.3443359375, Validation_Accuracy: 0.8100000023841858\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fire       1.00      0.81      0.89        21\n",
            "     Neutral       0.85      0.71      0.77        24\n",
            "       Smoke       0.52      0.80      0.63        15\n",
            "\n",
            "    accuracy                           0.77        60\n",
            "   macro avg       0.79      0.77      0.77        60\n",
            "weighted avg       0.82      0.77      0.78        60\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn1HvNgOE-GM",
        "colab_type": "code",
        "outputId": "daaa1804-6c64-4380-c455-93f9326363c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "load_saved_model = torch.load('fire-flame.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-589e8ec1bee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_saved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fire-flame.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fire-flame.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX9S8p3_X0ng",
        "colab_type": "code",
        "outputId": "54bca8d1-3eb9-448a-96a9-bbba168c0639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiSequential(\n",
              "  (0): Convert()\n",
              "  (1): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be14oMqAZeYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(image, model):\n",
        "    # Pass the image through our model\n",
        "    output = model.forward(image)\n",
        "    \n",
        "    # Reverse the log function in our output\n",
        "    output = torch.exp(output)\n",
        "    \n",
        "    # Get the top predicted class, and the output percentage for\n",
        "    # that class\n",
        "    probs, classes = output.topk(1, dim=1)\n",
        "    return probs.item(), classes.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dionFwg3at2s",
        "colab_type": "code",
        "outputId": "2c5a2545-d285-4e00-8579-1e784cc0b62d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "p = []\n",
        "for data, target in testloader:\n",
        "    data, target = data.to(device,dtype=torch.float), target.to(device)\n",
        "\n",
        "\n",
        "                \n",
        "    data = data.float()\n",
        "    target = target.long()\n",
        "    data, target = Variable(data), Variable(target)\n",
        "\n",
        "\n",
        "\n",
        "    predictions = load_saved_model(data)\n",
        "    p.append(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-61dd2041259c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchfusion_utils/fp16/fp16.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.43 GiB total capacity; 6.77 GiB already allocated; 2.94 MiB free; 6.91 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkARar1Lb_84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image  \n",
        "\n",
        "img = image.load_img(img_path, target_size=(224, 224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW3yXd_dg3W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_split_test(testdir):\n",
        "    \n",
        "    transforms_test = transforms.Compose([transforms.Resize((224,224),0),\n",
        "                                       transforms.ToTensor()])\n",
        "    test_data = datasets.ImageFolder(testdir,       \n",
        "                    transform=transforms_test)\n",
        "        \n",
        "    test = torch.utils.data.DataLoader(test_data, shuffle=True)\n",
        "    \n",
        "    return test\n",
        "test= load_split_test(test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw0yP5Zlhmsk",
        "colab_type": "code",
        "outputId": "8a593e6b-c464-43ea-9821-cd0a4293939d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "p = []\n",
        "for data, target in testloader:\n",
        "    #            \n",
        "    data = data.float()\n",
        "    target = target.long()\n",
        "    data, target = Variable(data), Variable(target)\n",
        "\n",
        "\n",
        "\n",
        "    predictions = load_saved_model(data)\n",
        "    p.append(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a9247abedf74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchfusion_utils/fp16/fp16.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.43 GiB total capacity; 6.76 GiB already allocated; 10.94 MiB free; 6.90 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1ZgyHR7h0xS",
        "colab_type": "code",
        "outputId": "ce3b4e3e-7b66-4327-a6fa-4f33e4ca78ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "n_epochs = 50\n",
        "model = model_traing_and_validation_loop(Model, n_epochs, 'fire-flame.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 th epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7d3e98151283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_traing_and_validation_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fire-flame.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-98907d06690e>\u001b[0m in \u001b[0;36mmodel_traing_and_validation_loop\u001b[0;34m(Model, n_epochs, save_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 7.43 GiB total capacity; 6.76 GiB already allocated; 10.94 MiB free; 6.90 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhZn1i5limzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}